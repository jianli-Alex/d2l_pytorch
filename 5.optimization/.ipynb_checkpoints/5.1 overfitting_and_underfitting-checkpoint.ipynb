{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T13:21:22.105791Z",
     "start_time": "2020-10-08T13:21:22.085875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity = \"all\"\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以多项式函数拟合来试验模型复杂度和训练数据集大小对欠拟合和过拟合的影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T12:55:40.173905Z",
     "start_time": "2020-10-05T12:55:40.170520Z"
    }
   },
   "source": [
    "$$y = 1.2x - 3.4x^2 + 5.6x^3 + 5 + \\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T13:21:24.048693Z",
     "start_time": "2020-10-08T13:21:23.434967Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.init as init\n",
    "sys.path.append(\"../d2l_func/\")\n",
    "from model_train import train_experiment\n",
    "from draw import set_fig_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T13:21:26.045163Z",
     "start_time": "2020-10-08T13:21:26.023283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator object at 0x7f8a6472cf50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_num = 100\n",
    "true_w = torch.tensor([1.2, -3.4, 5.6]).view(-1, 1)\n",
    "true_b = torch.tensor([5]).view(-1, 1)\n",
    "\n",
    "# 训练集和测试集数据量都是100\n",
    "torch.manual_seed(100)\n",
    "# x = torch.randn(size=data_num*2, 1)\n",
    "linear_feature = torch.normal(0, 1, size=(data_num*2, 1))\n",
    "poly_feature = torch.cat((linear_feature, linear_feature**2, linear_feature**3), dim=1)\n",
    "error = torch.normal(0, 0.01, size=(len(poly_feature), 1))\n",
    "y = torch.mm(poly_feature, true_w) + true_b + error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T13:21:26.585240Z",
     "start_time": "2020-10-08T13:21:26.575868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1268],\n",
       "        [1.3564]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.2685e-01, 1.6091e-02, 2.0411e-03],\n",
       "        [1.3564e+00, 1.8398e+00, 2.4955e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.0842],\n",
       "        [14.3357]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 看一下前两个数据样本\n",
    "linear_feature[:2]\n",
    "poly_feature[:2]\n",
    "y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正常拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T13:21:29.414671Z",
     "start_time": "2020-10-08T13:21:29.407025Z"
    }
   },
   "outputs": [],
   "source": [
    "class PolyModel(nn.Module):\n",
    "    def __init__(self, fea_num):\n",
    "        super(PolyModel, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(fea_num, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T13:21:39.994616Z",
     "start_time": "2020-10-08T13:21:35.488203Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0155,  0.0127, -0.0093]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 910.3158, train_score: -, test_loss: 191.0725, test_score: -\n",
      "\n",
      "Epoch [2/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 241.9207, train_score: -, test_loss: 65.3693, test_score: -\n",
      "\n",
      "Epoch [3/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 76.9585, train_score: -, test_loss: 32.5119, test_score: -\n",
      "\n",
      "Epoch [4/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 35.5458, train_score: -, test_loss: 23.2020, test_score: -\n",
      "\n",
      "Epoch [5/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 24.5391, train_score: -, test_loss: 20.0668, test_score: -\n",
      "\n",
      "Epoch [6/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 21.0864, train_score: -, test_loss: 18.6600, test_score: -\n",
      "\n",
      "Epoch [7/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 19.5695, train_score: -, test_loss: 17.7986, test_score: -\n",
      "\n",
      "Epoch [8/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 18.5976, train_score: -, test_loss: 17.1450, test_score: -\n",
      "\n",
      "Epoch [9/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 17.8185, train_score: -, test_loss: 16.5914, test_score: -\n",
      "\n",
      "Epoch [10/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 17.1366, train_score: -, test_loss: 16.0971, test_score: -\n",
      "\n",
      "Epoch [11/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 16.5207, train_score: -, test_loss: 15.6436, test_score: -\n",
      "\n",
      "Epoch [12/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 15.9567, train_score: -, test_loss: 15.2211, test_score: -\n",
      "\n",
      "Epoch [13/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 15.4361, train_score: -, test_loss: 14.8233, test_score: -\n",
      "\n",
      "Epoch [14/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 14.9523, train_score: -, test_loss: 14.4460, test_score: -\n",
      "\n",
      "Epoch [15/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 14.5001, train_score: -, test_loss: 14.0860, test_score: -\n",
      "\n",
      "Epoch [16/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 14.0752, train_score: -, test_loss: 13.7410, test_score: -\n",
      "\n",
      "Epoch [17/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 13.6741, train_score: -, test_loss: 13.4091, test_score: -\n",
      "\n",
      "Epoch [18/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 13.2938, train_score: -, test_loss: 13.0888, test_score: -\n",
      "\n",
      "Epoch [19/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 12.9319, train_score: -, test_loss: 12.7790, test_score: -\n",
      "\n",
      "Epoch [20/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 12.5862, train_score: -, test_loss: 12.4786, test_score: -\n",
      "\n",
      "Epoch [21/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 12.2552, train_score: -, test_loss: 12.1869, test_score: -\n",
      "\n",
      "Epoch [22/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 11.9373, train_score: -, test_loss: 11.9033, test_score: -\n",
      "\n",
      "Epoch [23/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 11.6313, train_score: -, test_loss: 11.6271, test_score: -\n",
      "\n",
      "Epoch [24/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 11.3361, train_score: -, test_loss: 11.3579, test_score: -\n",
      "\n",
      "Epoch [25/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 11.0511, train_score: -, test_loss: 11.0954, test_score: -\n",
      "\n",
      "Epoch [26/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 10.7752, train_score: -, test_loss: 10.8393, test_score: -\n",
      "\n",
      "Epoch [27/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 10.5080, train_score: -, test_loss: 10.5892, test_score: -\n",
      "\n",
      "Epoch [28/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 10.2489, train_score: -, test_loss: 10.3450, test_score: -\n",
      "\n",
      "Epoch [29/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 9.9974, train_score: -, test_loss: 10.1064, test_score: -\n",
      "\n",
      "Epoch [30/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 9.7530, train_score: -, test_loss: 9.8732, test_score: -\n",
      "\n",
      "Epoch [31/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 9.5155, train_score: -, test_loss: 9.6454, test_score: -\n",
      "\n",
      "Epoch [32/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 9.2845, train_score: -, test_loss: 9.4227, test_score: -\n",
      "\n",
      "Epoch [33/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 9.0597, train_score: -, test_loss: 9.2051, test_score: -\n",
      "\n",
      "Epoch [34/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 8.8408, train_score: -, test_loss: 8.9924, test_score: -\n",
      "\n",
      "Epoch [35/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 8.6277, train_score: -, test_loss: 8.7845, test_score: -\n",
      "\n",
      "Epoch [36/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 8.4200, train_score: -, test_loss: 8.5813, test_score: -\n",
      "\n",
      "Epoch [37/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 8.2177, train_score: -, test_loss: 8.3826, test_score: -\n",
      "\n",
      "Epoch [38/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 8.0205, train_score: -, test_loss: 8.1885, test_score: -\n",
      "\n",
      "Epoch [39/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 7.8283, train_score: -, test_loss: 7.9988, test_score: -\n",
      "\n",
      "Epoch [40/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 7.6409, train_score: -, test_loss: 7.8134, test_score: -\n",
      "\n",
      "Epoch [41/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 7.4581, train_score: -, test_loss: 7.6322, test_score: -\n",
      "\n",
      "Epoch [42/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 7.2799, train_score: -, test_loss: 7.4551, test_score: -\n",
      "\n",
      "Epoch [43/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 7.1061, train_score: -, test_loss: 7.2821, test_score: -\n",
      "\n",
      "Epoch [44/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 6.9365, train_score: -, test_loss: 7.1131, test_score: -\n",
      "\n",
      "Epoch [45/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 6.7711, train_score: -, test_loss: 6.9479, test_score: -\n",
      "\n",
      "Epoch [46/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 6.6098, train_score: -, test_loss: 6.7865, test_score: -\n",
      "\n",
      "Epoch [47/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 6.4524, train_score: -, test_loss: 6.6289, test_score: -\n",
      "\n",
      "Epoch [48/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 6.2989, train_score: -, test_loss: 6.4749, test_score: -\n",
      "\n",
      "Epoch [49/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 6.1491, train_score: -, test_loss: 6.3244, test_score: -\n",
      "\n",
      "Epoch [50/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 6.0029, train_score: -, test_loss: 6.1775, test_score: -\n",
      "\n",
      "Epoch [51/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 5.8603, train_score: -, test_loss: 6.0340, test_score: -\n",
      "\n",
      "Epoch [52/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 5.7211, train_score: -, test_loss: 5.8937, test_score: -\n",
      "\n",
      "Epoch [53/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 5.5853, train_score: -, test_loss: 5.7568, test_score: -\n",
      "\n",
      "Epoch [54/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 5.4528, train_score: -, test_loss: 5.6231, test_score: -\n",
      "\n",
      "Epoch [55/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 5.3235, train_score: -, test_loss: 5.4924, test_score: -\n",
      "\n",
      "Epoch [56/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 5.1974, train_score: -, test_loss: 5.3649, test_score: -\n",
      "\n",
      "Epoch [57/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 5.0742, train_score: -, test_loss: 5.2403, test_score: -\n",
      "\n",
      "Epoch [58/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 4.9541, train_score: -, test_loss: 5.1186, test_score: -\n",
      "\n",
      "Epoch [59/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 4.8369, train_score: -, test_loss: 4.9998, test_score: -\n",
      "\n",
      "Epoch [60/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 4.7224, train_score: -, test_loss: 4.8837, test_score: -\n",
      "\n",
      "Epoch [61/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 4.6108, train_score: -, test_loss: 4.7704, test_score: -\n",
      "\n",
      "Epoch [62/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 4.5018, train_score: -, test_loss: 4.6597, test_score: -\n",
      "\n",
      "Epoch [63/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 4.3955, train_score: -, test_loss: 4.5517, test_score: -\n",
      "\n",
      "Epoch [64/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 4.2917, train_score: -, test_loss: 4.4461, test_score: -\n",
      "\n",
      "Epoch [65/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 4.1904, train_score: -, test_loss: 4.3431, test_score: -\n",
      "\n",
      "Epoch [66/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 4.0915, train_score: -, test_loss: 4.2424, test_score: -\n",
      "\n",
      "Epoch [67/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 3.9951, train_score: -, test_loss: 4.1442, test_score: -\n",
      "\n",
      "Epoch [68/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 3.9009, train_score: -, test_loss: 4.0482, test_score: -\n",
      "\n",
      "Epoch [69/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 3.8090, train_score: -, test_loss: 3.9545, test_score: -\n",
      "\n",
      "Epoch [70/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 3.7194, train_score: -, test_loss: 3.8630, test_score: -\n",
      "\n",
      "Epoch [71/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 3.6318, train_score: -, test_loss: 3.7737, test_score: -\n",
      "\n",
      "Epoch [72/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 3.5464, train_score: -, test_loss: 3.6864, test_score: -\n",
      "\n",
      "Epoch [73/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 3.4630, train_score: -, test_loss: 3.6012, test_score: -\n",
      "\n",
      "Epoch [74/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 3.3817, train_score: -, test_loss: 3.5180, test_score: -\n",
      "\n",
      "Epoch [75/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 3.3022, train_score: -, test_loss: 3.4368, test_score: -\n",
      "\n",
      "Epoch [76/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 3.2247, train_score: -, test_loss: 3.3575, test_score: -\n",
      "\n",
      "Epoch [77/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 3.1490, train_score: -, test_loss: 3.2800, test_score: -\n",
      "\n",
      "Epoch [78/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 3.0752, train_score: -, test_loss: 3.2044, test_score: -\n",
      "\n",
      "Epoch [79/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 3.0031, train_score: -, test_loss: 3.1305, test_score: -\n",
      "\n",
      "Epoch [80/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.9328, train_score: -, test_loss: 3.0584, test_score: -\n",
      "\n",
      "Epoch [81/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.8641, train_score: -, test_loss: 2.9880, test_score: -\n",
      "\n",
      "Epoch [82/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.7971, train_score: -, test_loss: 2.9192, test_score: -\n",
      "\n",
      "Epoch [83/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.7316, train_score: -, test_loss: 2.8520, test_score: -\n",
      "\n",
      "Epoch [84/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.6678, train_score: -, test_loss: 2.7864, test_score: -\n",
      "\n",
      "Epoch [85/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.6054, train_score: -, test_loss: 2.7224, test_score: -\n",
      "\n",
      "Epoch [86/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.5446, train_score: -, test_loss: 2.6599, test_score: -\n",
      "\n",
      "Epoch [87/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.4852, train_score: -, test_loss: 2.5988, test_score: -\n",
      "\n",
      "Epoch [88/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.4272, train_score: -, test_loss: 2.5391, test_score: -\n",
      "\n",
      "Epoch [89/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.3706, train_score: -, test_loss: 2.4809, test_score: -\n",
      "\n",
      "Epoch [90/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.3154, train_score: -, test_loss: 2.4240, test_score: -\n",
      "\n",
      "Epoch [91/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.2614, train_score: -, test_loss: 2.3685, test_score: -\n",
      "\n",
      "Epoch [92/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.2088, train_score: -, test_loss: 2.3142, test_score: -\n",
      "\n",
      "Epoch [93/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.1574, train_score: -, test_loss: 2.2612, test_score: -\n",
      "\n",
      "Epoch [94/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.1072, train_score: -, test_loss: 2.2095, test_score: -\n",
      "\n",
      "Epoch [95/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.0583, train_score: -, test_loss: 2.1590, test_score: -\n",
      "\n",
      "Epoch [96/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.0105, train_score: -, test_loss: 2.1096, test_score: -\n",
      "\n",
      "Epoch [97/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.9638, train_score: -, test_loss: 2.0615, test_score: -\n",
      "\n",
      "Epoch [98/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.9182, train_score: -, test_loss: 2.0144, test_score: -\n",
      "\n",
      "Epoch [99/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.8738, train_score: -, test_loss: 1.9684, test_score: -\n",
      "\n",
      "Epoch [100/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.8303, train_score: -, test_loss: 1.9235, test_score: -\n",
      "\n",
      "Epoch [101/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.7880, train_score: -, test_loss: 1.8797, test_score: -\n",
      "\n",
      "Epoch [102/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.7466, train_score: -, test_loss: 1.8369, test_score: -\n",
      "\n",
      "Epoch [103/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.7062, train_score: -, test_loss: 1.7951, test_score: -\n",
      "\n",
      "Epoch [104/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.6667, train_score: -, test_loss: 1.7542, test_score: -\n",
      "\n",
      "Epoch [105/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.6282, train_score: -, test_loss: 1.7143, test_score: -\n",
      "\n",
      "Epoch [106/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.5906, train_score: -, test_loss: 1.6754, test_score: -\n",
      "\n",
      "Epoch [107/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.5539, train_score: -, test_loss: 1.6373, test_score: -\n",
      "\n",
      "Epoch [108/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.5181, train_score: -, test_loss: 1.6001, test_score: -\n",
      "\n",
      "Epoch [109/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.4831, train_score: -, test_loss: 1.5638, test_score: -\n",
      "\n",
      "Epoch [110/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.4489, train_score: -, test_loss: 1.5284, test_score: -\n",
      "\n",
      "Epoch [111/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.4156, train_score: -, test_loss: 1.4937, test_score: -\n",
      "\n",
      "Epoch [112/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.3830, train_score: -, test_loss: 1.4599, test_score: -\n",
      "\n",
      "Epoch [113/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.3512, train_score: -, test_loss: 1.4268, test_score: -\n",
      "\n",
      "Epoch [114/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.3202, train_score: -, test_loss: 1.3946, test_score: -\n",
      "\n",
      "Epoch [115/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.2899, train_score: -, test_loss: 1.3630, test_score: -\n",
      "\n",
      "Epoch [116/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.2603, train_score: -, test_loss: 1.3322, test_score: -\n",
      "\n",
      "Epoch [117/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.2314, train_score: -, test_loss: 1.3022, test_score: -\n",
      "\n",
      "Epoch [118/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.2031, train_score: -, test_loss: 1.2728, test_score: -\n",
      "\n",
      "Epoch [119/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.1756, train_score: -, test_loss: 1.2441, test_score: -\n",
      "\n",
      "Epoch [120/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.1487, train_score: -, test_loss: 1.2160, test_score: -\n",
      "\n",
      "Epoch [121/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.1224, train_score: -, test_loss: 1.1886, test_score: -\n",
      "\n",
      "Epoch [122/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.0967, train_score: -, test_loss: 1.1619, test_score: -\n",
      "\n",
      "Epoch [123/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.0717, train_score: -, test_loss: 1.1357, test_score: -\n",
      "\n",
      "Epoch [124/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.0472, train_score: -, test_loss: 1.1102, test_score: -\n",
      "\n",
      "Epoch [125/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.0233, train_score: -, test_loss: 1.0852, test_score: -\n",
      "\n",
      "Epoch [126/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.0000, train_score: -, test_loss: 1.0609, test_score: -\n",
      "\n",
      "Epoch [127/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.9772, train_score: -, test_loss: 1.0371, test_score: -\n",
      "\n",
      "Epoch [128/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.9550, train_score: -, test_loss: 1.0138, test_score: -\n",
      "\n",
      "Epoch [129/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.9333, train_score: -, test_loss: 0.9911, test_score: -\n",
      "\n",
      "Epoch [130/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.9120, train_score: -, test_loss: 0.9689, test_score: -\n",
      "\n",
      "Epoch [131/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.8913, train_score: -, test_loss: 0.9472, test_score: -\n",
      "\n",
      "Epoch [132/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.8711, train_score: -, test_loss: 0.9260, test_score: -\n",
      "\n",
      "Epoch [133/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.8513, train_score: -, test_loss: 0.9053, test_score: -\n",
      "\n",
      "Epoch [134/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.8320, train_score: -, test_loss: 0.8851, test_score: -\n",
      "\n",
      "Epoch [135/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.8132, train_score: -, test_loss: 0.8653, test_score: -\n",
      "\n",
      "Epoch [136/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.7948, train_score: -, test_loss: 0.8460, test_score: -\n",
      "\n",
      "Epoch [137/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.7768, train_score: -, test_loss: 0.8271, test_score: -\n",
      "\n",
      "Epoch [138/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.7592, train_score: -, test_loss: 0.8087, test_score: -\n",
      "\n",
      "Epoch [139/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.7421, train_score: -, test_loss: 0.7907, test_score: -\n",
      "\n",
      "Epoch [140/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.7253, train_score: -, test_loss: 0.7731, test_score: -\n",
      "\n",
      "Epoch [141/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.7090, train_score: -, test_loss: 0.7559, test_score: -\n",
      "\n",
      "Epoch [142/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.6930, train_score: -, test_loss: 0.7391, test_score: -\n",
      "\n",
      "Epoch [143/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.6774, train_score: -, test_loss: 0.7227, test_score: -\n",
      "\n",
      "Epoch [144/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.6622, train_score: -, test_loss: 0.7067, test_score: -\n",
      "\n",
      "Epoch [145/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.6473, train_score: -, test_loss: 0.6910, test_score: -\n",
      "\n",
      "Epoch [146/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.6327, train_score: -, test_loss: 0.6757, test_score: -\n",
      "\n",
      "Epoch [147/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.6185, train_score: -, test_loss: 0.6607, test_score: -\n",
      "\n",
      "Epoch [148/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.6046, train_score: -, test_loss: 0.6461, test_score: -\n",
      "\n",
      "Epoch [149/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.5911, train_score: -, test_loss: 0.6318, test_score: -\n",
      "\n",
      "Epoch [150/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.5778, train_score: -, test_loss: 0.6178, test_score: -\n",
      "\n",
      "Epoch [151/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.5649, train_score: -, test_loss: 0.6042, test_score: -\n",
      "\n",
      "Epoch [152/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.5523, train_score: -, test_loss: 0.5908, test_score: -\n",
      "\n",
      "Epoch [153/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.5399, train_score: -, test_loss: 0.5778, test_score: -\n",
      "\n",
      "Epoch [154/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.5279, train_score: -, test_loss: 0.5651, test_score: -\n",
      "\n",
      "Epoch [155/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.5161, train_score: -, test_loss: 0.5526, test_score: -\n",
      "\n",
      "Epoch [156/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.5046, train_score: -, test_loss: 0.5405, test_score: -\n",
      "\n",
      "Epoch [157/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.4933, train_score: -, test_loss: 0.5286, test_score: -\n",
      "\n",
      "Epoch [158/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.4824, train_score: -, test_loss: 0.5170, test_score: -\n",
      "\n",
      "Epoch [159/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.4716, train_score: -, test_loss: 0.5056, test_score: -\n",
      "\n",
      "Epoch [160/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.4611, train_score: -, test_loss: 0.4945, test_score: -\n",
      "\n",
      "Epoch [161/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.4509, train_score: -, test_loss: 0.4837, test_score: -\n",
      "\n",
      "Epoch [162/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.4409, train_score: -, test_loss: 0.4731, test_score: -\n",
      "\n",
      "Epoch [163/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.4311, train_score: -, test_loss: 0.4627, test_score: -\n",
      "\n",
      "Epoch [164/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.4216, train_score: -, test_loss: 0.4526, test_score: -\n",
      "\n",
      "Epoch [165/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.4122, train_score: -, test_loss: 0.4427, test_score: -\n",
      "\n",
      "Epoch [166/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.4031, train_score: -, test_loss: 0.4330, test_score: -\n",
      "\n",
      "Epoch [167/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.3942, train_score: -, test_loss: 0.4236, test_score: -\n",
      "\n",
      "Epoch [168/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.3855, train_score: -, test_loss: 0.4143, test_score: -\n",
      "\n",
      "Epoch [169/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.3770, train_score: -, test_loss: 0.4053, test_score: -\n",
      "\n",
      "Epoch [170/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.3687, train_score: -, test_loss: 0.3965, test_score: -\n",
      "\n",
      "Epoch [171/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.3606, train_score: -, test_loss: 0.3878, test_score: -\n",
      "\n",
      "Epoch [172/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.3527, train_score: -, test_loss: 0.3794, test_score: -\n",
      "\n",
      "Epoch [173/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.3449, train_score: -, test_loss: 0.3711, test_score: -\n",
      "\n",
      "Epoch [174/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.3373, train_score: -, test_loss: 0.3631, test_score: -\n",
      "\n",
      "Epoch [175/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.3299, train_score: -, test_loss: 0.3552, test_score: -\n",
      "\n",
      "Epoch [176/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.3227, train_score: -, test_loss: 0.3475, test_score: -\n",
      "\n",
      "Epoch [177/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.3156, train_score: -, test_loss: 0.3400, test_score: -\n",
      "\n",
      "Epoch [178/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.3087, train_score: -, test_loss: 0.3326, test_score: -\n",
      "\n",
      "Epoch [179/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.3020, train_score: -, test_loss: 0.3254, test_score: -\n",
      "\n",
      "Epoch [180/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2954, train_score: -, test_loss: 0.3184, test_score: -\n",
      "\n",
      "Epoch [181/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2889, train_score: -, test_loss: 0.3115, test_score: -\n",
      "\n",
      "Epoch [182/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2826, train_score: -, test_loss: 0.3048, test_score: -\n",
      "\n",
      "Epoch [183/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2764, train_score: -, test_loss: 0.2982, test_score: -\n",
      "\n",
      "Epoch [184/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2704, train_score: -, test_loss: 0.2918, test_score: -\n",
      "\n",
      "Epoch [185/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2645, train_score: -, test_loss: 0.2855, test_score: -\n",
      "\n",
      "Epoch [186/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2588, train_score: -, test_loss: 0.2793, test_score: -\n",
      "\n",
      "Epoch [187/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2532, train_score: -, test_loss: 0.2733, test_score: -\n",
      "\n",
      "Epoch [188/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2477, train_score: -, test_loss: 0.2675, test_score: -\n",
      "\n",
      "Epoch [189/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2423, train_score: -, test_loss: 0.2617, test_score: -\n",
      "\n",
      "Epoch [190/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2371, train_score: -, test_loss: 0.2561, test_score: -\n",
      "\n",
      "Epoch [191/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2319, train_score: -, test_loss: 0.2506, test_score: -\n",
      "\n",
      "Epoch [192/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2269, train_score: -, test_loss: 0.2453, test_score: -\n",
      "\n",
      "Epoch [193/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2220, train_score: -, test_loss: 0.2400, test_score: -\n",
      "\n",
      "Epoch [194/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2172, train_score: -, test_loss: 0.2349, test_score: -\n",
      "\n",
      "Epoch [195/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2126, train_score: -, test_loss: 0.2299, test_score: -\n",
      "\n",
      "Epoch [196/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2080, train_score: -, test_loss: 0.2249, test_score: -\n",
      "\n",
      "Epoch [197/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2035, train_score: -, test_loss: 0.2201, test_score: -\n",
      "\n",
      "Epoch [198/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1991, train_score: -, test_loss: 0.2155, test_score: -\n",
      "\n",
      "Epoch [199/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1949, train_score: -, test_loss: 0.2109, test_score: -\n",
      "\n",
      "Epoch [200/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1907, train_score: -, test_loss: 0.2064, test_score: -\n",
      "\n",
      "Epoch [201/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1866, train_score: -, test_loss: 0.2020, test_score: -\n",
      "\n",
      "Epoch [202/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1826, train_score: -, test_loss: 0.1977, test_score: -\n",
      "\n",
      "Epoch [203/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1787, train_score: -, test_loss: 0.1935, test_score: -\n",
      "\n",
      "Epoch [204/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1749, train_score: -, test_loss: 0.1894, test_score: -\n",
      "\n",
      "Epoch [205/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1711, train_score: -, test_loss: 0.1854, test_score: -\n",
      "\n",
      "Epoch [206/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1675, train_score: -, test_loss: 0.1815, test_score: -\n",
      "\n",
      "Epoch [207/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1639, train_score: -, test_loss: 0.1776, test_score: -\n",
      "\n",
      "Epoch [208/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1604, train_score: -, test_loss: 0.1739, test_score: -\n",
      "\n",
      "Epoch [209/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1570, train_score: -, test_loss: 0.1702, test_score: -\n",
      "\n",
      "Epoch [210/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1537, train_score: -, test_loss: 0.1666, test_score: -\n",
      "\n",
      "Epoch [211/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1504, train_score: -, test_loss: 0.1631, test_score: -\n",
      "\n",
      "Epoch [212/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1472, train_score: -, test_loss: 0.1596, test_score: -\n",
      "\n",
      "Epoch [213/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1441, train_score: -, test_loss: 0.1563, test_score: -\n",
      "\n",
      "Epoch [214/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1411, train_score: -, test_loss: 0.1530, test_score: -\n",
      "\n",
      "Epoch [215/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1381, train_score: -, test_loss: 0.1498, test_score: -\n",
      "\n",
      "Epoch [216/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1352, train_score: -, test_loss: 0.1466, test_score: -\n",
      "\n",
      "Epoch [217/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1323, train_score: -, test_loss: 0.1436, test_score: -\n",
      "\n",
      "Epoch [218/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1295, train_score: -, test_loss: 0.1405, test_score: -\n",
      "\n",
      "Epoch [219/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1268, train_score: -, test_loss: 0.1376, test_score: -\n",
      "\n",
      "Epoch [220/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1241, train_score: -, test_loss: 0.1347, test_score: -\n",
      "\n",
      "Epoch [221/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1215, train_score: -, test_loss: 0.1319, test_score: -\n",
      "\n",
      "Epoch [222/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1190, train_score: -, test_loss: 0.1291, test_score: -\n",
      "\n",
      "Epoch [223/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1165, train_score: -, test_loss: 0.1265, test_score: -\n",
      "\n",
      "Epoch [224/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1140, train_score: -, test_loss: 0.1238, test_score: -\n",
      "\n",
      "Epoch [225/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1116, train_score: -, test_loss: 0.1212, test_score: -\n",
      "\n",
      "Epoch [226/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1093, train_score: -, test_loss: 0.1187, test_score: -\n",
      "\n",
      "Epoch [227/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1070, train_score: -, test_loss: 0.1162, test_score: -\n",
      "\n",
      "Epoch [228/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1048, train_score: -, test_loss: 0.1138, test_score: -\n",
      "\n",
      "Epoch [229/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1026, train_score: -, test_loss: 0.1115, test_score: -\n",
      "\n",
      "Epoch [230/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1005, train_score: -, test_loss: 0.1091, test_score: -\n",
      "\n",
      "Epoch [231/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0984, train_score: -, test_loss: 0.1069, test_score: -\n",
      "\n",
      "Epoch [232/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0963, train_score: -, test_loss: 0.1047, test_score: -\n",
      "\n",
      "Epoch [233/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0943, train_score: -, test_loss: 0.1025, test_score: -\n",
      "\n",
      "Epoch [234/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0924, train_score: -, test_loss: 0.1004, test_score: -\n",
      "\n",
      "Epoch [235/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0905, train_score: -, test_loss: 0.0983, test_score: -\n",
      "\n",
      "Epoch [236/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0886, train_score: -, test_loss: 0.0963, test_score: -\n",
      "\n",
      "Epoch [237/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0868, train_score: -, test_loss: 0.0943, test_score: -\n",
      "\n",
      "Epoch [238/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0850, train_score: -, test_loss: 0.0923, test_score: -\n",
      "\n",
      "Epoch [239/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0832, train_score: -, test_loss: 0.0904, test_score: -\n",
      "\n",
      "Epoch [240/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0815, train_score: -, test_loss: 0.0886, test_score: -\n",
      "\n",
      "Epoch [241/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0798, train_score: -, test_loss: 0.0868, test_score: -\n",
      "\n",
      "Epoch [242/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0782, train_score: -, test_loss: 0.0850, test_score: -\n",
      "\n",
      "Epoch [243/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0766, train_score: -, test_loss: 0.0832, test_score: -\n",
      "\n",
      "Epoch [244/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0750, train_score: -, test_loss: 0.0815, test_score: -\n",
      "\n",
      "Epoch [245/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0735, train_score: -, test_loss: 0.0799, test_score: -\n",
      "\n",
      "Epoch [246/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0720, train_score: -, test_loss: 0.0782, test_score: -\n",
      "\n",
      "Epoch [247/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0705, train_score: -, test_loss: 0.0766, test_score: -\n",
      "\n",
      "Epoch [248/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0691, train_score: -, test_loss: 0.0751, test_score: -\n",
      "\n",
      "Epoch [249/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0676, train_score: -, test_loss: 0.0735, test_score: -\n",
      "\n",
      "Epoch [250/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0663, train_score: -, test_loss: 0.0720, test_score: -\n",
      "\n",
      "Epoch [251/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0649, train_score: -, test_loss: 0.0706, test_score: -\n",
      "\n",
      "Epoch [252/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0636, train_score: -, test_loss: 0.0691, test_score: -\n",
      "\n",
      "Epoch [253/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0623, train_score: -, test_loss: 0.0677, test_score: -\n",
      "\n",
      "Epoch [254/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0610, train_score: -, test_loss: 0.0663, test_score: -\n",
      "\n",
      "Epoch [255/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0598, train_score: -, test_loss: 0.0650, test_score: -\n",
      "\n",
      "Epoch [256/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0586, train_score: -, test_loss: 0.0637, test_score: -\n",
      "\n",
      "Epoch [257/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0574, train_score: -, test_loss: 0.0624, test_score: -\n",
      "\n",
      "Epoch [258/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0562, train_score: -, test_loss: 0.0611, test_score: -\n",
      "\n",
      "Epoch [259/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0551, train_score: -, test_loss: 0.0599, test_score: -\n",
      "\n",
      "Epoch [260/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0540, train_score: -, test_loss: 0.0587, test_score: -\n",
      "\n",
      "Epoch [261/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0529, train_score: -, test_loss: 0.0575, test_score: -\n",
      "\n",
      "Epoch [262/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0518, train_score: -, test_loss: 0.0563, test_score: -\n",
      "\n",
      "Epoch [263/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0508, train_score: -, test_loss: 0.0552, test_score: -\n",
      "\n",
      "Epoch [264/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0498, train_score: -, test_loss: 0.0541, test_score: -\n",
      "\n",
      "Epoch [265/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0488, train_score: -, test_loss: 0.0530, test_score: -\n",
      "\n",
      "Epoch [266/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0478, train_score: -, test_loss: 0.0519, test_score: -\n",
      "\n",
      "Epoch [267/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0469, train_score: -, test_loss: 0.0509, test_score: -\n",
      "\n",
      "Epoch [268/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0459, train_score: -, test_loss: 0.0499, test_score: -\n",
      "\n",
      "Epoch [269/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0450, train_score: -, test_loss: 0.0489, test_score: -\n",
      "\n",
      "Epoch [270/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0441, train_score: -, test_loss: 0.0479, test_score: -\n",
      "\n",
      "Epoch [271/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0432, train_score: -, test_loss: 0.0469, test_score: -\n",
      "\n",
      "Epoch [272/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0424, train_score: -, test_loss: 0.0460, test_score: -\n",
      "\n",
      "Epoch [273/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0415, train_score: -, test_loss: 0.0451, test_score: -\n",
      "\n",
      "Epoch [274/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0407, train_score: -, test_loss: 0.0442, test_score: -\n",
      "\n",
      "Epoch [275/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0399, train_score: -, test_loss: 0.0433, test_score: -\n",
      "\n",
      "Epoch [276/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0391, train_score: -, test_loss: 0.0424, test_score: -\n",
      "\n",
      "Epoch [277/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0383, train_score: -, test_loss: 0.0416, test_score: -\n",
      "\n",
      "Epoch [278/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0376, train_score: -, test_loss: 0.0408, test_score: -\n",
      "\n",
      "Epoch [279/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0368, train_score: -, test_loss: 0.0399, test_score: -\n",
      "\n",
      "Epoch [280/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0361, train_score: -, test_loss: 0.0391, test_score: -\n",
      "\n",
      "Epoch [281/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0354, train_score: -, test_loss: 0.0384, test_score: -\n",
      "\n",
      "Epoch [282/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0347, train_score: -, test_loss: 0.0376, test_score: -\n",
      "\n",
      "Epoch [283/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0340, train_score: -, test_loss: 0.0369, test_score: -\n",
      "\n",
      "Epoch [284/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0333, train_score: -, test_loss: 0.0361, test_score: -\n",
      "\n",
      "Epoch [285/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0327, train_score: -, test_loss: 0.0354, test_score: -\n",
      "\n",
      "Epoch [286/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0320, train_score: -, test_loss: 0.0347, test_score: -\n",
      "\n",
      "Epoch [287/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0314, train_score: -, test_loss: 0.0340, test_score: -\n",
      "\n",
      "Epoch [288/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0308, train_score: -, test_loss: 0.0334, test_score: -\n",
      "\n",
      "Epoch [289/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0302, train_score: -, test_loss: 0.0327, test_score: -\n",
      "\n",
      "Epoch [290/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0296, train_score: -, test_loss: 0.0321, test_score: -\n",
      "\n",
      "Epoch [291/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0290, train_score: -, test_loss: 0.0314, test_score: -\n",
      "\n",
      "Epoch [292/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0285, train_score: -, test_loss: 0.0308, test_score: -\n",
      "\n",
      "Epoch [293/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0279, train_score: -, test_loss: 0.0302, test_score: -\n",
      "\n",
      "Epoch [294/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0274, train_score: -, test_loss: 0.0296, test_score: -\n",
      "\n",
      "Epoch [295/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0268, train_score: -, test_loss: 0.0290, test_score: -\n",
      "\n",
      "Epoch [296/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0263, train_score: -, test_loss: 0.0285, test_score: -\n",
      "\n",
      "Epoch [297/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0258, train_score: -, test_loss: 0.0279, test_score: -\n",
      "\n",
      "Epoch [298/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0253, train_score: -, test_loss: 0.0274, test_score: -\n",
      "\n",
      "Epoch [299/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0248, train_score: -, test_loss: 0.0268, test_score: -\n",
      "\n",
      "Epoch [300/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0243, train_score: -, test_loss: 0.0263, test_score: -\n",
      "\n",
      "Epoch [301/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0239, train_score: -, test_loss: 0.0258, test_score: -\n",
      "\n",
      "Epoch [302/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0234, train_score: -, test_loss: 0.0253, test_score: -\n",
      "\n",
      "Epoch [303/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0230, train_score: -, test_loss: 0.0248, test_score: -\n",
      "\n",
      "Epoch [304/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0225, train_score: -, test_loss: 0.0243, test_score: -\n",
      "\n",
      "Epoch [305/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0221, train_score: -, test_loss: 0.0238, test_score: -\n",
      "\n",
      "Epoch [306/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0217, train_score: -, test_loss: 0.0234, test_score: -\n",
      "\n",
      "Epoch [307/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0213, train_score: -, test_loss: 0.0229, test_score: -\n",
      "\n",
      "Epoch [308/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0209, train_score: -, test_loss: 0.0225, test_score: -\n",
      "\n",
      "Epoch [309/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0205, train_score: -, test_loss: 0.0221, test_score: -\n",
      "\n",
      "Epoch [310/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0201, train_score: -, test_loss: 0.0216, test_score: -\n",
      "\n",
      "Epoch [311/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0197, train_score: -, test_loss: 0.0212, test_score: -\n",
      "\n",
      "Epoch [312/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0193, train_score: -, test_loss: 0.0208, test_score: -\n",
      "\n",
      "Epoch [313/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0189, train_score: -, test_loss: 0.0204, test_score: -\n",
      "\n",
      "Epoch [314/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0186, train_score: -, test_loss: 0.0200, test_score: -\n",
      "\n",
      "Epoch [315/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0182, train_score: -, test_loss: 0.0196, test_score: -\n",
      "\n",
      "Epoch [316/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0179, train_score: -, test_loss: 0.0192, test_score: -\n",
      "\n",
      "Epoch [317/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0175, train_score: -, test_loss: 0.0189, test_score: -\n",
      "\n",
      "Epoch [318/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0172, train_score: -, test_loss: 0.0185, test_score: -\n",
      "\n",
      "Epoch [319/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0169, train_score: -, test_loss: 0.0182, test_score: -\n",
      "\n",
      "Epoch [320/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0166, train_score: -, test_loss: 0.0178, test_score: -\n",
      "\n",
      "Epoch [321/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0163, train_score: -, test_loss: 0.0175, test_score: -\n",
      "\n",
      "Epoch [322/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0160, train_score: -, test_loss: 0.0171, test_score: -\n",
      "\n",
      "Epoch [323/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0157, train_score: -, test_loss: 0.0168, test_score: -\n",
      "\n",
      "Epoch [324/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0154, train_score: -, test_loss: 0.0165, test_score: -\n",
      "\n",
      "Epoch [325/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0151, train_score: -, test_loss: 0.0162, test_score: -\n",
      "\n",
      "Epoch [326/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0148, train_score: -, test_loss: 0.0159, test_score: -\n",
      "\n",
      "Epoch [327/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0145, train_score: -, test_loss: 0.0156, test_score: -\n",
      "\n",
      "Epoch [328/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0142, train_score: -, test_loss: 0.0153, test_score: -\n",
      "\n",
      "Epoch [329/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0140, train_score: -, test_loss: 0.0150, test_score: -\n",
      "\n",
      "Epoch [330/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0137, train_score: -, test_loss: 0.0147, test_score: -\n",
      "\n",
      "Epoch [331/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0135, train_score: -, test_loss: 0.0144, test_score: -\n",
      "\n",
      "Epoch [332/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0132, train_score: -, test_loss: 0.0141, test_score: -\n",
      "\n",
      "Epoch [333/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0130, train_score: -, test_loss: 0.0139, test_score: -\n",
      "\n",
      "Epoch [334/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0127, train_score: -, test_loss: 0.0136, test_score: -\n",
      "\n",
      "Epoch [335/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0125, train_score: -, test_loss: 0.0133, test_score: -\n",
      "\n",
      "Epoch [336/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0123, train_score: -, test_loss: 0.0131, test_score: -\n",
      "\n",
      "Epoch [337/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0120, train_score: -, test_loss: 0.0128, test_score: -\n",
      "\n",
      "Epoch [338/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0118, train_score: -, test_loss: 0.0126, test_score: -\n",
      "\n",
      "Epoch [339/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0116, train_score: -, test_loss: 0.0124, test_score: -\n",
      "\n",
      "Epoch [340/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0114, train_score: -, test_loss: 0.0121, test_score: -\n",
      "\n",
      "Epoch [341/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0112, train_score: -, test_loss: 0.0119, test_score: -\n",
      "\n",
      "Epoch [342/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0110, train_score: -, test_loss: 0.0117, test_score: -\n",
      "\n",
      "Epoch [343/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0108, train_score: -, test_loss: 0.0115, test_score: -\n",
      "\n",
      "Epoch [344/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0106, train_score: -, test_loss: 0.0112, test_score: -\n",
      "\n",
      "Epoch [345/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0104, train_score: -, test_loss: 0.0110, test_score: -\n",
      "\n",
      "Epoch [346/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0102, train_score: -, test_loss: 0.0108, test_score: -\n",
      "\n",
      "Epoch [347/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0100, train_score: -, test_loss: 0.0106, test_score: -\n",
      "\n",
      "Epoch [348/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0098, train_score: -, test_loss: 0.0104, test_score: -\n",
      "\n",
      "Epoch [349/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0096, train_score: -, test_loss: 0.0102, test_score: -\n",
      "\n",
      "Epoch [350/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0095, train_score: -, test_loss: 0.0100, test_score: -\n",
      "\n",
      "Epoch [351/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0093, train_score: -, test_loss: 0.0099, test_score: -\n",
      "\n",
      "Epoch [352/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0091, train_score: -, test_loss: 0.0097, test_score: -\n",
      "\n",
      "Epoch [353/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0089, train_score: -, test_loss: 0.0095, test_score: -\n",
      "\n",
      "Epoch [354/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0088, train_score: -, test_loss: 0.0093, test_score: -\n",
      "\n",
      "Epoch [355/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0086, train_score: -, test_loss: 0.0091, test_score: -\n",
      "\n",
      "Epoch [356/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0085, train_score: -, test_loss: 0.0090, test_score: -\n",
      "\n",
      "Epoch [357/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0083, train_score: -, test_loss: 0.0088, test_score: -\n",
      "\n",
      "Epoch [358/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0082, train_score: -, test_loss: 0.0086, test_score: -\n",
      "\n",
      "Epoch [359/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0080, train_score: -, test_loss: 0.0085, test_score: -\n",
      "\n",
      "Epoch [360/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0079, train_score: -, test_loss: 0.0083, test_score: -\n",
      "\n",
      "Epoch [361/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0077, train_score: -, test_loss: 0.0082, test_score: -\n",
      "\n",
      "Epoch [362/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0076, train_score: -, test_loss: 0.0080, test_score: -\n",
      "\n",
      "Epoch [363/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0075, train_score: -, test_loss: 0.0079, test_score: -\n",
      "\n",
      "Epoch [364/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0073, train_score: -, test_loss: 0.0077, test_score: -\n",
      "\n",
      "Epoch [365/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0072, train_score: -, test_loss: 0.0076, test_score: -\n",
      "\n",
      "Epoch [366/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0071, train_score: -, test_loss: 0.0074, test_score: -\n",
      "\n",
      "Epoch [367/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0069, train_score: -, test_loss: 0.0073, test_score: -\n",
      "\n",
      "Epoch [368/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0068, train_score: -, test_loss: 0.0072, test_score: -\n",
      "\n",
      "Epoch [369/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0067, train_score: -, test_loss: 0.0070, test_score: -\n",
      "\n",
      "Epoch [370/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0066, train_score: -, test_loss: 0.0069, test_score: -\n",
      "\n",
      "Epoch [371/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0065, train_score: -, test_loss: 0.0068, test_score: -\n",
      "\n",
      "Epoch [372/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0063, train_score: -, test_loss: 0.0067, test_score: -\n",
      "\n",
      "Epoch [373/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0062, train_score: -, test_loss: 0.0065, test_score: -\n",
      "\n",
      "Epoch [374/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0061, train_score: -, test_loss: 0.0064, test_score: -\n",
      "\n",
      "Epoch [375/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0060, train_score: -, test_loss: 0.0063, test_score: -\n",
      "\n",
      "Epoch [376/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0059, train_score: -, test_loss: 0.0062, test_score: -\n",
      "\n",
      "Epoch [377/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0058, train_score: -, test_loss: 0.0061, test_score: -\n",
      "\n",
      "Epoch [378/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0057, train_score: -, test_loss: 0.0060, test_score: -\n",
      "\n",
      "Epoch [379/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0056, train_score: -, test_loss: 0.0059, test_score: -\n",
      "\n",
      "Epoch [380/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0055, train_score: -, test_loss: 0.0057, test_score: -\n",
      "\n",
      "Epoch [381/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0054, train_score: -, test_loss: 0.0056, test_score: -\n",
      "\n",
      "Epoch [382/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0053, train_score: -, test_loss: 0.0055, test_score: -\n",
      "\n",
      "Epoch [383/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0052, train_score: -, test_loss: 0.0054, test_score: -\n",
      "\n",
      "Epoch [384/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0051, train_score: -, test_loss: 0.0053, test_score: -\n",
      "\n",
      "Epoch [385/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0050, train_score: -, test_loss: 0.0052, test_score: -\n",
      "\n",
      "Epoch [386/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0049, train_score: -, test_loss: 0.0052, test_score: -\n",
      "\n",
      "Epoch [387/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0049, train_score: -, test_loss: 0.0051, test_score: -\n",
      "\n",
      "Epoch [388/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0048, train_score: -, test_loss: 0.0050, test_score: -\n",
      "\n",
      "Epoch [389/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0047, train_score: -, test_loss: 0.0049, test_score: -\n",
      "\n",
      "Epoch [390/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0046, train_score: -, test_loss: 0.0048, test_score: -\n",
      "\n",
      "Epoch [391/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0045, train_score: -, test_loss: 0.0047, test_score: -\n",
      "\n",
      "Epoch [392/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0044, train_score: -, test_loss: 0.0046, test_score: -\n",
      "\n",
      "Epoch [393/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0044, train_score: -, test_loss: 0.0045, test_score: -\n",
      "\n",
      "Epoch [394/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0043, train_score: -, test_loss: 0.0045, test_score: -\n",
      "\n",
      "Epoch [395/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0042, train_score: -, test_loss: 0.0044, test_score: -\n",
      "\n",
      "Epoch [396/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0041, train_score: -, test_loss: 0.0043, test_score: -\n",
      "\n",
      "Epoch [397/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0041, train_score: -, test_loss: 0.0042, test_score: -\n",
      "\n",
      "Epoch [398/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0040, train_score: -, test_loss: 0.0041, test_score: -\n",
      "\n",
      "Epoch [399/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0039, train_score: -, test_loss: 0.0041, test_score: -\n",
      "\n",
      "Epoch [400/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0039, train_score: -, test_loss: 0.0040, test_score: -\n",
      "\n",
      "Epoch [401/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0038, train_score: -, test_loss: 0.0039, test_score: -\n",
      "\n",
      "Epoch [402/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0037, train_score: -, test_loss: 0.0039, test_score: -\n",
      "\n",
      "Epoch [403/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0037, train_score: -, test_loss: 0.0038, test_score: -\n",
      "\n",
      "Epoch [404/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0036, train_score: -, test_loss: 0.0037, test_score: -\n",
      "\n",
      "Epoch [405/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0035, train_score: -, test_loss: 0.0037, test_score: -\n",
      "\n",
      "Epoch [406/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0035, train_score: -, test_loss: 0.0036, test_score: -\n",
      "\n",
      "Epoch [407/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0034, train_score: -, test_loss: 0.0035, test_score: -\n",
      "\n",
      "Epoch [408/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0034, train_score: -, test_loss: 0.0035, test_score: -\n",
      "\n",
      "Epoch [409/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0033, train_score: -, test_loss: 0.0034, test_score: -\n",
      "\n",
      "Epoch [410/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0033, train_score: -, test_loss: 0.0033, test_score: -\n",
      "\n",
      "Epoch [411/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0032, train_score: -, test_loss: 0.0033, test_score: -\n",
      "\n",
      "Epoch [412/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0031, train_score: -, test_loss: 0.0032, test_score: -\n",
      "\n",
      "Epoch [413/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0031, train_score: -, test_loss: 0.0032, test_score: -\n",
      "\n",
      "Epoch [414/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0030, train_score: -, test_loss: 0.0031, test_score: -\n",
      "\n",
      "Epoch [415/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0030, train_score: -, test_loss: 0.0031, test_score: -\n",
      "\n",
      "Epoch [416/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0029, train_score: -, test_loss: 0.0030, test_score: -\n",
      "\n",
      "Epoch [417/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0029, train_score: -, test_loss: 0.0029, test_score: -\n",
      "\n",
      "Epoch [418/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0028, train_score: -, test_loss: 0.0029, test_score: -\n",
      "\n",
      "Epoch [419/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0028, train_score: -, test_loss: 0.0028, test_score: -\n",
      "\n",
      "Epoch [420/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0027, train_score: -, test_loss: 0.0028, test_score: -\n",
      "\n",
      "Epoch [421/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0027, train_score: -, test_loss: 0.0027, test_score: -\n",
      "\n",
      "Epoch [422/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0027, train_score: -, test_loss: 0.0027, test_score: -\n",
      "\n",
      "Epoch [423/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0026, train_score: -, test_loss: 0.0027, test_score: -\n",
      "\n",
      "Epoch [424/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0026, train_score: -, test_loss: 0.0026, test_score: -\n",
      "\n",
      "Epoch [425/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0025, train_score: -, test_loss: 0.0026, test_score: -\n",
      "\n",
      "Epoch [426/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0025, train_score: -, test_loss: 0.0025, test_score: -\n",
      "\n",
      "Epoch [427/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0024, train_score: -, test_loss: 0.0025, test_score: -\n",
      "\n",
      "Epoch [428/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0024, train_score: -, test_loss: 0.0024, test_score: -\n",
      "\n",
      "Epoch [429/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0024, train_score: -, test_loss: 0.0024, test_score: -\n",
      "\n",
      "Epoch [430/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0023, train_score: -, test_loss: 0.0023, test_score: -\n",
      "\n",
      "Epoch [431/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0023, train_score: -, test_loss: 0.0023, test_score: -\n",
      "\n",
      "Epoch [432/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0022, train_score: -, test_loss: 0.0023, test_score: -\n",
      "\n",
      "Epoch [433/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0022, train_score: -, test_loss: 0.0022, test_score: -\n",
      "\n",
      "Epoch [434/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0022, train_score: -, test_loss: 0.0022, test_score: -\n",
      "\n",
      "Epoch [435/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0021, train_score: -, test_loss: 0.0021, test_score: -\n",
      "\n",
      "Epoch [436/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0021, train_score: -, test_loss: 0.0021, test_score: -\n",
      "\n",
      "Epoch [437/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0021, train_score: -, test_loss: 0.0021, test_score: -\n",
      "\n",
      "Epoch [438/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0020, train_score: -, test_loss: 0.0020, test_score: -\n",
      "\n",
      "Epoch [439/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0020, train_score: -, test_loss: 0.0020, test_score: -\n",
      "\n",
      "Epoch [440/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0020, train_score: -, test_loss: 0.0020, test_score: -\n",
      "\n",
      "Epoch [441/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0019, train_score: -, test_loss: 0.0019, test_score: -\n",
      "\n",
      "Epoch [442/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0019, train_score: -, test_loss: 0.0019, test_score: -\n",
      "\n",
      "Epoch [443/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0019, train_score: -, test_loss: 0.0019, test_score: -\n",
      "\n",
      "Epoch [444/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0018, train_score: -, test_loss: 0.0018, test_score: -\n",
      "\n",
      "Epoch [445/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0018, train_score: -, test_loss: 0.0018, test_score: -\n",
      "\n",
      "Epoch [446/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0018, train_score: -, test_loss: 0.0018, test_score: -\n",
      "\n",
      "Epoch [447/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0018, train_score: -, test_loss: 0.0017, test_score: -\n",
      "\n",
      "Epoch [448/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0017, train_score: -, test_loss: 0.0017, test_score: -\n",
      "\n",
      "Epoch [449/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0017, train_score: -, test_loss: 0.0017, test_score: -\n",
      "\n",
      "Epoch [450/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0017, train_score: -, test_loss: 0.0017, test_score: -\n",
      "\n",
      "Epoch [451/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0016, train_score: -, test_loss: 0.0016, test_score: -\n",
      "\n",
      "Epoch [452/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0016, train_score: -, test_loss: 0.0016, test_score: -\n",
      "\n",
      "Epoch [453/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0016, train_score: -, test_loss: 0.0016, test_score: -\n",
      "\n",
      "Epoch [454/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0016, train_score: -, test_loss: 0.0015, test_score: -\n",
      "\n",
      "Epoch [455/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0015, train_score: -, test_loss: 0.0015, test_score: -\n",
      "\n",
      "Epoch [456/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0015, train_score: -, test_loss: 0.0015, test_score: -\n",
      "\n",
      "Epoch [457/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0015, train_score: -, test_loss: 0.0015, test_score: -\n",
      "\n",
      "Epoch [458/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0015, train_score: -, test_loss: 0.0014, test_score: -\n",
      "\n",
      "Epoch [459/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0014, train_score: -, test_loss: 0.0014, test_score: -\n",
      "\n",
      "Epoch [460/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0014, train_score: -, test_loss: 0.0014, test_score: -\n",
      "\n",
      "Epoch [461/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0014, train_score: -, test_loss: 0.0014, test_score: -\n",
      "\n",
      "Epoch [462/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0014, train_score: -, test_loss: 0.0014, test_score: -\n",
      "\n",
      "Epoch [463/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0014, train_score: -, test_loss: 0.0013, test_score: -\n",
      "\n",
      "Epoch [464/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0013, train_score: -, test_loss: 0.0013, test_score: -\n",
      "\n",
      "Epoch [465/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0013, train_score: -, test_loss: 0.0013, test_score: -\n",
      "\n",
      "Epoch [466/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0013, train_score: -, test_loss: 0.0013, test_score: -\n",
      "\n",
      "Epoch [467/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0013, train_score: -, test_loss: 0.0012, test_score: -\n",
      "\n",
      "Epoch [468/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0013, train_score: -, test_loss: 0.0012, test_score: -\n",
      "\n",
      "Epoch [469/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0012, train_score: -, test_loss: 0.0012, test_score: -\n",
      "\n",
      "Epoch [470/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0012, train_score: -, test_loss: 0.0012, test_score: -\n",
      "\n",
      "Epoch [471/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0012, train_score: -, test_loss: 0.0012, test_score: -\n",
      "\n",
      "Epoch [472/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0012, train_score: -, test_loss: 0.0011, test_score: -\n",
      "\n",
      "Epoch [473/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0012, train_score: -, test_loss: 0.0011, test_score: -\n",
      "\n",
      "Epoch [474/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0011, train_score: -, test_loss: 0.0011, test_score: -\n",
      "\n",
      "Epoch [475/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0011, train_score: -, test_loss: 0.0011, test_score: -\n",
      "\n",
      "Epoch [476/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0011, train_score: -, test_loss: 0.0011, test_score: -\n",
      "\n",
      "Epoch [477/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0011, train_score: -, test_loss: 0.0011, test_score: -\n",
      "\n",
      "Epoch [478/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0011, train_score: -, test_loss: 0.0010, test_score: -\n",
      "\n",
      "Epoch [479/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0011, train_score: -, test_loss: 0.0010, test_score: -\n",
      "\n",
      "Epoch [480/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0010, train_score: -, test_loss: 0.0010, test_score: -\n",
      "\n",
      "Epoch [481/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0010, train_score: -, test_loss: 0.0010, test_score: -\n",
      "\n",
      "Epoch [482/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0010, train_score: -, test_loss: 0.0010, test_score: -\n",
      "\n",
      "Epoch [483/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0010, train_score: -, test_loss: 0.0010, test_score: -\n",
      "\n",
      "Epoch [484/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0010, train_score: -, test_loss: 0.0009, test_score: -\n",
      "\n",
      "Epoch [485/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0010, train_score: -, test_loss: 0.0009, test_score: -\n",
      "\n",
      "Epoch [486/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0009, train_score: -, test_loss: 0.0009, test_score: -\n",
      "\n",
      "Epoch [487/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0009, train_score: -, test_loss: 0.0009, test_score: -\n",
      "\n",
      "Epoch [488/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0009, train_score: -, test_loss: 0.0009, test_score: -\n",
      "\n",
      "Epoch [489/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0009, train_score: -, test_loss: 0.0009, test_score: -\n",
      "\n",
      "Epoch [490/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0009, train_score: -, test_loss: 0.0008, test_score: -\n",
      "\n",
      "Epoch [491/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0009, train_score: -, test_loss: 0.0008, test_score: -\n",
      "\n",
      "Epoch [492/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0009, train_score: -, test_loss: 0.0008, test_score: -\n",
      "\n",
      "Epoch [493/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0009, train_score: -, test_loss: 0.0008, test_score: -\n",
      "\n",
      "Epoch [494/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0008, train_score: -, test_loss: 0.0008, test_score: -\n",
      "\n",
      "Epoch [495/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0008, train_score: -, test_loss: 0.0008, test_score: -\n",
      "\n",
      "Epoch [496/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0008, train_score: -, test_loss: 0.0008, test_score: -\n",
      "\n",
      "Epoch [497/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0008, train_score: -, test_loss: 0.0008, test_score: -\n",
      "\n",
      "Epoch [498/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0008, train_score: -, test_loss: 0.0007, test_score: -\n",
      "\n",
      "Epoch [499/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0008, train_score: -, test_loss: 0.0007, test_score: -\n",
      "\n",
      "Epoch [500/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0008, train_score: -, test_loss: 0.0007, test_score: -\n",
      "\n",
      "Epoch [501/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0008, train_score: -, test_loss: 0.0007, test_score: -\n",
      "\n",
      "Epoch [502/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0007, train_score: -, test_loss: 0.0007, test_score: -\n",
      "\n",
      "Epoch [503/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0007, train_score: -, test_loss: 0.0007, test_score: -\n",
      "\n",
      "Epoch [504/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0007, train_score: -, test_loss: 0.0007, test_score: -\n",
      "\n",
      "Epoch [505/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0007, train_score: -, test_loss: 0.0007, test_score: -\n",
      "\n",
      "Epoch [506/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0007, train_score: -, test_loss: 0.0007, test_score: -\n",
      "\n",
      "Epoch [507/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0007, train_score: -, test_loss: 0.0006, test_score: -\n",
      "\n",
      "Epoch [508/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0007, train_score: -, test_loss: 0.0006, test_score: -\n",
      "\n",
      "Epoch [509/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0007, train_score: -, test_loss: 0.0006, test_score: -\n",
      "\n",
      "Epoch [510/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0007, train_score: -, test_loss: 0.0006, test_score: -\n",
      "\n",
      "Epoch [511/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0007, train_score: -, test_loss: 0.0006, test_score: -\n",
      "\n",
      "Epoch [512/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0006, train_score: -, test_loss: 0.0006, test_score: -\n",
      "\n",
      "Epoch [513/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0006, train_score: -, test_loss: 0.0006, test_score: -\n",
      "\n",
      "Epoch [514/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0006, train_score: -, test_loss: 0.0006, test_score: -\n",
      "\n",
      "Epoch [515/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0006, train_score: -, test_loss: 0.0006, test_score: -\n",
      "\n",
      "Epoch [516/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0006, train_score: -, test_loss: 0.0006, test_score: -\n",
      "\n",
      "Epoch [517/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0006, train_score: -, test_loss: 0.0006, test_score: -\n",
      "\n",
      "Epoch [518/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0006, train_score: -, test_loss: 0.0005, test_score: -\n",
      "\n",
      "Epoch [519/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0006, train_score: -, test_loss: 0.0005, test_score: -\n",
      "\n",
      "Epoch [520/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0006, train_score: -, test_loss: 0.0005, test_score: -\n",
      "\n",
      "Epoch [521/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0006, train_score: -, test_loss: 0.0005, test_score: -\n",
      "\n",
      "Epoch [522/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0006, train_score: -, test_loss: 0.0005, test_score: -\n",
      "\n",
      "Epoch [523/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0006, train_score: -, test_loss: 0.0005, test_score: -\n",
      "\n",
      "Epoch [524/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0005, test_score: -\n",
      "\n",
      "Epoch [525/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0005, test_score: -\n",
      "\n",
      "Epoch [526/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0005, test_score: -\n",
      "\n",
      "Epoch [527/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0005, test_score: -\n",
      "\n",
      "Epoch [528/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0005, test_score: -\n",
      "\n",
      "Epoch [529/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0005, test_score: -\n",
      "\n",
      "Epoch [530/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0005, test_score: -\n",
      "\n",
      "Epoch [531/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [532/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [533/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [534/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [535/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [536/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [537/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [538/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0005, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [539/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [540/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [541/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [542/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [543/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [544/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [545/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [546/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [547/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [548/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0004, test_score: -\n",
      "\n",
      "Epoch [549/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [550/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [551/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [552/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [553/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [554/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [555/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [556/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [557/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [558/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0004, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [559/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [560/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [561/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [562/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [563/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [564/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [565/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [566/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [567/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [568/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [569/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [570/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [571/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [572/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [573/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0003, test_score: -\n",
      "\n",
      "Epoch [574/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [575/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [576/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [577/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [578/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [579/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [580/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [581/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [582/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [583/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [584/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [585/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [586/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [587/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [588/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0003, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [589/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [590/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [591/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [592/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [593/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [594/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [595/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [596/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [597/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [598/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [599/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [600/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [601/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [602/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [603/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [604/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [605/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [606/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [607/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [608/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [609/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [610/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [611/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [612/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [613/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [614/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [615/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [616/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [617/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [618/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [619/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0002, test_score: -\n",
      "\n",
      "Epoch [620/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [621/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [622/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [623/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [624/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [625/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [626/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [627/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [628/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [629/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [630/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [631/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [632/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [633/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [634/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [635/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [636/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [637/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [638/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [639/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [640/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [641/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [642/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [643/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [644/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [645/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [646/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [647/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [648/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [649/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [650/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0002, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [651/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [652/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [653/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [654/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [655/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [656/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [657/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [658/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [659/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [660/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [661/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [662/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [663/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [664/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [665/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [666/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [667/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [668/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [669/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [670/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [671/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [672/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [673/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [674/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [675/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [676/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [677/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [678/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [679/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [680/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [681/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [682/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [683/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [684/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [685/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [686/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [687/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [688/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [689/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [690/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [691/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [692/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [693/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [694/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [695/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [696/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [697/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [698/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [699/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [700/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [701/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [702/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [703/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [704/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [705/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [706/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [707/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [708/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [709/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [710/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [711/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [712/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [713/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [714/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [715/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [716/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [717/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [718/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [719/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [720/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [721/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [722/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [723/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [724/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [725/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [726/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [727/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [728/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [729/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [730/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [731/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [732/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [733/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [734/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [735/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [736/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [737/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [738/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [739/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [740/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [741/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [742/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [743/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [744/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [745/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [746/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [747/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [748/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [749/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [750/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [751/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [752/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [753/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [754/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [755/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [756/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [757/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [758/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [759/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [760/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [761/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [762/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [763/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [764/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [765/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [766/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [767/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [768/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [769/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [770/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [771/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [772/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [773/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [774/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [775/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [776/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [777/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [778/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [779/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [780/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [781/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [782/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [783/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [784/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [785/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [786/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [787/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [788/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [789/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [790/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [791/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [792/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [793/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [794/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [795/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [796/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [797/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [798/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [799/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [800/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [801/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [802/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [803/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [804/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [805/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [806/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [807/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [808/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [809/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [810/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [811/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [812/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [813/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [814/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [815/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [816/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [817/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [818/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [819/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [820/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [821/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [822/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [823/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [824/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [825/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [826/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [827/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [828/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [829/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [830/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [831/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [832/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [833/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [834/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [835/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [836/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [837/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [838/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [839/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [840/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [841/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [842/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [843/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [844/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [845/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [846/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [847/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [848/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [849/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [850/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [851/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [852/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [853/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [854/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [855/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [856/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [857/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [858/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [859/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [860/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [861/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [862/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [863/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [864/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [865/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [866/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [867/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [868/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [869/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [870/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [871/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [872/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [873/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [874/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [875/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [876/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [877/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [878/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [879/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [880/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [881/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [882/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [883/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [884/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [885/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [886/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [887/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [888/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [889/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [890/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [891/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [892/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [893/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [894/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [895/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [896/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [897/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [898/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [899/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [900/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [901/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [902/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [903/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [904/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [905/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [906/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [907/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [908/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [909/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [910/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [911/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [912/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [913/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [914/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [915/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [916/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [917/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [918/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [919/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [920/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [921/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [922/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [923/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [924/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [925/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [926/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [927/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [928/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [929/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [930/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [931/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [932/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [933/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [934/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [935/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [936/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [937/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [938/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [939/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [940/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [941/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [942/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [943/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [944/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [945/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [946/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [947/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [948/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [949/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [950/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [951/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [952/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [953/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [954/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [955/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [956/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [957/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [958/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [959/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [960/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [961/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [962/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [963/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [964/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [965/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [966/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [967/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [968/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [969/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [970/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [971/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [972/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [973/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [974/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [975/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [976/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [977/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [978/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [979/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [980/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [981/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [982/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [983/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [984/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [985/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [986/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [987/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [988/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [989/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [990/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [991/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [992/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [993/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [994/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [995/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [996/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [997/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [998/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [999/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n",
      "Epoch [1000/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0001, train_score: -, test_loss: 0.0001, test_score: -\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"316.7pt\" version=\"1.1\" viewBox=\"0 0 611.15 316.7\" width=\"611.15pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2020-10-08T21:21:39.945960</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 316.7 \n",
       "L 611.15 316.7 \n",
       "L 611.15 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 45.95 279 \n",
       "L 603.95 279 \n",
       "L 603.95 7.2 \n",
       "L 45.95 7.2 \n",
       "z\n",
       "\" style=\"fill:#f5f5f5;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m65dfb32968\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"71.313636\" xlink:href=\"#m65dfb32968\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(68.313636 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 46.484375 35.15625 \n",
       "Q 46.484375 21.09375 41.40625 10.9375 \n",
       "Q 36.328125 0.78125 25 0.78125 \n",
       "Q 13.671875 0.78125 8.390625 10.9375 \n",
       "Q 3.125 21.09375 3.125 35.15625 \n",
       "Q 3.125 49.21875 8.390625 59.171875 \n",
       "Q 13.671875 69.140625 25 69.140625 \n",
       "Q 36.328125 69.140625 41.40625 59.171875 \n",
       "Q 46.484375 49.21875 46.484375 35.15625 \n",
       "z\n",
       "M 37.109375 35.15625 \n",
       "Q 37.109375 47.65625 34.171875 54.6875 \n",
       "Q 31.25 61.71875 25 61.71875 \n",
       "Q 18.75 61.71875 15.625 54.6875 \n",
       "Q 12.5 47.65625 12.5 35.15625 \n",
       "Q 12.5 22.65625 15.625 15.421875 \n",
       "Q 18.75 8.203125 25 8.203125 \n",
       "Q 31.25 8.203125 34.171875 15.421875 \n",
       "Q 37.109375 22.65625 37.109375 35.15625 \n",
       "z\n",
       "\" id=\"SimHei-48\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"172.869738\" xlink:href=\"#m65dfb32968\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(163.869738 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 44.53125 1.5625 \n",
       "L 4.6875 1.5625 \n",
       "L 4.6875 7.8125 \n",
       "Q 7.03125 14.0625 11.125 19.328125 \n",
       "Q 15.234375 24.609375 23.046875 31.25 \n",
       "Q 28.90625 36.328125 31.4375 40.625 \n",
       "Q 33.984375 44.921875 33.984375 50 \n",
       "Q 33.984375 55.078125 31.828125 58.390625 \n",
       "Q 29.6875 61.71875 25 61.71875 \n",
       "Q 21.09375 61.71875 18.15625 58.203125 \n",
       "Q 15.234375 54.6875 15.234375 45.703125 \n",
       "L 6.25 45.703125 \n",
       "Q 6.640625 57.03125 11.515625 63.078125 \n",
       "Q 16.40625 69.140625 25.390625 69.140625 \n",
       "Q 33.984375 69.140625 38.671875 63.859375 \n",
       "Q 43.359375 58.59375 43.359375 49.609375 \n",
       "Q 43.359375 42.1875 39.0625 36.71875 \n",
       "Q 34.765625 31.25 28.515625 25.78125 \n",
       "Q 21.484375 19.53125 18.75 16.40625 \n",
       "Q 16.015625 13.28125 13.671875 8.984375 \n",
       "L 44.53125 8.984375 \n",
       "z\n",
       "\" id=\"SimHei-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"274.425839\" xlink:href=\"#m65dfb32968\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(265.425839 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 46.484375 18.75 \n",
       "L 38.28125 18.75 \n",
       "L 38.28125 1.5625 \n",
       "L 29.296875 1.5625 \n",
       "L 29.296875 18.75 \n",
       "L 3.125 18.75 \n",
       "L 3.125 26.171875 \n",
       "L 29.296875 69.140625 \n",
       "L 38.28125 69.140625 \n",
       "L 38.28125 26.171875 \n",
       "L 46.484375 26.171875 \n",
       "z\n",
       "M 29.296875 26.171875 \n",
       "L 29.296875 55.078125 \n",
       "L 11.71875 26.171875 \n",
       "z\n",
       "\" id=\"SimHei-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-52\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"375.981941\" xlink:href=\"#m65dfb32968\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 600 -->\n",
       "      <g transform=\"translate(366.981941 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 44.53125 24.21875 \n",
       "Q 44.53125 13.28125 39.84375 7.03125 \n",
       "Q 35.15625 0.78125 25.78125 0.78125 \n",
       "Q 16.40625 0.78125 10.9375 8.59375 \n",
       "Q 5.46875 16.40625 5.46875 33.984375 \n",
       "Q 5.46875 50 11.125 59.5625 \n",
       "Q 16.796875 69.140625 27.34375 69.140625 \n",
       "Q 34.765625 69.140625 39.25 63.671875 \n",
       "Q 43.75 58.203125 43.75 51.5625 \n",
       "L 34.765625 51.5625 \n",
       "Q 34.765625 55.46875 32.609375 58.59375 \n",
       "Q 30.46875 61.71875 26.953125 61.71875 \n",
       "Q 21.09375 61.71875 17.96875 55.65625 \n",
       "Q 14.84375 49.609375 14.453125 37.109375 \n",
       "Q 17.1875 42.1875 20.3125 44.140625 \n",
       "Q 23.4375 46.09375 27.734375 46.09375 \n",
       "Q 35.15625 46.09375 39.84375 40.234375 \n",
       "Q 44.53125 34.375 44.53125 24.21875 \n",
       "z\n",
       "M 35.15625 24.21875 \n",
       "Q 35.15625 31.25 32.8125 35.15625 \n",
       "Q 30.46875 39.0625 26.171875 39.0625 \n",
       "Q 21.09375 39.0625 18.15625 35.15625 \n",
       "Q 15.234375 31.25 15.234375 25.78125 \n",
       "Q 15.234375 17.1875 18.15625 12.5 \n",
       "Q 21.09375 7.8125 26.171875 7.8125 \n",
       "Q 29.6875 7.8125 32.421875 11.328125 \n",
       "Q 35.15625 14.84375 35.15625 24.21875 \n",
       "z\n",
       "\" id=\"SimHei-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-54\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"477.538043\" xlink:href=\"#m65dfb32968\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 800 -->\n",
       "      <g transform=\"translate(468.538043 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 44.921875 20.703125 \n",
       "Q 44.921875 10.9375 39.453125 5.859375 \n",
       "Q 33.984375 0.78125 24.609375 0.78125 \n",
       "Q 15.234375 0.78125 9.765625 5.859375 \n",
       "Q 4.296875 10.9375 4.296875 20.703125 \n",
       "Q 4.296875 25.78125 7.421875 29.875 \n",
       "Q 10.546875 33.984375 16.015625 35.9375 \n",
       "Q 11.328125 37.890625 8.78125 41.40625 \n",
       "Q 6.25 44.921875 6.25 50.390625 \n",
       "Q 6.25 58.984375 11.71875 64.0625 \n",
       "Q 17.1875 69.140625 24.609375 69.140625 \n",
       "Q 32.03125 69.140625 37.5 64.0625 \n",
       "Q 42.96875 58.984375 42.96875 50.390625 \n",
       "Q 42.96875 44.921875 40.421875 41.40625 \n",
       "Q 37.890625 37.890625 33.203125 35.9375 \n",
       "Q 38.671875 33.984375 41.796875 29.875 \n",
       "Q 44.921875 25.78125 44.921875 20.703125 \n",
       "z\n",
       "M 34.375 50.390625 \n",
       "Q 34.375 56.640625 31.640625 59.375 \n",
       "Q 28.90625 62.109375 24.609375 62.109375 \n",
       "Q 20.3125 62.109375 17.578125 59.375 \n",
       "Q 14.84375 56.640625 14.84375 50.390625 \n",
       "Q 14.84375 44.140625 17.765625 41.59375 \n",
       "Q 20.703125 39.0625 24.609375 39.0625 \n",
       "Q 28.515625 39.0625 31.4375 41.59375 \n",
       "Q 34.375 44.140625 34.375 50.390625 \n",
       "z\n",
       "M 35.9375 20.703125 \n",
       "Q 35.9375 26.171875 33 29.296875 \n",
       "Q 30.078125 32.421875 24.609375 32.421875 \n",
       "Q 19.140625 32.421875 16.203125 29.296875 \n",
       "Q 13.28125 26.171875 13.28125 20.703125 \n",
       "Q 13.28125 14.453125 16.40625 11.125 \n",
       "Q 19.53125 7.8125 24.609375 7.8125 \n",
       "Q 29.6875 7.8125 32.8125 11.125 \n",
       "Q 35.9375 14.453125 35.9375 20.703125 \n",
       "z\n",
       "\" id=\"SimHei-56\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-56\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"579.094144\" xlink:href=\"#m65dfb32968\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1000 -->\n",
       "      <g transform=\"translate(567.094144 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 30.46875 1.5625 \n",
       "L 21.484375 1.5625 \n",
       "L 21.484375 53.515625 \n",
       "L 9.765625 53.515625 \n",
       "L 9.765625 58.203125 \n",
       "Q 16.796875 58.203125 20.703125 60.9375 \n",
       "Q 24.609375 63.671875 25.78125 69.140625 \n",
       "L 30.46875 69.140625 \n",
       "z\n",
       "\" id=\"SimHei-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- iteration num -->\n",
       "     <g transform=\"translate(285.95 307.953125)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 28.515625 57.8125 \n",
       "L 20.703125 57.8125 \n",
       "L 20.703125 67.96875 \n",
       "L 28.515625 67.96875 \n",
       "z\n",
       "M 28.515625 1.5625 \n",
       "L 20.703125 1.5625 \n",
       "L 20.703125 45.3125 \n",
       "L 28.515625 45.3125 \n",
       "z\n",
       "\" id=\"SimHei-105\"/>\n",
       "       <path d=\"M 43.359375 2.734375 \n",
       "Q 41.40625 1.953125 38.859375 1.359375 \n",
       "Q 36.328125 0.78125 32.03125 0.78125 \n",
       "Q 25 0.78125 20.703125 4.6875 \n",
       "Q 16.40625 8.59375 16.40625 15.625 \n",
       "L 16.40625 39.0625 \n",
       "L 3.125 39.0625 \n",
       "L 3.125 45.3125 \n",
       "L 16.40625 45.3125 \n",
       "L 16.40625 60.546875 \n",
       "L 24.21875 60.546875 \n",
       "L 24.21875 45.3125 \n",
       "L 40.234375 45.3125 \n",
       "L 40.234375 39.0625 \n",
       "L 24.21875 39.0625 \n",
       "L 24.21875 15.234375 \n",
       "Q 24.21875 12.109375 25.78125 9.953125 \n",
       "Q 27.34375 7.8125 31.640625 7.8125 \n",
       "Q 35.9375 7.8125 38.671875 8.59375 \n",
       "Q 41.40625 9.375 43.359375 10.546875 \n",
       "z\n",
       "\" id=\"SimHei-116\"/>\n",
       "       <path d=\"M 44.921875 16.40625 \n",
       "Q 44.140625 9.375 38.671875 5.078125 \n",
       "Q 33.203125 0.78125 25.78125 0.78125 \n",
       "Q 16.40625 0.78125 10.34375 6.828125 \n",
       "Q 4.296875 12.890625 4.296875 23.4375 \n",
       "Q 4.296875 33.984375 10.34375 40.03125 \n",
       "Q 16.40625 46.09375 25.78125 46.09375 \n",
       "Q 33.984375 46.09375 39.25 40.8125 \n",
       "Q 44.53125 35.546875 44.53125 23.4375 \n",
       "L 12.890625 23.4375 \n",
       "Q 12.890625 14.84375 16.59375 11.328125 \n",
       "Q 20.3125 7.8125 25.78125 7.8125 \n",
       "Q 30.078125 7.8125 32.8125 9.953125 \n",
       "Q 35.546875 12.109375 36.328125 16.40625 \n",
       "z\n",
       "M 35.546875 29.6875 \n",
       "Q 34.765625 35.15625 32.03125 37.296875 \n",
       "Q 29.296875 39.453125 25 39.453125 \n",
       "Q 21.09375 39.453125 17.96875 37.296875 \n",
       "Q 14.84375 35.15625 13.28125 29.6875 \n",
       "z\n",
       "\" id=\"SimHei-101\"/>\n",
       "       <path d=\"M 39.453125 37.5 \n",
       "Q 32.03125 38.671875 26.953125 35.34375 \n",
       "Q 21.875 32.03125 18.359375 23.828125 \n",
       "L 18.359375 1.5625 \n",
       "L 10.546875 1.5625 \n",
       "L 10.546875 45.3125 \n",
       "L 18.359375 45.3125 \n",
       "L 18.359375 33.984375 \n",
       "Q 21.875 40.234375 27.140625 43.15625 \n",
       "Q 32.421875 46.09375 39.453125 46.09375 \n",
       "z\n",
       "\" id=\"SimHei-114\"/>\n",
       "       <path d=\"M 45.3125 1.5625 \n",
       "L 35.9375 1.5625 \n",
       "Q 35.15625 2.34375 34.765625 3.703125 \n",
       "Q 34.375 5.078125 34.375 7.03125 \n",
       "Q 31.640625 3.90625 27.734375 2.34375 \n",
       "Q 23.828125 0.78125 19.53125 0.78125 \n",
       "Q 13.28125 0.78125 8.984375 3.90625 \n",
       "Q 4.6875 7.03125 4.6875 12.890625 \n",
       "Q 4.6875 18.75 8.59375 22.265625 \n",
       "Q 12.5 25.78125 20.703125 26.953125 \n",
       "Q 26.171875 27.734375 30.265625 28.90625 \n",
       "Q 34.375 30.078125 34.375 32.03125 \n",
       "Q 34.375 34.375 32.609375 36.71875 \n",
       "Q 30.859375 39.0625 25 39.0625 \n",
       "Q 20.3125 39.0625 18.15625 37.296875 \n",
       "Q 16.015625 35.546875 15.234375 32.421875 \n",
       "L 6.640625 32.421875 \n",
       "Q 7.421875 38.671875 12.296875 42.375 \n",
       "Q 17.1875 46.09375 25 46.09375 \n",
       "Q 33.59375 46.09375 37.890625 42.1875 \n",
       "Q 42.1875 38.28125 42.1875 31.25 \n",
       "L 42.1875 9.765625 \n",
       "Q 42.1875 7.421875 42.96875 5.46875 \n",
       "Q 43.75 3.515625 45.3125 1.5625 \n",
       "z\n",
       "M 34.375 16.015625 \n",
       "L 34.375 23.828125 \n",
       "Q 32.03125 23.046875 29.875 22.453125 \n",
       "Q 27.734375 21.875 22.65625 21.09375 \n",
       "Q 16.796875 20.3125 15.03125 18.359375 \n",
       "Q 13.28125 16.40625 13.28125 13.671875 \n",
       "Q 13.28125 11.328125 15.03125 9.5625 \n",
       "Q 16.796875 7.8125 20.3125 7.8125 \n",
       "Q 23.828125 7.8125 27.921875 9.765625 \n",
       "Q 32.03125 11.71875 34.375 16.015625 \n",
       "z\n",
       "\" id=\"SimHei-97\"/>\n",
       "       <path d=\"M 46.09375 23.4375 \n",
       "Q 46.09375 13.28125 39.84375 7.03125 \n",
       "Q 33.59375 0.78125 25 0.78125 \n",
       "Q 16.40625 0.78125 10.15625 7.03125 \n",
       "Q 3.90625 13.28125 3.90625 23.4375 \n",
       "Q 3.90625 33.59375 10.15625 39.84375 \n",
       "Q 16.40625 46.09375 25 46.09375 \n",
       "Q 33.59375 46.09375 39.84375 39.84375 \n",
       "Q 46.09375 33.59375 46.09375 23.4375 \n",
       "z\n",
       "M 37.5 23.4375 \n",
       "Q 37.5 31.25 33.59375 35.15625 \n",
       "Q 29.6875 39.0625 25 39.0625 \n",
       "Q 20.3125 39.0625 16.40625 35.15625 \n",
       "Q 12.5 31.25 12.5 23.4375 \n",
       "Q 12.5 15.625 16.40625 11.71875 \n",
       "Q 20.3125 7.8125 25 7.8125 \n",
       "Q 29.6875 7.8125 33.59375 11.71875 \n",
       "Q 37.5 15.625 37.5 23.4375 \n",
       "z\n",
       "\" id=\"SimHei-111\"/>\n",
       "       <path d=\"M 44.140625 1.5625 \n",
       "L 36.328125 1.5625 \n",
       "L 36.328125 29.6875 \n",
       "Q 36.328125 34.375 33.984375 37.109375 \n",
       "Q 31.640625 39.84375 27.734375 39.84375 \n",
       "Q 22.65625 39.84375 18.15625 34.5625 \n",
       "Q 13.671875 29.296875 13.671875 21.484375 \n",
       "L 13.671875 1.5625 \n",
       "L 5.859375 1.5625 \n",
       "L 5.859375 45.3125 \n",
       "L 13.671875 45.3125 \n",
       "L 13.671875 37.109375 \n",
       "Q 16.796875 41.40625 20.5 43.75 \n",
       "Q 24.21875 46.09375 30.078125 46.09375 \n",
       "Q 37.109375 46.09375 40.625 42.1875 \n",
       "Q 44.140625 38.28125 44.140625 32.421875 \n",
       "z\n",
       "\" id=\"SimHei-110\"/>\n",
       "       <path id=\"SimHei-32\"/>\n",
       "       <path d=\"M 44.140625 1.5625 \n",
       "L 36.328125 1.5625 \n",
       "L 36.328125 9.765625 \n",
       "Q 33.203125 5.46875 29.484375 3.125 \n",
       "Q 25.78125 0.78125 19.921875 0.78125 \n",
       "Q 12.890625 0.78125 9.375 4.6875 \n",
       "Q 5.859375 8.59375 5.859375 14.453125 \n",
       "L 5.859375 45.3125 \n",
       "L 13.671875 45.3125 \n",
       "L 13.671875 17.1875 \n",
       "Q 13.671875 12.5 16.015625 9.765625 \n",
       "Q 18.359375 7.03125 22.265625 7.03125 \n",
       "Q 27.34375 7.03125 31.828125 12.296875 \n",
       "Q 36.328125 17.578125 36.328125 25.390625 \n",
       "L 36.328125 45.3125 \n",
       "L 44.140625 45.3125 \n",
       "z\n",
       "\" id=\"SimHei-117\"/>\n",
       "       <path d=\"M 48.046875 1.5625 \n",
       "L 40.234375 1.5625 \n",
       "L 40.234375 33.203125 \n",
       "Q 40.234375 35.546875 39.453125 37.109375 \n",
       "Q 38.671875 38.671875 36.328125 38.671875 \n",
       "Q 33.59375 38.671875 31.25 35.734375 \n",
       "Q 28.90625 32.8125 28.90625 28.125 \n",
       "L 28.90625 1.5625 \n",
       "L 21.09375 1.5625 \n",
       "L 21.09375 33.203125 \n",
       "Q 21.09375 35.546875 20.3125 37.109375 \n",
       "Q 19.53125 38.671875 17.1875 38.671875 \n",
       "Q 14.453125 38.671875 12.109375 35.734375 \n",
       "Q 9.765625 32.8125 9.765625 28.125 \n",
       "L 9.765625 1.5625 \n",
       "L 1.953125 1.5625 \n",
       "L 1.953125 45.3125 \n",
       "L 9.765625 45.3125 \n",
       "L 9.765625 39.453125 \n",
       "Q 11.71875 42.578125 14.453125 44.328125 \n",
       "Q 17.1875 46.09375 20.3125 46.09375 \n",
       "Q 23.4375 46.09375 25.578125 44.328125 \n",
       "Q 27.734375 42.578125 28.515625 39.453125 \n",
       "Q 30.46875 42.578125 33 44.328125 \n",
       "Q 35.546875 46.09375 38.671875 46.09375 \n",
       "Q 43.359375 46.09375 45.703125 43.546875 \n",
       "Q 48.046875 41.015625 48.046875 36.328125 \n",
       "z\n",
       "\" id=\"SimHei-109\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-105\"/>\n",
       "      <use x=\"50\" xlink:href=\"#SimHei-116\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-101\"/>\n",
       "      <use x=\"150\" xlink:href=\"#SimHei-114\"/>\n",
       "      <use x=\"200\" xlink:href=\"#SimHei-97\"/>\n",
       "      <use x=\"250\" xlink:href=\"#SimHei-116\"/>\n",
       "      <use x=\"300\" xlink:href=\"#SimHei-105\"/>\n",
       "      <use x=\"350\" xlink:href=\"#SimHei-111\"/>\n",
       "      <use x=\"400\" xlink:href=\"#SimHei-110\"/>\n",
       "      <use x=\"450\" xlink:href=\"#SimHei-32\"/>\n",
       "      <use x=\"500\" xlink:href=\"#SimHei-110\"/>\n",
       "      <use x=\"550\" xlink:href=\"#SimHei-117\"/>\n",
       "      <use x=\"600\" xlink:href=\"#SimHei-109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m151e058d7e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#m151e058d7e\" y=\"266.645475\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(32.95 270.747037)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#m151e058d7e\" y=\"212.358615\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(20.95 216.460177)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#m151e058d7e\" y=\"158.071755\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(20.95 162.173318)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-52\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#m151e058d7e\" y=\"103.784896\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 600 -->\n",
       "      <g transform=\"translate(20.95 107.886458)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-54\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#m151e058d7e\" y=\"49.498036\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 800 -->\n",
       "      <g transform=\"translate(20.95 53.599599)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-56\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- loss -->\n",
       "     <g transform=\"translate(15.403125 155.1)rotate(-90)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 28.90625 1.5625 \n",
       "L 21.09375 1.5625 \n",
       "L 21.09375 68.359375 \n",
       "L 28.90625 68.359375 \n",
       "z\n",
       "\" id=\"SimHei-108\"/>\n",
       "       <path d=\"M 43.359375 13.671875 \n",
       "Q 43.359375 7.421875 38.46875 4.09375 \n",
       "Q 33.59375 0.78125 26.171875 0.78125 \n",
       "Q 16.796875 0.78125 11.71875 4.484375 \n",
       "Q 6.640625 8.203125 6.640625 15.234375 \n",
       "L 14.453125 15.234375 \n",
       "Q 14.453125 10.546875 17.765625 8.984375 \n",
       "Q 21.09375 7.421875 25.78125 7.421875 \n",
       "Q 30.46875 7.421875 32.8125 9.171875 \n",
       "Q 35.15625 10.9375 35.15625 13.671875 \n",
       "Q 35.15625 15.625 33.203125 17.578125 \n",
       "Q 31.25 19.53125 23.4375 20.703125 \n",
       "Q 14.453125 21.875 11.125 25.1875 \n",
       "Q 7.8125 28.515625 7.8125 33.984375 \n",
       "Q 7.8125 38.671875 12.296875 42.375 \n",
       "Q 16.796875 46.09375 25.390625 46.09375 \n",
       "Q 33.203125 46.09375 37.6875 42.578125 \n",
       "Q 42.1875 39.0625 42.1875 33.203125 \n",
       "L 34.375 33.203125 \n",
       "Q 34.375 36.71875 31.828125 38.078125 \n",
       "Q 29.296875 39.453125 25.390625 39.453125 \n",
       "Q 20.3125 39.453125 18.15625 37.6875 \n",
       "Q 16.015625 35.9375 16.015625 33.59375 \n",
       "Q 16.015625 30.859375 17.96875 29.296875 \n",
       "Q 19.921875 27.734375 26.171875 26.953125 \n",
       "Q 36.328125 25.390625 39.84375 22.0625 \n",
       "Q 43.359375 18.75 43.359375 13.671875 \n",
       "z\n",
       "\" id=\"SimHei-115\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-108\"/>\n",
       "      <use x=\"50\" xlink:href=\"#SimHei-111\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-115\"/>\n",
       "      <use x=\"150\" xlink:href=\"#SimHei-115\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_12\">\n",
       "    <path clip-path=\"url(#p3fa728f937)\" d=\"M 71.313636 19.554545 \n",
       "L 71.821417 200.979887 \n",
       "L 72.329197 245.756297 \n",
       "L 72.836978 256.997114 \n",
       "L 73.344758 259.984715 \n",
       "L 73.852539 260.921899 \n",
       "L 74.360319 261.333635 \n",
       "L 75.37588 261.808914 \n",
       "L 77.407002 262.455583 \n",
       "L 80.453686 263.135323 \n",
       "L 84.51593 263.793237 \n",
       "L 90.101515 264.468433 \n",
       "L 97.210442 265.092568 \n",
       "L 105.842711 265.611571 \n",
       "L 116.506102 266.017004 \n",
       "L 130.723956 266.318903 \n",
       "L 151.542957 266.517458 \n",
       "L 189.626495 266.620399 \n",
       "L 322.157207 266.64525 \n",
       "L 578.586364 266.645449 \n",
       "L 578.586364 266.645449 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_13\">\n",
       "    <path clip-path=\"url(#p3fa728f937)\" d=\"M 71.313636 214.781854 \n",
       "L 71.821417 248.901998 \n",
       "L 72.329197 257.820636 \n",
       "L 72.836978 260.347661 \n",
       "L 73.344758 261.198652 \n",
       "L 73.852539 261.580503 \n",
       "L 74.8681 261.991731 \n",
       "L 76.899222 262.513934 \n",
       "L 80.453686 263.176817 \n",
       "L 86.039271 263.96554 \n",
       "L 92.640418 264.668863 \n",
       "L 100.257125 265.256115 \n",
       "L 109.397174 265.734137 \n",
       "L 121.076126 266.111176 \n",
       "L 136.817322 266.382488 \n",
       "L 161.190786 266.555192 \n",
       "L 210.445495 266.633725 \n",
       "L 476.522482 266.645454 \n",
       "L 578.586364 266.645454 \n",
       "L 578.586364 266.645454 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 45.95 279 \n",
       "L 45.95 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 603.95 279 \n",
       "L 603.95 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 45.95 279 \n",
       "L 603.95 279 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 45.95 7.2 \n",
       "L 603.95 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"legend_1\">\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 366.03425 57.006 \n",
       "L 576.03425 57.006 \n",
       "Q 578.43425 57.006 578.43425 54.606 \n",
       "L 578.43425 39.765375 \n",
       "Q 578.43425 37.365375 576.03425 37.365375 \n",
       "L 366.03425 37.365375 \n",
       "Q 363.63425 37.365375 363.63425 39.765375 \n",
       "L 363.63425 54.606 \n",
       "Q 363.63425 57.006 366.03425 57.006 \n",
       "z\n",
       "\" style=\"fill:#f5f5f5;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path d=\"M 368.43425 46.365375 \n",
       "L 392.43425 46.365375 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\"/>\n",
       "   <g id=\"text_14\">\n",
       "    <!-- train_loss -->\n",
       "    <g transform=\"translate(402.03425 50.565375)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path d=\"M 49.609375 -13.671875 \n",
       "L 0 -13.671875 \n",
       "L 0 -8.984375 \n",
       "L 49.609375 -8.984375 \n",
       "z\n",
       "\" id=\"SimHei-95\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#SimHei-116\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-114\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-97\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-105\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-110\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-95\"/>\n",
       "     <use x=\"300\" xlink:href=\"#SimHei-108\"/>\n",
       "     <use x=\"350\" xlink:href=\"#SimHei-111\"/>\n",
       "     <use x=\"400\" xlink:href=\"#SimHei-115\"/>\n",
       "     <use x=\"450\" xlink:href=\"#SimHei-115\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 486.03425 46.365375 \n",
       "L 510.03425 46.365375 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_17\"/>\n",
       "   <g id=\"text_15\">\n",
       "    <!-- test_loss -->\n",
       "    <g transform=\"translate(519.63425 50.565375)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#SimHei-116\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-101\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-115\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-116\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-95\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-108\"/>\n",
       "     <use x=\"300\" xlink:href=\"#SimHei-111\"/>\n",
       "     <use x=\"350\" xlink:href=\"#SimHei-115\"/>\n",
       "     <use x=\"400\" xlink:href=\"#SimHei-115\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p3fa728f937\">\n",
       "   <rect height=\"271.8\" width=\"558\" x=\"45.95\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute time is 4.476 seconds\n"
     ]
    }
   ],
   "source": [
    "# define model and loss\n",
    "model = PolyModel(poly_feature.shape[1])\n",
    "init.normal_(model.layer[0].weight, 0, 0.01)\n",
    "init.constant_(model.layer[0].bias, 0)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# deal with data\n",
    "train_dataset = Data.TensorDataset(poly_feature[:100], y[:100])\n",
    "test_dataset = Data.TensorDataset(poly_feature[100:], y[100:])\n",
    "test_iter = Data.DataLoader(test_dataset, batch_size=len(y[:100]), shuffle=True)\n",
    "\n",
    "params = {\n",
    "    \"model\": model,\n",
    "    \"loss\": loss,\n",
    "    \"epoch_num\": 1000,\n",
    "    \"batch_size\": 100,\n",
    "    \"lr\": 0.01,\n",
    "    \"data_num\": 100,\n",
    "    \"test_iter\":test_iter,\n",
    "    \"draw\": True,\n",
    "}\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=params[\"lr\"])\n",
    "train_iter = Data.DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "params[\"optimizer\"] = optimizer\n",
    "params[\"train_iter\"] = train_iter\n",
    "\n",
    "# training\n",
    "set_fig_display()\n",
    "train_experiment(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T13:21:44.213618Z",
     "start_time": "2020-10-08T13:21:44.187795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.1989, -3.4003,  5.6000]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([5.0015], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer[0].weight\n",
    "model.layer[0].bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 欠拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T13:21:55.733958Z",
     "start_time": "2020-10-08T13:21:51.352802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.0096]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 905.8680, train_score: -, test_loss: 664.8123, test_score: -\n",
      "\n",
      "Epoch [2/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 879.6163, train_score: -, test_loss: 645.0322, test_score: -\n",
      "\n",
      "Epoch [3/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 854.6152, train_score: -, test_loss: 626.2202, test_score: -\n",
      "\n",
      "Epoch [4/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 830.8053, train_score: -, test_loss: 608.3298, test_score: -\n",
      "\n",
      "Epoch [5/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 808.1296, train_score: -, test_loss: 591.3165, test_score: -\n",
      "\n",
      "Epoch [6/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 786.5338, train_score: -, test_loss: 575.1379, test_score: -\n",
      "\n",
      "Epoch [7/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 765.9666, train_score: -, test_loss: 559.7540, test_score: -\n",
      "\n",
      "Epoch [8/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 746.3792, train_score: -, test_loss: 545.1260, test_score: -\n",
      "\n",
      "Epoch [9/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 727.7241, train_score: -, test_loss: 531.2177, test_score: -\n",
      "\n",
      "Epoch [10/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 709.9573, train_score: -, test_loss: 517.9941, test_score: -\n",
      "\n",
      "Epoch [11/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 693.0369, train_score: -, test_loss: 505.4223, test_score: -\n",
      "\n",
      "Epoch [12/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 676.9217, train_score: -, test_loss: 493.4705, test_score: -\n",
      "\n",
      "Epoch [13/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 661.5737, train_score: -, test_loss: 482.1089, test_score: -\n",
      "\n",
      "Epoch [14/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 646.9565, train_score: -, test_loss: 471.3088, test_score: -\n",
      "\n",
      "Epoch [15/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 633.0351, train_score: -, test_loss: 461.0432, test_score: -\n",
      "\n",
      "Epoch [16/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 619.7762, train_score: -, test_loss: 451.2859, test_score: -\n",
      "\n",
      "Epoch [17/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 607.1481, train_score: -, test_loss: 442.0127, test_score: -\n",
      "\n",
      "Epoch [18/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 595.1212, train_score: -, test_loss: 433.1997, test_score: -\n",
      "\n",
      "Epoch [19/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 583.6665, train_score: -, test_loss: 424.8248, test_score: -\n",
      "\n",
      "Epoch [20/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 572.7568, train_score: -, test_loss: 416.8665, test_score: -\n",
      "\n",
      "Epoch [21/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 562.3661, train_score: -, test_loss: 409.3050, test_score: -\n",
      "\n",
      "Epoch [22/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 552.4697, train_score: -, test_loss: 402.1206, test_score: -\n",
      "\n",
      "Epoch [23/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 543.0441, train_score: -, test_loss: 395.2953, test_score: -\n",
      "\n",
      "Epoch [24/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 534.0669, train_score: -, test_loss: 388.8113, test_score: -\n",
      "\n",
      "Epoch [25/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 525.5165, train_score: -, test_loss: 382.6522, test_score: -\n",
      "\n",
      "Epoch [26/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 517.3729, train_score: -, test_loss: 376.8021, test_score: -\n",
      "\n",
      "Epoch [27/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 509.6164, train_score: -, test_loss: 371.2461, test_score: -\n",
      "\n",
      "Epoch [28/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 502.2288, train_score: -, test_loss: 365.9696, test_score: -\n",
      "\n",
      "Epoch [29/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 495.1923, train_score: -, test_loss: 360.9591, test_score: -\n",
      "\n",
      "Epoch [30/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 488.4905, train_score: -, test_loss: 356.2017, test_score: -\n",
      "\n",
      "Epoch [31/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 482.1070, train_score: -, test_loss: 351.6849, test_score: -\n",
      "\n",
      "Epoch [32/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 476.0272, train_score: -, test_loss: 347.3969, test_score: -\n",
      "\n",
      "Epoch [33/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 470.2362, train_score: -, test_loss: 343.3266, test_score: -\n",
      "\n",
      "Epoch [34/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 464.7204, train_score: -, test_loss: 339.4634, test_score: -\n",
      "\n",
      "Epoch [35/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 459.4666, train_score: -, test_loss: 335.7970, test_score: -\n",
      "\n",
      "Epoch [36/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 454.4626, train_score: -, test_loss: 332.3179, test_score: -\n",
      "\n",
      "Epoch [37/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 449.6963, train_score: -, test_loss: 329.0168, test_score: -\n",
      "\n",
      "Epoch [38/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 445.1564, train_score: -, test_loss: 325.8849, test_score: -\n",
      "\n",
      "Epoch [39/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 440.8321, train_score: -, test_loss: 322.9142, test_score: -\n",
      "\n",
      "Epoch [40/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 436.7133, train_score: -, test_loss: 320.0964, test_score: -\n",
      "\n",
      "Epoch [41/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 432.7900, train_score: -, test_loss: 317.4240, test_score: -\n",
      "\n",
      "Epoch [42/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 429.0530, train_score: -, test_loss: 314.8901, test_score: -\n",
      "\n",
      "Epoch [43/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 425.4934, train_score: -, test_loss: 312.4876, test_score: -\n",
      "\n",
      "Epoch [44/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 422.1029, train_score: -, test_loss: 310.2101, test_score: -\n",
      "\n",
      "Epoch [45/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 418.8733, train_score: -, test_loss: 308.0515, test_score: -\n",
      "\n",
      "Epoch [46/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 415.7970, train_score: -, test_loss: 306.0059, test_score: -\n",
      "\n",
      "Epoch [47/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 412.8668, train_score: -, test_loss: 304.0675, test_score: -\n",
      "\n",
      "Epoch [48/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 410.0754, train_score: -, test_loss: 302.2312, test_score: -\n",
      "\n",
      "Epoch [49/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 407.4167, train_score: -, test_loss: 300.4919, test_score: -\n",
      "\n",
      "Epoch [50/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 404.8841, train_score: -, test_loss: 298.8446, test_score: -\n",
      "\n",
      "Epoch [51/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 402.4717, train_score: -, test_loss: 297.2850, test_score: -\n",
      "\n",
      "Epoch [52/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 400.1737, train_score: -, test_loss: 295.8085, test_score: -\n",
      "\n",
      "Epoch [53/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 397.9845, train_score: -, test_loss: 294.4110, test_score: -\n",
      "\n",
      "Epoch [54/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 395.8994, train_score: -, test_loss: 293.0886, test_score: -\n",
      "\n",
      "Epoch [55/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 393.9131, train_score: -, test_loss: 291.8375, test_score: -\n",
      "\n",
      "Epoch [56/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 392.0209, train_score: -, test_loss: 290.6542, test_score: -\n",
      "\n",
      "Epoch [57/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 390.2184, train_score: -, test_loss: 289.5352, test_score: -\n",
      "\n",
      "Epoch [58/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 388.5016, train_score: -, test_loss: 288.4772, test_score: -\n",
      "\n",
      "Epoch [59/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 386.8658, train_score: -, test_loss: 287.4774, test_score: -\n",
      "\n",
      "Epoch [60/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 385.3078, train_score: -, test_loss: 286.5325, test_score: -\n",
      "\n",
      "Epoch [61/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 383.8235, train_score: -, test_loss: 285.6400, test_score: -\n",
      "\n",
      "Epoch [62/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 382.4096, train_score: -, test_loss: 284.7973, test_score: -\n",
      "\n",
      "Epoch [63/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 381.0628, train_score: -, test_loss: 284.0016, test_score: -\n",
      "\n",
      "Epoch [64/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 379.7797, train_score: -, test_loss: 283.2506, test_score: -\n",
      "\n",
      "Epoch [65/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 378.5572, train_score: -, test_loss: 282.5422, test_score: -\n",
      "\n",
      "Epoch [66/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 377.3929, train_score: -, test_loss: 281.8740, test_score: -\n",
      "\n",
      "Epoch [67/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 376.2835, train_score: -, test_loss: 281.2441, test_score: -\n",
      "\n",
      "Epoch [68/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 375.2267, train_score: -, test_loss: 280.6505, test_score: -\n",
      "\n",
      "Epoch [69/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 374.2200, train_score: -, test_loss: 280.0913, test_score: -\n",
      "\n",
      "Epoch [70/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 373.2609, train_score: -, test_loss: 279.5647, test_score: -\n",
      "\n",
      "Epoch [71/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 372.3472, train_score: -, test_loss: 279.0690, test_score: -\n",
      "\n",
      "Epoch [72/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 371.4768, train_score: -, test_loss: 278.6028, test_score: -\n",
      "\n",
      "Epoch [73/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 370.6476, train_score: -, test_loss: 278.1644, test_score: -\n",
      "\n",
      "Epoch [74/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 369.8575, train_score: -, test_loss: 277.7523, test_score: -\n",
      "\n",
      "Epoch [75/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 369.1049, train_score: -, test_loss: 277.3653, test_score: -\n",
      "\n",
      "Epoch [76/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 368.3878, train_score: -, test_loss: 277.0020, test_score: -\n",
      "\n",
      "Epoch [77/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 367.7047, train_score: -, test_loss: 276.6611, test_score: -\n",
      "\n",
      "Epoch [78/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 367.0539, train_score: -, test_loss: 276.3416, test_score: -\n",
      "\n",
      "Epoch [79/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 366.4338, train_score: -, test_loss: 276.0421, test_score: -\n",
      "\n",
      "Epoch [80/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 365.8431, train_score: -, test_loss: 275.7618, test_score: -\n",
      "\n",
      "Epoch [81/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 365.2804, train_score: -, test_loss: 275.4996, test_score: -\n",
      "\n",
      "Epoch [82/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 364.7441, train_score: -, test_loss: 275.2545, test_score: -\n",
      "\n",
      "Epoch [83/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 364.2332, train_score: -, test_loss: 275.0255, test_score: -\n",
      "\n",
      "Epoch [84/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 363.7466, train_score: -, test_loss: 274.8120, test_score: -\n",
      "\n",
      "Epoch [85/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 363.2828, train_score: -, test_loss: 274.6129, test_score: -\n",
      "\n",
      "Epoch [86/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 362.8410, train_score: -, test_loss: 274.4275, test_score: -\n",
      "\n",
      "Epoch [87/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 362.4200, train_score: -, test_loss: 274.2551, test_score: -\n",
      "\n",
      "Epoch [88/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 362.0189, train_score: -, test_loss: 274.0950, test_score: -\n",
      "\n",
      "Epoch [89/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 361.6368, train_score: -, test_loss: 273.9464, test_score: -\n",
      "\n",
      "Epoch [90/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 361.2727, train_score: -, test_loss: 273.8089, test_score: -\n",
      "\n",
      "Epoch [91/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 360.9258, train_score: -, test_loss: 273.6817, test_score: -\n",
      "\n",
      "Epoch [92/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 360.5953, train_score: -, test_loss: 273.5642, test_score: -\n",
      "\n",
      "Epoch [93/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 360.2804, train_score: -, test_loss: 273.4560, test_score: -\n",
      "\n",
      "Epoch [94/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 359.9803, train_score: -, test_loss: 273.3565, test_score: -\n",
      "\n",
      "Epoch [95/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 359.6944, train_score: -, test_loss: 273.2652, test_score: -\n",
      "\n",
      "Epoch [96/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 359.4220, train_score: -, test_loss: 273.1817, test_score: -\n",
      "\n",
      "Epoch [97/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 359.1624, train_score: -, test_loss: 273.1054, test_score: -\n",
      "\n",
      "Epoch [98/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 358.9150, train_score: -, test_loss: 273.0361, test_score: -\n",
      "\n",
      "Epoch [99/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 358.6793, train_score: -, test_loss: 272.9733, test_score: -\n",
      "\n",
      "Epoch [100/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 358.4548, train_score: -, test_loss: 272.9165, test_score: -\n",
      "\n",
      "Epoch [101/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 358.2408, train_score: -, test_loss: 272.8656, test_score: -\n",
      "\n",
      "Epoch [102/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 358.0369, train_score: -, test_loss: 272.8200, test_score: -\n",
      "\n",
      "Epoch [103/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 357.8426, train_score: -, test_loss: 272.7796, test_score: -\n",
      "\n",
      "Epoch [104/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 357.6575, train_score: -, test_loss: 272.7438, test_score: -\n",
      "\n",
      "Epoch [105/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 357.4810, train_score: -, test_loss: 272.7127, test_score: -\n",
      "\n",
      "Epoch [106/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 357.3130, train_score: -, test_loss: 272.6857, test_score: -\n",
      "\n",
      "Epoch [107/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 357.1528, train_score: -, test_loss: 272.6627, test_score: -\n",
      "\n",
      "Epoch [108/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 357.0002, train_score: -, test_loss: 272.6434, test_score: -\n",
      "\n",
      "Epoch [109/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 356.8547, train_score: -, test_loss: 272.6276, test_score: -\n",
      "\n",
      "Epoch [110/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 356.7161, train_score: -, test_loss: 272.6150, test_score: -\n",
      "\n",
      "Epoch [111/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 356.5840, train_score: -, test_loss: 272.6055, test_score: -\n",
      "\n",
      "Epoch [112/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 356.4581, train_score: -, test_loss: 272.5988, test_score: -\n",
      "\n",
      "Epoch [113/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 356.3382, train_score: -, test_loss: 272.5948, test_score: -\n",
      "\n",
      "Epoch [114/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 356.2239, train_score: -, test_loss: 272.5933, test_score: -\n",
      "\n",
      "Epoch [115/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 356.1150, train_score: -, test_loss: 272.5941, test_score: -\n",
      "\n",
      "Epoch [116/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 356.0112, train_score: -, test_loss: 272.5971, test_score: -\n",
      "\n",
      "Epoch [117/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 355.9121, train_score: -, test_loss: 272.6020, test_score: -\n",
      "\n",
      "Epoch [118/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 355.8178, train_score: -, test_loss: 272.6089, test_score: -\n",
      "\n",
      "Epoch [119/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 355.7281, train_score: -, test_loss: 272.6174, test_score: -\n",
      "\n",
      "Epoch [120/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 355.6424, train_score: -, test_loss: 272.6275, test_score: -\n",
      "\n",
      "Epoch [121/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 355.5607, train_score: -, test_loss: 272.6392, test_score: -\n",
      "\n",
      "Epoch [122/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 355.4830, train_score: -, test_loss: 272.6522, test_score: -\n",
      "\n",
      "Epoch [123/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 355.4089, train_score: -, test_loss: 272.6664, test_score: -\n",
      "\n",
      "Epoch [124/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 355.3383, train_score: -, test_loss: 272.6818, test_score: -\n",
      "\n",
      "Epoch [125/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 355.2709, train_score: -, test_loss: 272.6984, test_score: -\n",
      "\n",
      "Epoch [126/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 355.2068, train_score: -, test_loss: 272.7159, test_score: -\n",
      "\n",
      "Epoch [127/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 355.1456, train_score: -, test_loss: 272.7342, test_score: -\n",
      "\n",
      "Epoch [128/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 355.0874, train_score: -, test_loss: 272.7534, test_score: -\n",
      "\n",
      "Epoch [129/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 355.0317, train_score: -, test_loss: 272.7733, test_score: -\n",
      "\n",
      "Epoch [130/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.9789, train_score: -, test_loss: 272.7939, test_score: -\n",
      "\n",
      "Epoch [131/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.9283, train_score: -, test_loss: 272.8151, test_score: -\n",
      "\n",
      "Epoch [132/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.8803, train_score: -, test_loss: 272.8368, test_score: -\n",
      "\n",
      "Epoch [133/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.8344, train_score: -, test_loss: 272.8589, test_score: -\n",
      "\n",
      "Epoch [134/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.7908, train_score: -, test_loss: 272.8815, test_score: -\n",
      "\n",
      "Epoch [135/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.7491, train_score: -, test_loss: 272.9045, test_score: -\n",
      "\n",
      "Epoch [136/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.7094, train_score: -, test_loss: 272.9278, test_score: -\n",
      "\n",
      "Epoch [137/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.6715, train_score: -, test_loss: 272.9514, test_score: -\n",
      "\n",
      "Epoch [138/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.6354, train_score: -, test_loss: 272.9752, test_score: -\n",
      "\n",
      "Epoch [139/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.6011, train_score: -, test_loss: 272.9992, test_score: -\n",
      "\n",
      "Epoch [140/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.5683, train_score: -, test_loss: 273.0233, test_score: -\n",
      "\n",
      "Epoch [141/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.5371, train_score: -, test_loss: 273.0475, test_score: -\n",
      "\n",
      "Epoch [142/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.5073, train_score: -, test_loss: 273.0719, test_score: -\n",
      "\n",
      "Epoch [143/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.4789, train_score: -, test_loss: 273.0963, test_score: -\n",
      "\n",
      "Epoch [144/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.4519, train_score: -, test_loss: 273.1207, test_score: -\n",
      "\n",
      "Epoch [145/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.4261, train_score: -, test_loss: 273.1451, test_score: -\n",
      "\n",
      "Epoch [146/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.4015, train_score: -, test_loss: 273.1695, test_score: -\n",
      "\n",
      "Epoch [147/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.3780, train_score: -, test_loss: 273.1938, test_score: -\n",
      "\n",
      "Epoch [148/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.3557, train_score: -, test_loss: 273.2180, test_score: -\n",
      "\n",
      "Epoch [149/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.3344, train_score: -, test_loss: 273.2422, test_score: -\n",
      "\n",
      "Epoch [150/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.3142, train_score: -, test_loss: 273.2663, test_score: -\n",
      "\n",
      "Epoch [151/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.2948, train_score: -, test_loss: 273.2902, test_score: -\n",
      "\n",
      "Epoch [152/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.2763, train_score: -, test_loss: 273.3139, test_score: -\n",
      "\n",
      "Epoch [153/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.2588, train_score: -, test_loss: 273.3376, test_score: -\n",
      "\n",
      "Epoch [154/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.2420, train_score: -, test_loss: 273.3610, test_score: -\n",
      "\n",
      "Epoch [155/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.2260, train_score: -, test_loss: 273.3842, test_score: -\n",
      "\n",
      "Epoch [156/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.2108, train_score: -, test_loss: 273.4073, test_score: -\n",
      "\n",
      "Epoch [157/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.1962, train_score: -, test_loss: 273.4301, test_score: -\n",
      "\n",
      "Epoch [158/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.1824, train_score: -, test_loss: 273.4527, test_score: -\n",
      "\n",
      "Epoch [159/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.1692, train_score: -, test_loss: 273.4752, test_score: -\n",
      "\n",
      "Epoch [160/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.1566, train_score: -, test_loss: 273.4973, test_score: -\n",
      "\n",
      "Epoch [161/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.1445, train_score: -, test_loss: 273.5192, test_score: -\n",
      "\n",
      "Epoch [162/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.1331, train_score: -, test_loss: 273.5409, test_score: -\n",
      "\n",
      "Epoch [163/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.1222, train_score: -, test_loss: 273.5623, test_score: -\n",
      "\n",
      "Epoch [164/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.1118, train_score: -, test_loss: 273.5835, test_score: -\n",
      "\n",
      "Epoch [165/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.1019, train_score: -, test_loss: 273.6044, test_score: -\n",
      "\n",
      "Epoch [166/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.0924, train_score: -, test_loss: 273.6250, test_score: -\n",
      "\n",
      "Epoch [167/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.0835, train_score: -, test_loss: 273.6454, test_score: -\n",
      "\n",
      "Epoch [168/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.0748, train_score: -, test_loss: 273.6655, test_score: -\n",
      "\n",
      "Epoch [169/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.0665, train_score: -, test_loss: 273.6854, test_score: -\n",
      "\n",
      "Epoch [170/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.0588, train_score: -, test_loss: 273.7048, test_score: -\n",
      "\n",
      "Epoch [171/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.0513, train_score: -, test_loss: 273.7242, test_score: -\n",
      "\n",
      "Epoch [172/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.0443, train_score: -, test_loss: 273.7431, test_score: -\n",
      "\n",
      "Epoch [173/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.0374, train_score: -, test_loss: 273.7619, test_score: -\n",
      "\n",
      "Epoch [174/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.0310, train_score: -, test_loss: 273.7803, test_score: -\n",
      "\n",
      "Epoch [175/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.0248, train_score: -, test_loss: 273.7984, test_score: -\n",
      "\n",
      "Epoch [176/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.0190, train_score: -, test_loss: 273.8163, test_score: -\n",
      "\n",
      "Epoch [177/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.0134, train_score: -, test_loss: 273.8339, test_score: -\n",
      "\n",
      "Epoch [178/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.0080, train_score: -, test_loss: 273.8512, test_score: -\n",
      "\n",
      "Epoch [179/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 354.0029, train_score: -, test_loss: 273.8683, test_score: -\n",
      "\n",
      "Epoch [180/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9980, train_score: -, test_loss: 273.8850, test_score: -\n",
      "\n",
      "Epoch [181/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9934, train_score: -, test_loss: 273.9015, test_score: -\n",
      "\n",
      "Epoch [182/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9890, train_score: -, test_loss: 273.9177, test_score: -\n",
      "\n",
      "Epoch [183/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9848, train_score: -, test_loss: 273.9336, test_score: -\n",
      "\n",
      "Epoch [184/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9808, train_score: -, test_loss: 273.9493, test_score: -\n",
      "\n",
      "Epoch [185/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9770, train_score: -, test_loss: 273.9647, test_score: -\n",
      "\n",
      "Epoch [186/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9733, train_score: -, test_loss: 273.9799, test_score: -\n",
      "\n",
      "Epoch [187/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9698, train_score: -, test_loss: 273.9948, test_score: -\n",
      "\n",
      "Epoch [188/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9665, train_score: -, test_loss: 274.0094, test_score: -\n",
      "\n",
      "Epoch [189/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9633, train_score: -, test_loss: 274.0237, test_score: -\n",
      "\n",
      "Epoch [190/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9603, train_score: -, test_loss: 274.0378, test_score: -\n",
      "\n",
      "Epoch [191/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9574, train_score: -, test_loss: 274.0517, test_score: -\n",
      "\n",
      "Epoch [192/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9546, train_score: -, test_loss: 274.0653, test_score: -\n",
      "\n",
      "Epoch [193/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9520, train_score: -, test_loss: 274.0787, test_score: -\n",
      "\n",
      "Epoch [194/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9495, train_score: -, test_loss: 274.0918, test_score: -\n",
      "\n",
      "Epoch [195/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9471, train_score: -, test_loss: 274.1047, test_score: -\n",
      "\n",
      "Epoch [196/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9448, train_score: -, test_loss: 274.1173, test_score: -\n",
      "\n",
      "Epoch [197/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9427, train_score: -, test_loss: 274.1298, test_score: -\n",
      "\n",
      "Epoch [198/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9406, train_score: -, test_loss: 274.1420, test_score: -\n",
      "\n",
      "Epoch [199/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9386, train_score: -, test_loss: 274.1539, test_score: -\n",
      "\n",
      "Epoch [200/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9367, train_score: -, test_loss: 274.1656, test_score: -\n",
      "\n",
      "Epoch [201/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9349, train_score: -, test_loss: 274.1772, test_score: -\n",
      "\n",
      "Epoch [202/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9332, train_score: -, test_loss: 274.1884, test_score: -\n",
      "\n",
      "Epoch [203/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9315, train_score: -, test_loss: 274.1995, test_score: -\n",
      "\n",
      "Epoch [204/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9300, train_score: -, test_loss: 274.2104, test_score: -\n",
      "\n",
      "Epoch [205/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9285, train_score: -, test_loss: 274.2210, test_score: -\n",
      "\n",
      "Epoch [206/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9271, train_score: -, test_loss: 274.2314, test_score: -\n",
      "\n",
      "Epoch [207/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9258, train_score: -, test_loss: 274.2417, test_score: -\n",
      "\n",
      "Epoch [208/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9244, train_score: -, test_loss: 274.2517, test_score: -\n",
      "\n",
      "Epoch [209/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9232, train_score: -, test_loss: 274.2616, test_score: -\n",
      "\n",
      "Epoch [210/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9220, train_score: -, test_loss: 274.2713, test_score: -\n",
      "\n",
      "Epoch [211/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9209, train_score: -, test_loss: 274.2807, test_score: -\n",
      "\n",
      "Epoch [212/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9198, train_score: -, test_loss: 274.2900, test_score: -\n",
      "\n",
      "Epoch [213/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9188, train_score: -, test_loss: 274.2991, test_score: -\n",
      "\n",
      "Epoch [214/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9178, train_score: -, test_loss: 274.3081, test_score: -\n",
      "\n",
      "Epoch [215/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9169, train_score: -, test_loss: 274.3168, test_score: -\n",
      "\n",
      "Epoch [216/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9160, train_score: -, test_loss: 274.3254, test_score: -\n",
      "\n",
      "Epoch [217/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9152, train_score: -, test_loss: 274.3338, test_score: -\n",
      "\n",
      "Epoch [218/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9144, train_score: -, test_loss: 274.3420, test_score: -\n",
      "\n",
      "Epoch [219/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9136, train_score: -, test_loss: 274.3501, test_score: -\n",
      "\n",
      "Epoch [220/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9128, train_score: -, test_loss: 274.3580, test_score: -\n",
      "\n",
      "Epoch [221/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9121, train_score: -, test_loss: 274.3657, test_score: -\n",
      "\n",
      "Epoch [222/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9115, train_score: -, test_loss: 274.3734, test_score: -\n",
      "\n",
      "Epoch [223/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9109, train_score: -, test_loss: 274.3807, test_score: -\n",
      "\n",
      "Epoch [224/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9102, train_score: -, test_loss: 274.3881, test_score: -\n",
      "\n",
      "Epoch [225/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9096, train_score: -, test_loss: 274.3952, test_score: -\n",
      "\n",
      "Epoch [226/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9090, train_score: -, test_loss: 274.4022, test_score: -\n",
      "\n",
      "Epoch [227/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9086, train_score: -, test_loss: 274.4091, test_score: -\n",
      "\n",
      "Epoch [228/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9081, train_score: -, test_loss: 274.4157, test_score: -\n",
      "\n",
      "Epoch [229/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9075, train_score: -, test_loss: 274.4223, test_score: -\n",
      "\n",
      "Epoch [230/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9071, train_score: -, test_loss: 274.4288, test_score: -\n",
      "\n",
      "Epoch [231/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9067, train_score: -, test_loss: 274.4351, test_score: -\n",
      "\n",
      "Epoch [232/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9062, train_score: -, test_loss: 274.4413, test_score: -\n",
      "\n",
      "Epoch [233/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9059, train_score: -, test_loss: 274.4473, test_score: -\n",
      "\n",
      "Epoch [234/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9054, train_score: -, test_loss: 274.4533, test_score: -\n",
      "\n",
      "Epoch [235/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9051, train_score: -, test_loss: 274.4590, test_score: -\n",
      "\n",
      "Epoch [236/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9047, train_score: -, test_loss: 274.4647, test_score: -\n",
      "\n",
      "Epoch [237/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9044, train_score: -, test_loss: 274.4703, test_score: -\n",
      "\n",
      "Epoch [238/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9042, train_score: -, test_loss: 274.4758, test_score: -\n",
      "\n",
      "Epoch [239/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9038, train_score: -, test_loss: 274.4811, test_score: -\n",
      "\n",
      "Epoch [240/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9035, train_score: -, test_loss: 274.4864, test_score: -\n",
      "\n",
      "Epoch [241/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9032, train_score: -, test_loss: 274.4914, test_score: -\n",
      "\n",
      "Epoch [242/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9030, train_score: -, test_loss: 274.4965, test_score: -\n",
      "\n",
      "Epoch [243/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9028, train_score: -, test_loss: 274.5014, test_score: -\n",
      "\n",
      "Epoch [244/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9025, train_score: -, test_loss: 274.5062, test_score: -\n",
      "\n",
      "Epoch [245/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9022, train_score: -, test_loss: 274.5109, test_score: -\n",
      "\n",
      "Epoch [246/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9020, train_score: -, test_loss: 274.5155, test_score: -\n",
      "\n",
      "Epoch [247/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9018, train_score: -, test_loss: 274.5201, test_score: -\n",
      "\n",
      "Epoch [248/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9016, train_score: -, test_loss: 274.5244, test_score: -\n",
      "\n",
      "Epoch [249/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9015, train_score: -, test_loss: 274.5287, test_score: -\n",
      "\n",
      "Epoch [250/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9012, train_score: -, test_loss: 274.5331, test_score: -\n",
      "\n",
      "Epoch [251/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9011, train_score: -, test_loss: 274.5371, test_score: -\n",
      "\n",
      "Epoch [252/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9009, train_score: -, test_loss: 274.5412, test_score: -\n",
      "\n",
      "Epoch [253/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9008, train_score: -, test_loss: 274.5452, test_score: -\n",
      "\n",
      "Epoch [254/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9007, train_score: -, test_loss: 274.5491, test_score: -\n",
      "\n",
      "Epoch [255/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9004, train_score: -, test_loss: 274.5528, test_score: -\n",
      "\n",
      "Epoch [256/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9004, train_score: -, test_loss: 274.5566, test_score: -\n",
      "\n",
      "Epoch [257/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9002, train_score: -, test_loss: 274.5602, test_score: -\n",
      "\n",
      "Epoch [258/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9000, train_score: -, test_loss: 274.5638, test_score: -\n",
      "\n",
      "Epoch [259/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.9000, train_score: -, test_loss: 274.5673, test_score: -\n",
      "\n",
      "Epoch [260/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8998, train_score: -, test_loss: 274.5708, test_score: -\n",
      "\n",
      "Epoch [261/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8997, train_score: -, test_loss: 274.5741, test_score: -\n",
      "\n",
      "Epoch [262/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8996, train_score: -, test_loss: 274.5773, test_score: -\n",
      "\n",
      "Epoch [263/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8995, train_score: -, test_loss: 274.5805, test_score: -\n",
      "\n",
      "Epoch [264/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8994, train_score: -, test_loss: 274.5837, test_score: -\n",
      "\n",
      "Epoch [265/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8994, train_score: -, test_loss: 274.5868, test_score: -\n",
      "\n",
      "Epoch [266/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8993, train_score: -, test_loss: 274.5898, test_score: -\n",
      "\n",
      "Epoch [267/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8992, train_score: -, test_loss: 274.5927, test_score: -\n",
      "\n",
      "Epoch [268/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8991, train_score: -, test_loss: 274.5956, test_score: -\n",
      "\n",
      "Epoch [269/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8990, train_score: -, test_loss: 274.5985, test_score: -\n",
      "\n",
      "Epoch [270/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8990, train_score: -, test_loss: 274.6013, test_score: -\n",
      "\n",
      "Epoch [271/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8988, train_score: -, test_loss: 274.6039, test_score: -\n",
      "\n",
      "Epoch [272/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8988, train_score: -, test_loss: 274.6066, test_score: -\n",
      "\n",
      "Epoch [273/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8987, train_score: -, test_loss: 274.6092, test_score: -\n",
      "\n",
      "Epoch [274/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8986, train_score: -, test_loss: 274.6117, test_score: -\n",
      "\n",
      "Epoch [275/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8986, train_score: -, test_loss: 274.6141, test_score: -\n",
      "\n",
      "Epoch [276/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8986, train_score: -, test_loss: 274.6166, test_score: -\n",
      "\n",
      "Epoch [277/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8985, train_score: -, test_loss: 274.6190, test_score: -\n",
      "\n",
      "Epoch [278/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8984, train_score: -, test_loss: 274.6213, test_score: -\n",
      "\n",
      "Epoch [279/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8984, train_score: -, test_loss: 274.6236, test_score: -\n",
      "\n",
      "Epoch [280/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8983, train_score: -, test_loss: 274.6258, test_score: -\n",
      "\n",
      "Epoch [281/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8983, train_score: -, test_loss: 274.6280, test_score: -\n",
      "\n",
      "Epoch [282/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8983, train_score: -, test_loss: 274.6302, test_score: -\n",
      "\n",
      "Epoch [283/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8983, train_score: -, test_loss: 274.6322, test_score: -\n",
      "\n",
      "Epoch [284/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8982, train_score: -, test_loss: 274.6343, test_score: -\n",
      "\n",
      "Epoch [285/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8981, train_score: -, test_loss: 274.6363, test_score: -\n",
      "\n",
      "Epoch [286/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8981, train_score: -, test_loss: 274.6382, test_score: -\n",
      "\n",
      "Epoch [287/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8981, train_score: -, test_loss: 274.6402, test_score: -\n",
      "\n",
      "Epoch [288/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8980, train_score: -, test_loss: 274.6421, test_score: -\n",
      "\n",
      "Epoch [289/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8981, train_score: -, test_loss: 274.6439, test_score: -\n",
      "\n",
      "Epoch [290/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8980, train_score: -, test_loss: 274.6457, test_score: -\n",
      "\n",
      "Epoch [291/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8980, train_score: -, test_loss: 274.6474, test_score: -\n",
      "\n",
      "Epoch [292/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8979, train_score: -, test_loss: 274.6492, test_score: -\n",
      "\n",
      "Epoch [293/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8980, train_score: -, test_loss: 274.6508, test_score: -\n",
      "\n",
      "Epoch [294/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8979, train_score: -, test_loss: 274.6525, test_score: -\n",
      "\n",
      "Epoch [295/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8979, train_score: -, test_loss: 274.6541, test_score: -\n",
      "\n",
      "Epoch [296/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8979, train_score: -, test_loss: 274.6557, test_score: -\n",
      "\n",
      "Epoch [297/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8978, train_score: -, test_loss: 274.6573, test_score: -\n",
      "\n",
      "Epoch [298/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8979, train_score: -, test_loss: 274.6588, test_score: -\n",
      "\n",
      "Epoch [299/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8978, train_score: -, test_loss: 274.6603, test_score: -\n",
      "\n",
      "Epoch [300/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8978, train_score: -, test_loss: 274.6617, test_score: -\n",
      "\n",
      "Epoch [301/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8978, train_score: -, test_loss: 274.6631, test_score: -\n",
      "\n",
      "Epoch [302/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8978, train_score: -, test_loss: 274.6645, test_score: -\n",
      "\n",
      "Epoch [303/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8977, train_score: -, test_loss: 274.6658, test_score: -\n",
      "\n",
      "Epoch [304/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8977, train_score: -, test_loss: 274.6672, test_score: -\n",
      "\n",
      "Epoch [305/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8977, train_score: -, test_loss: 274.6685, test_score: -\n",
      "\n",
      "Epoch [306/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6697, test_score: -\n",
      "\n",
      "Epoch [307/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8977, train_score: -, test_loss: 274.6710, test_score: -\n",
      "\n",
      "Epoch [308/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8977, train_score: -, test_loss: 274.6722, test_score: -\n",
      "\n",
      "Epoch [309/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6734, test_score: -\n",
      "\n",
      "Epoch [310/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6746, test_score: -\n",
      "\n",
      "Epoch [311/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6757, test_score: -\n",
      "\n",
      "Epoch [312/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6768, test_score: -\n",
      "\n",
      "Epoch [313/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6779, test_score: -\n",
      "\n",
      "Epoch [314/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6790, test_score: -\n",
      "\n",
      "Epoch [315/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6801, test_score: -\n",
      "\n",
      "Epoch [316/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6811, test_score: -\n",
      "\n",
      "Epoch [317/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6821, test_score: -\n",
      "\n",
      "Epoch [318/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6831, test_score: -\n",
      "\n",
      "Epoch [319/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6840, test_score: -\n",
      "\n",
      "Epoch [320/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6850, test_score: -\n",
      "\n",
      "Epoch [321/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6859, test_score: -\n",
      "\n",
      "Epoch [322/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6868, test_score: -\n",
      "\n",
      "Epoch [323/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6877, test_score: -\n",
      "\n",
      "Epoch [324/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6886, test_score: -\n",
      "\n",
      "Epoch [325/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.6894, test_score: -\n",
      "\n",
      "Epoch [326/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.6902, test_score: -\n",
      "\n",
      "Epoch [327/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6910, test_score: -\n",
      "\n",
      "Epoch [328/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.6918, test_score: -\n",
      "\n",
      "Epoch [329/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.6926, test_score: -\n",
      "\n",
      "Epoch [330/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.6933, test_score: -\n",
      "\n",
      "Epoch [331/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.6941, test_score: -\n",
      "\n",
      "Epoch [332/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8976, train_score: -, test_loss: 274.6948, test_score: -\n",
      "\n",
      "Epoch [333/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.6955, test_score: -\n",
      "\n",
      "Epoch [334/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.6962, test_score: -\n",
      "\n",
      "Epoch [335/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.6969, test_score: -\n",
      "\n",
      "Epoch [336/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.6976, test_score: -\n",
      "\n",
      "Epoch [337/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.6982, test_score: -\n",
      "\n",
      "Epoch [338/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.6989, test_score: -\n",
      "\n",
      "Epoch [339/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.6995, test_score: -\n",
      "\n",
      "Epoch [340/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7001, test_score: -\n",
      "\n",
      "Epoch [341/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7007, test_score: -\n",
      "\n",
      "Epoch [342/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7013, test_score: -\n",
      "\n",
      "Epoch [343/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7018, test_score: -\n",
      "\n",
      "Epoch [344/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7024, test_score: -\n",
      "\n",
      "Epoch [345/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7029, test_score: -\n",
      "\n",
      "Epoch [346/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7035, test_score: -\n",
      "\n",
      "Epoch [347/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7040, test_score: -\n",
      "\n",
      "Epoch [348/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7046, test_score: -\n",
      "\n",
      "Epoch [349/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7050, test_score: -\n",
      "\n",
      "Epoch [350/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7055, test_score: -\n",
      "\n",
      "Epoch [351/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7060, test_score: -\n",
      "\n",
      "Epoch [352/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7065, test_score: -\n",
      "\n",
      "Epoch [353/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7069, test_score: -\n",
      "\n",
      "Epoch [354/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7074, test_score: -\n",
      "\n",
      "Epoch [355/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7078, test_score: -\n",
      "\n",
      "Epoch [356/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7083, test_score: -\n",
      "\n",
      "Epoch [357/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7087, test_score: -\n",
      "\n",
      "Epoch [358/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7091, test_score: -\n",
      "\n",
      "Epoch [359/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7095, test_score: -\n",
      "\n",
      "Epoch [360/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7099, test_score: -\n",
      "\n",
      "Epoch [361/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7103, test_score: -\n",
      "\n",
      "Epoch [362/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7107, test_score: -\n",
      "\n",
      "Epoch [363/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7111, test_score: -\n",
      "\n",
      "Epoch [364/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7114, test_score: -\n",
      "\n",
      "Epoch [365/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7118, test_score: -\n",
      "\n",
      "Epoch [366/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7121, test_score: -\n",
      "\n",
      "Epoch [367/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7125, test_score: -\n",
      "\n",
      "Epoch [368/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7128, test_score: -\n",
      "\n",
      "Epoch [369/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7131, test_score: -\n",
      "\n",
      "Epoch [370/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7134, test_score: -\n",
      "\n",
      "Epoch [371/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7137, test_score: -\n",
      "\n",
      "Epoch [372/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7141, test_score: -\n",
      "\n",
      "Epoch [373/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7144, test_score: -\n",
      "\n",
      "Epoch [374/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7147, test_score: -\n",
      "\n",
      "Epoch [375/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7149, test_score: -\n",
      "\n",
      "Epoch [376/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7152, test_score: -\n",
      "\n",
      "Epoch [377/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7155, test_score: -\n",
      "\n",
      "Epoch [378/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7158, test_score: -\n",
      "\n",
      "Epoch [379/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7161, test_score: -\n",
      "\n",
      "Epoch [380/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7163, test_score: -\n",
      "\n",
      "Epoch [381/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7166, test_score: -\n",
      "\n",
      "Epoch [382/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7168, test_score: -\n",
      "\n",
      "Epoch [383/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7170, test_score: -\n",
      "\n",
      "Epoch [384/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7173, test_score: -\n",
      "\n",
      "Epoch [385/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7175, test_score: -\n",
      "\n",
      "Epoch [386/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7177, test_score: -\n",
      "\n",
      "Epoch [387/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7180, test_score: -\n",
      "\n",
      "Epoch [388/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7182, test_score: -\n",
      "\n",
      "Epoch [389/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7184, test_score: -\n",
      "\n",
      "Epoch [390/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7186, test_score: -\n",
      "\n",
      "Epoch [391/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7189, test_score: -\n",
      "\n",
      "Epoch [392/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7190, test_score: -\n",
      "\n",
      "Epoch [393/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7192, test_score: -\n",
      "\n",
      "Epoch [394/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7194, test_score: -\n",
      "\n",
      "Epoch [395/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7196, test_score: -\n",
      "\n",
      "Epoch [396/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7198, test_score: -\n",
      "\n",
      "Epoch [397/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7200, test_score: -\n",
      "\n",
      "Epoch [398/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7201, test_score: -\n",
      "\n",
      "Epoch [399/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7203, test_score: -\n",
      "\n",
      "Epoch [400/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7205, test_score: -\n",
      "\n",
      "Epoch [401/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7206, test_score: -\n",
      "\n",
      "Epoch [402/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7208, test_score: -\n",
      "\n",
      "Epoch [403/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7209, test_score: -\n",
      "\n",
      "Epoch [404/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7211, test_score: -\n",
      "\n",
      "Epoch [405/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7213, test_score: -\n",
      "\n",
      "Epoch [406/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7214, test_score: -\n",
      "\n",
      "Epoch [407/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7216, test_score: -\n",
      "\n",
      "Epoch [408/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7217, test_score: -\n",
      "\n",
      "Epoch [409/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7219, test_score: -\n",
      "\n",
      "Epoch [410/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7220, test_score: -\n",
      "\n",
      "Epoch [411/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7221, test_score: -\n",
      "\n",
      "Epoch [412/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7223, test_score: -\n",
      "\n",
      "Epoch [413/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7224, test_score: -\n",
      "\n",
      "Epoch [414/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7225, test_score: -\n",
      "\n",
      "Epoch [415/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7226, test_score: -\n",
      "\n",
      "Epoch [416/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7227, test_score: -\n",
      "\n",
      "Epoch [417/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7228, test_score: -\n",
      "\n",
      "Epoch [418/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7230, test_score: -\n",
      "\n",
      "Epoch [419/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7231, test_score: -\n",
      "\n",
      "Epoch [420/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7232, test_score: -\n",
      "\n",
      "Epoch [421/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7233, test_score: -\n",
      "\n",
      "Epoch [422/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7234, test_score: -\n",
      "\n",
      "Epoch [423/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7235, test_score: -\n",
      "\n",
      "Epoch [424/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7236, test_score: -\n",
      "\n",
      "Epoch [425/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7237, test_score: -\n",
      "\n",
      "Epoch [426/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7238, test_score: -\n",
      "\n",
      "Epoch [427/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7239, test_score: -\n",
      "\n",
      "Epoch [428/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7239, test_score: -\n",
      "\n",
      "Epoch [429/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7240, test_score: -\n",
      "\n",
      "Epoch [430/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7242, test_score: -\n",
      "\n",
      "Epoch [431/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7242, test_score: -\n",
      "\n",
      "Epoch [432/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7243, test_score: -\n",
      "\n",
      "Epoch [433/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7244, test_score: -\n",
      "\n",
      "Epoch [434/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7245, test_score: -\n",
      "\n",
      "Epoch [435/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7246, test_score: -\n",
      "\n",
      "Epoch [436/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7247, test_score: -\n",
      "\n",
      "Epoch [437/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7248, test_score: -\n",
      "\n",
      "Epoch [438/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7248, test_score: -\n",
      "\n",
      "Epoch [439/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7249, test_score: -\n",
      "\n",
      "Epoch [440/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7250, test_score: -\n",
      "\n",
      "Epoch [441/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7251, test_score: -\n",
      "\n",
      "Epoch [442/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7251, test_score: -\n",
      "\n",
      "Epoch [443/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7252, test_score: -\n",
      "\n",
      "Epoch [444/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7252, test_score: -\n",
      "\n",
      "Epoch [445/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7253, test_score: -\n",
      "\n",
      "Epoch [446/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7254, test_score: -\n",
      "\n",
      "Epoch [447/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7254, test_score: -\n",
      "\n",
      "Epoch [448/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7255, test_score: -\n",
      "\n",
      "Epoch [449/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7256, test_score: -\n",
      "\n",
      "Epoch [450/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7256, test_score: -\n",
      "\n",
      "Epoch [451/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7257, test_score: -\n",
      "\n",
      "Epoch [452/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7257, test_score: -\n",
      "\n",
      "Epoch [453/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7258, test_score: -\n",
      "\n",
      "Epoch [454/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7258, test_score: -\n",
      "\n",
      "Epoch [455/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7259, test_score: -\n",
      "\n",
      "Epoch [456/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7260, test_score: -\n",
      "\n",
      "Epoch [457/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7260, test_score: -\n",
      "\n",
      "Epoch [458/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7260, test_score: -\n",
      "\n",
      "Epoch [459/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7261, test_score: -\n",
      "\n",
      "Epoch [460/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7261, test_score: -\n",
      "\n",
      "Epoch [461/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7262, test_score: -\n",
      "\n",
      "Epoch [462/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7262, test_score: -\n",
      "\n",
      "Epoch [463/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7263, test_score: -\n",
      "\n",
      "Epoch [464/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7263, test_score: -\n",
      "\n",
      "Epoch [465/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7263, test_score: -\n",
      "\n",
      "Epoch [466/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7264, test_score: -\n",
      "\n",
      "Epoch [467/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7264, test_score: -\n",
      "\n",
      "Epoch [468/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7264, test_score: -\n",
      "\n",
      "Epoch [469/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7265, test_score: -\n",
      "\n",
      "Epoch [470/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7266, test_score: -\n",
      "\n",
      "Epoch [471/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7266, test_score: -\n",
      "\n",
      "Epoch [472/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7266, test_score: -\n",
      "\n",
      "Epoch [473/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7267, test_score: -\n",
      "\n",
      "Epoch [474/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7267, test_score: -\n",
      "\n",
      "Epoch [475/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7267, test_score: -\n",
      "\n",
      "Epoch [476/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7267, test_score: -\n",
      "\n",
      "Epoch [477/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7268, test_score: -\n",
      "\n",
      "Epoch [478/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7268, test_score: -\n",
      "\n",
      "Epoch [479/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7268, test_score: -\n",
      "\n",
      "Epoch [480/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7269, test_score: -\n",
      "\n",
      "Epoch [481/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7270, test_score: -\n",
      "\n",
      "Epoch [482/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7270, test_score: -\n",
      "\n",
      "Epoch [483/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7270, test_score: -\n",
      "\n",
      "Epoch [484/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7270, test_score: -\n",
      "\n",
      "Epoch [485/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7270, test_score: -\n",
      "\n",
      "Epoch [486/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7271, test_score: -\n",
      "\n",
      "Epoch [487/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7271, test_score: -\n",
      "\n",
      "Epoch [488/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7271, test_score: -\n",
      "\n",
      "Epoch [489/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7271, test_score: -\n",
      "\n",
      "Epoch [490/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7272, test_score: -\n",
      "\n",
      "Epoch [491/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7272, test_score: -\n",
      "\n",
      "Epoch [492/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7272, test_score: -\n",
      "\n",
      "Epoch [493/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7272, test_score: -\n",
      "\n",
      "Epoch [494/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7272, test_score: -\n",
      "\n",
      "Epoch [495/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7273, test_score: -\n",
      "\n",
      "Epoch [496/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7273, test_score: -\n",
      "\n",
      "Epoch [497/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7274, test_score: -\n",
      "\n",
      "Epoch [498/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7274, test_score: -\n",
      "\n",
      "Epoch [499/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7274, test_score: -\n",
      "\n",
      "Epoch [500/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7274, test_score: -\n",
      "\n",
      "Epoch [501/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7274, test_score: -\n",
      "\n",
      "Epoch [502/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7274, test_score: -\n",
      "\n",
      "Epoch [503/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7275, test_score: -\n",
      "\n",
      "Epoch [504/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7275, test_score: -\n",
      "\n",
      "Epoch [505/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7275, test_score: -\n",
      "\n",
      "Epoch [506/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7275, test_score: -\n",
      "\n",
      "Epoch [507/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7276, test_score: -\n",
      "\n",
      "Epoch [508/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7276, test_score: -\n",
      "\n",
      "Epoch [509/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7276, test_score: -\n",
      "\n",
      "Epoch [510/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7276, test_score: -\n",
      "\n",
      "Epoch [511/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7276, test_score: -\n",
      "\n",
      "Epoch [512/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7276, test_score: -\n",
      "\n",
      "Epoch [513/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7277, test_score: -\n",
      "\n",
      "Epoch [514/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7277, test_score: -\n",
      "\n",
      "Epoch [515/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7277, test_score: -\n",
      "\n",
      "Epoch [516/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7277, test_score: -\n",
      "\n",
      "Epoch [517/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7277, test_score: -\n",
      "\n",
      "Epoch [518/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7277, test_score: -\n",
      "\n",
      "Epoch [519/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7277, test_score: -\n",
      "\n",
      "Epoch [520/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7277, test_score: -\n",
      "\n",
      "Epoch [521/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7277, test_score: -\n",
      "\n",
      "Epoch [522/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7277, test_score: -\n",
      "\n",
      "Epoch [523/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7278, test_score: -\n",
      "\n",
      "Epoch [524/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7278, test_score: -\n",
      "\n",
      "Epoch [525/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7278, test_score: -\n",
      "\n",
      "Epoch [526/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7278, test_score: -\n",
      "\n",
      "Epoch [527/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7278, test_score: -\n",
      "\n",
      "Epoch [528/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7278, test_score: -\n",
      "\n",
      "Epoch [529/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7278, test_score: -\n",
      "\n",
      "Epoch [530/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7278, test_score: -\n",
      "\n",
      "Epoch [531/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7279, test_score: -\n",
      "\n",
      "Epoch [532/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7278, test_score: -\n",
      "\n",
      "Epoch [533/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7279, test_score: -\n",
      "\n",
      "Epoch [534/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7279, test_score: -\n",
      "\n",
      "Epoch [535/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7279, test_score: -\n",
      "\n",
      "Epoch [536/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7279, test_score: -\n",
      "\n",
      "Epoch [537/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7279, test_score: -\n",
      "\n",
      "Epoch [538/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7279, test_score: -\n",
      "\n",
      "Epoch [539/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7279, test_score: -\n",
      "\n",
      "Epoch [540/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7279, test_score: -\n",
      "\n",
      "Epoch [541/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7279, test_score: -\n",
      "\n",
      "Epoch [542/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7279, test_score: -\n",
      "\n",
      "Epoch [543/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7280, test_score: -\n",
      "\n",
      "Epoch [544/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7280, test_score: -\n",
      "\n",
      "Epoch [545/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7280, test_score: -\n",
      "\n",
      "Epoch [546/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7280, test_score: -\n",
      "\n",
      "Epoch [547/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [548/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7280, test_score: -\n",
      "\n",
      "Epoch [549/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [550/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7280, test_score: -\n",
      "\n",
      "Epoch [551/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7280, test_score: -\n",
      "\n",
      "Epoch [552/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [553/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [554/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [555/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [556/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [557/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [558/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [559/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [560/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [561/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [562/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [563/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [564/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [565/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [566/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [567/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [568/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [569/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [570/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [571/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [572/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [573/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [574/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [575/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [576/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [577/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [578/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [579/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [580/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [581/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [582/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [583/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [584/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [585/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [586/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [587/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [588/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [589/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [590/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [591/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [592/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [593/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [594/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [595/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [596/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [597/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [598/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [599/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7281, test_score: -\n",
      "\n",
      "Epoch [600/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [601/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [602/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [603/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [604/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [605/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [606/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [607/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [608/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [609/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [610/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [611/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [612/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [613/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [614/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [615/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [616/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [617/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [618/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [619/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [620/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [621/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [622/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [623/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [624/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [625/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [626/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [627/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [628/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [629/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [630/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [631/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [632/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [633/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [634/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [635/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [636/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [637/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [638/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [639/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [640/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [641/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [642/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [643/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [644/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [645/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [646/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [647/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [648/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [649/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [650/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [651/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [652/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [653/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [654/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [655/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [656/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [657/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [658/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [659/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [660/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [661/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [662/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [663/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [664/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [665/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [666/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [667/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [668/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [669/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [670/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [671/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [672/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [673/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [674/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [675/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [676/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [677/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [678/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7282, test_score: -\n",
      "\n",
      "Epoch [679/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [680/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [681/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [682/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [683/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [684/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [685/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [686/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [687/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [688/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [689/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [690/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [691/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [692/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [693/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [694/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [695/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [696/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [697/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [698/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [699/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [700/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [701/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [702/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [703/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [704/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [705/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [706/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [707/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [708/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [709/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [710/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [711/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [712/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [713/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [714/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [715/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [716/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [717/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [718/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [719/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [720/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [721/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [722/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [723/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [724/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [725/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [726/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [727/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [728/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [729/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [730/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [731/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [732/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [733/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [734/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [735/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [736/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [737/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [738/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [739/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [740/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [741/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [742/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [743/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [744/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [745/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [746/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [747/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [748/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [749/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [750/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [751/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [752/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [753/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [754/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [755/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [756/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [757/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [758/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [759/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [760/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [761/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [762/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [763/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [764/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [765/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [766/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [767/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [768/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [769/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [770/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [771/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [772/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [773/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [774/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [775/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [776/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [777/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [778/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [779/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [780/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [781/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [782/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [783/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [784/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [785/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [786/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [787/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [788/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [789/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [790/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [791/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [792/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [793/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [794/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [795/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [796/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [797/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [798/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [799/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [800/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [801/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [802/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [803/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [804/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [805/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [806/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [807/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [808/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [809/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [810/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [811/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [812/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [813/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [814/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [815/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [816/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [817/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [818/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [819/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [820/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [821/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [822/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [823/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [824/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [825/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [826/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [827/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [828/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [829/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [830/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [831/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [832/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [833/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [834/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [835/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [836/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [837/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [838/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [839/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [840/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [841/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [842/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [843/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [844/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [845/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [846/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [847/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [848/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [849/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [850/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [851/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [852/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [853/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [854/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [855/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [856/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [857/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [858/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [859/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [860/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [861/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [862/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [863/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [864/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [865/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [866/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [867/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [868/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [869/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [870/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [871/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [872/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [873/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [874/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8975, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [875/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [876/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [877/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [878/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [879/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [880/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [881/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [882/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [883/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [884/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [885/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [886/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [887/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [888/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [889/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [890/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [891/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [892/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [893/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [894/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [895/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [896/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [897/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [898/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [899/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [900/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [901/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [902/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [903/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [904/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [905/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [906/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [907/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [908/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [909/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [910/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [911/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [912/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [913/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [914/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [915/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [916/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [917/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [918/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [919/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [920/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [921/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [922/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [923/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [924/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [925/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [926/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [927/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [928/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [929/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [930/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [931/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [932/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [933/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [934/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [935/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [936/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [937/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [938/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [939/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [940/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [941/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [942/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [943/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [944/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [945/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [946/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [947/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [948/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [949/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [950/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [951/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [952/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [953/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [954/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [955/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [956/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [957/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [958/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [959/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [960/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [961/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [962/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [963/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [964/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [965/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [966/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [967/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [968/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [969/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [970/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [971/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [972/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [973/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [974/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [975/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [976/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [977/1000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [978/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [979/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [980/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [981/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [982/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [983/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [984/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [985/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [986/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [987/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [988/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [989/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [990/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [991/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [992/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [993/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [994/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [995/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [996/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8973, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [997/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [998/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [999/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n",
      "Epoch [1000/1000]\n",
      "100/100 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 353.8974, train_score: -, test_loss: 274.7283, test_score: -\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"316.7pt\" version=\"1.1\" viewBox=\"0 0 611.15 316.7\" width=\"611.15pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2020-10-08T21:21:55.681137</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 316.7 \n",
       "L 611.15 316.7 \n",
       "L 611.15 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 45.95 279 \n",
       "L 603.95 279 \n",
       "L 603.95 7.2 \n",
       "L 45.95 7.2 \n",
       "z\n",
       "\" style=\"fill:#f5f5f5;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"ma106045317\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"71.313636\" xlink:href=\"#ma106045317\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(68.313636 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 46.484375 35.15625 \n",
       "Q 46.484375 21.09375 41.40625 10.9375 \n",
       "Q 36.328125 0.78125 25 0.78125 \n",
       "Q 13.671875 0.78125 8.390625 10.9375 \n",
       "Q 3.125 21.09375 3.125 35.15625 \n",
       "Q 3.125 49.21875 8.390625 59.171875 \n",
       "Q 13.671875 69.140625 25 69.140625 \n",
       "Q 36.328125 69.140625 41.40625 59.171875 \n",
       "Q 46.484375 49.21875 46.484375 35.15625 \n",
       "z\n",
       "M 37.109375 35.15625 \n",
       "Q 37.109375 47.65625 34.171875 54.6875 \n",
       "Q 31.25 61.71875 25 61.71875 \n",
       "Q 18.75 61.71875 15.625 54.6875 \n",
       "Q 12.5 47.65625 12.5 35.15625 \n",
       "Q 12.5 22.65625 15.625 15.421875 \n",
       "Q 18.75 8.203125 25 8.203125 \n",
       "Q 31.25 8.203125 34.171875 15.421875 \n",
       "Q 37.109375 22.65625 37.109375 35.15625 \n",
       "z\n",
       "\" id=\"SimHei-48\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"172.869738\" xlink:href=\"#ma106045317\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(163.869738 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 44.53125 1.5625 \n",
       "L 4.6875 1.5625 \n",
       "L 4.6875 7.8125 \n",
       "Q 7.03125 14.0625 11.125 19.328125 \n",
       "Q 15.234375 24.609375 23.046875 31.25 \n",
       "Q 28.90625 36.328125 31.4375 40.625 \n",
       "Q 33.984375 44.921875 33.984375 50 \n",
       "Q 33.984375 55.078125 31.828125 58.390625 \n",
       "Q 29.6875 61.71875 25 61.71875 \n",
       "Q 21.09375 61.71875 18.15625 58.203125 \n",
       "Q 15.234375 54.6875 15.234375 45.703125 \n",
       "L 6.25 45.703125 \n",
       "Q 6.640625 57.03125 11.515625 63.078125 \n",
       "Q 16.40625 69.140625 25.390625 69.140625 \n",
       "Q 33.984375 69.140625 38.671875 63.859375 \n",
       "Q 43.359375 58.59375 43.359375 49.609375 \n",
       "Q 43.359375 42.1875 39.0625 36.71875 \n",
       "Q 34.765625 31.25 28.515625 25.78125 \n",
       "Q 21.484375 19.53125 18.75 16.40625 \n",
       "Q 16.015625 13.28125 13.671875 8.984375 \n",
       "L 44.53125 8.984375 \n",
       "z\n",
       "\" id=\"SimHei-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"274.425839\" xlink:href=\"#ma106045317\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(265.425839 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 46.484375 18.75 \n",
       "L 38.28125 18.75 \n",
       "L 38.28125 1.5625 \n",
       "L 29.296875 1.5625 \n",
       "L 29.296875 18.75 \n",
       "L 3.125 18.75 \n",
       "L 3.125 26.171875 \n",
       "L 29.296875 69.140625 \n",
       "L 38.28125 69.140625 \n",
       "L 38.28125 26.171875 \n",
       "L 46.484375 26.171875 \n",
       "z\n",
       "M 29.296875 26.171875 \n",
       "L 29.296875 55.078125 \n",
       "L 11.71875 26.171875 \n",
       "z\n",
       "\" id=\"SimHei-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-52\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"375.981941\" xlink:href=\"#ma106045317\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 600 -->\n",
       "      <g transform=\"translate(366.981941 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 44.53125 24.21875 \n",
       "Q 44.53125 13.28125 39.84375 7.03125 \n",
       "Q 35.15625 0.78125 25.78125 0.78125 \n",
       "Q 16.40625 0.78125 10.9375 8.59375 \n",
       "Q 5.46875 16.40625 5.46875 33.984375 \n",
       "Q 5.46875 50 11.125 59.5625 \n",
       "Q 16.796875 69.140625 27.34375 69.140625 \n",
       "Q 34.765625 69.140625 39.25 63.671875 \n",
       "Q 43.75 58.203125 43.75 51.5625 \n",
       "L 34.765625 51.5625 \n",
       "Q 34.765625 55.46875 32.609375 58.59375 \n",
       "Q 30.46875 61.71875 26.953125 61.71875 \n",
       "Q 21.09375 61.71875 17.96875 55.65625 \n",
       "Q 14.84375 49.609375 14.453125 37.109375 \n",
       "Q 17.1875 42.1875 20.3125 44.140625 \n",
       "Q 23.4375 46.09375 27.734375 46.09375 \n",
       "Q 35.15625 46.09375 39.84375 40.234375 \n",
       "Q 44.53125 34.375 44.53125 24.21875 \n",
       "z\n",
       "M 35.15625 24.21875 \n",
       "Q 35.15625 31.25 32.8125 35.15625 \n",
       "Q 30.46875 39.0625 26.171875 39.0625 \n",
       "Q 21.09375 39.0625 18.15625 35.15625 \n",
       "Q 15.234375 31.25 15.234375 25.78125 \n",
       "Q 15.234375 17.1875 18.15625 12.5 \n",
       "Q 21.09375 7.8125 26.171875 7.8125 \n",
       "Q 29.6875 7.8125 32.421875 11.328125 \n",
       "Q 35.15625 14.84375 35.15625 24.21875 \n",
       "z\n",
       "\" id=\"SimHei-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-54\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"477.538043\" xlink:href=\"#ma106045317\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 800 -->\n",
       "      <g transform=\"translate(468.538043 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 44.921875 20.703125 \n",
       "Q 44.921875 10.9375 39.453125 5.859375 \n",
       "Q 33.984375 0.78125 24.609375 0.78125 \n",
       "Q 15.234375 0.78125 9.765625 5.859375 \n",
       "Q 4.296875 10.9375 4.296875 20.703125 \n",
       "Q 4.296875 25.78125 7.421875 29.875 \n",
       "Q 10.546875 33.984375 16.015625 35.9375 \n",
       "Q 11.328125 37.890625 8.78125 41.40625 \n",
       "Q 6.25 44.921875 6.25 50.390625 \n",
       "Q 6.25 58.984375 11.71875 64.0625 \n",
       "Q 17.1875 69.140625 24.609375 69.140625 \n",
       "Q 32.03125 69.140625 37.5 64.0625 \n",
       "Q 42.96875 58.984375 42.96875 50.390625 \n",
       "Q 42.96875 44.921875 40.421875 41.40625 \n",
       "Q 37.890625 37.890625 33.203125 35.9375 \n",
       "Q 38.671875 33.984375 41.796875 29.875 \n",
       "Q 44.921875 25.78125 44.921875 20.703125 \n",
       "z\n",
       "M 34.375 50.390625 \n",
       "Q 34.375 56.640625 31.640625 59.375 \n",
       "Q 28.90625 62.109375 24.609375 62.109375 \n",
       "Q 20.3125 62.109375 17.578125 59.375 \n",
       "Q 14.84375 56.640625 14.84375 50.390625 \n",
       "Q 14.84375 44.140625 17.765625 41.59375 \n",
       "Q 20.703125 39.0625 24.609375 39.0625 \n",
       "Q 28.515625 39.0625 31.4375 41.59375 \n",
       "Q 34.375 44.140625 34.375 50.390625 \n",
       "z\n",
       "M 35.9375 20.703125 \n",
       "Q 35.9375 26.171875 33 29.296875 \n",
       "Q 30.078125 32.421875 24.609375 32.421875 \n",
       "Q 19.140625 32.421875 16.203125 29.296875 \n",
       "Q 13.28125 26.171875 13.28125 20.703125 \n",
       "Q 13.28125 14.453125 16.40625 11.125 \n",
       "Q 19.53125 7.8125 24.609375 7.8125 \n",
       "Q 29.6875 7.8125 32.8125 11.125 \n",
       "Q 35.9375 14.453125 35.9375 20.703125 \n",
       "z\n",
       "\" id=\"SimHei-56\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-56\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"579.094144\" xlink:href=\"#ma106045317\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1000 -->\n",
       "      <g transform=\"translate(567.094144 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 30.46875 1.5625 \n",
       "L 21.484375 1.5625 \n",
       "L 21.484375 53.515625 \n",
       "L 9.765625 53.515625 \n",
       "L 9.765625 58.203125 \n",
       "Q 16.796875 58.203125 20.703125 60.9375 \n",
       "Q 24.609375 63.671875 25.78125 69.140625 \n",
       "L 30.46875 69.140625 \n",
       "z\n",
       "\" id=\"SimHei-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- iteration num -->\n",
       "     <g transform=\"translate(285.95 307.953125)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 28.515625 57.8125 \n",
       "L 20.703125 57.8125 \n",
       "L 20.703125 67.96875 \n",
       "L 28.515625 67.96875 \n",
       "z\n",
       "M 28.515625 1.5625 \n",
       "L 20.703125 1.5625 \n",
       "L 20.703125 45.3125 \n",
       "L 28.515625 45.3125 \n",
       "z\n",
       "\" id=\"SimHei-105\"/>\n",
       "       <path d=\"M 43.359375 2.734375 \n",
       "Q 41.40625 1.953125 38.859375 1.359375 \n",
       "Q 36.328125 0.78125 32.03125 0.78125 \n",
       "Q 25 0.78125 20.703125 4.6875 \n",
       "Q 16.40625 8.59375 16.40625 15.625 \n",
       "L 16.40625 39.0625 \n",
       "L 3.125 39.0625 \n",
       "L 3.125 45.3125 \n",
       "L 16.40625 45.3125 \n",
       "L 16.40625 60.546875 \n",
       "L 24.21875 60.546875 \n",
       "L 24.21875 45.3125 \n",
       "L 40.234375 45.3125 \n",
       "L 40.234375 39.0625 \n",
       "L 24.21875 39.0625 \n",
       "L 24.21875 15.234375 \n",
       "Q 24.21875 12.109375 25.78125 9.953125 \n",
       "Q 27.34375 7.8125 31.640625 7.8125 \n",
       "Q 35.9375 7.8125 38.671875 8.59375 \n",
       "Q 41.40625 9.375 43.359375 10.546875 \n",
       "z\n",
       "\" id=\"SimHei-116\"/>\n",
       "       <path d=\"M 44.921875 16.40625 \n",
       "Q 44.140625 9.375 38.671875 5.078125 \n",
       "Q 33.203125 0.78125 25.78125 0.78125 \n",
       "Q 16.40625 0.78125 10.34375 6.828125 \n",
       "Q 4.296875 12.890625 4.296875 23.4375 \n",
       "Q 4.296875 33.984375 10.34375 40.03125 \n",
       "Q 16.40625 46.09375 25.78125 46.09375 \n",
       "Q 33.984375 46.09375 39.25 40.8125 \n",
       "Q 44.53125 35.546875 44.53125 23.4375 \n",
       "L 12.890625 23.4375 \n",
       "Q 12.890625 14.84375 16.59375 11.328125 \n",
       "Q 20.3125 7.8125 25.78125 7.8125 \n",
       "Q 30.078125 7.8125 32.8125 9.953125 \n",
       "Q 35.546875 12.109375 36.328125 16.40625 \n",
       "z\n",
       "M 35.546875 29.6875 \n",
       "Q 34.765625 35.15625 32.03125 37.296875 \n",
       "Q 29.296875 39.453125 25 39.453125 \n",
       "Q 21.09375 39.453125 17.96875 37.296875 \n",
       "Q 14.84375 35.15625 13.28125 29.6875 \n",
       "z\n",
       "\" id=\"SimHei-101\"/>\n",
       "       <path d=\"M 39.453125 37.5 \n",
       "Q 32.03125 38.671875 26.953125 35.34375 \n",
       "Q 21.875 32.03125 18.359375 23.828125 \n",
       "L 18.359375 1.5625 \n",
       "L 10.546875 1.5625 \n",
       "L 10.546875 45.3125 \n",
       "L 18.359375 45.3125 \n",
       "L 18.359375 33.984375 \n",
       "Q 21.875 40.234375 27.140625 43.15625 \n",
       "Q 32.421875 46.09375 39.453125 46.09375 \n",
       "z\n",
       "\" id=\"SimHei-114\"/>\n",
       "       <path d=\"M 45.3125 1.5625 \n",
       "L 35.9375 1.5625 \n",
       "Q 35.15625 2.34375 34.765625 3.703125 \n",
       "Q 34.375 5.078125 34.375 7.03125 \n",
       "Q 31.640625 3.90625 27.734375 2.34375 \n",
       "Q 23.828125 0.78125 19.53125 0.78125 \n",
       "Q 13.28125 0.78125 8.984375 3.90625 \n",
       "Q 4.6875 7.03125 4.6875 12.890625 \n",
       "Q 4.6875 18.75 8.59375 22.265625 \n",
       "Q 12.5 25.78125 20.703125 26.953125 \n",
       "Q 26.171875 27.734375 30.265625 28.90625 \n",
       "Q 34.375 30.078125 34.375 32.03125 \n",
       "Q 34.375 34.375 32.609375 36.71875 \n",
       "Q 30.859375 39.0625 25 39.0625 \n",
       "Q 20.3125 39.0625 18.15625 37.296875 \n",
       "Q 16.015625 35.546875 15.234375 32.421875 \n",
       "L 6.640625 32.421875 \n",
       "Q 7.421875 38.671875 12.296875 42.375 \n",
       "Q 17.1875 46.09375 25 46.09375 \n",
       "Q 33.59375 46.09375 37.890625 42.1875 \n",
       "Q 42.1875 38.28125 42.1875 31.25 \n",
       "L 42.1875 9.765625 \n",
       "Q 42.1875 7.421875 42.96875 5.46875 \n",
       "Q 43.75 3.515625 45.3125 1.5625 \n",
       "z\n",
       "M 34.375 16.015625 \n",
       "L 34.375 23.828125 \n",
       "Q 32.03125 23.046875 29.875 22.453125 \n",
       "Q 27.734375 21.875 22.65625 21.09375 \n",
       "Q 16.796875 20.3125 15.03125 18.359375 \n",
       "Q 13.28125 16.40625 13.28125 13.671875 \n",
       "Q 13.28125 11.328125 15.03125 9.5625 \n",
       "Q 16.796875 7.8125 20.3125 7.8125 \n",
       "Q 23.828125 7.8125 27.921875 9.765625 \n",
       "Q 32.03125 11.71875 34.375 16.015625 \n",
       "z\n",
       "\" id=\"SimHei-97\"/>\n",
       "       <path d=\"M 46.09375 23.4375 \n",
       "Q 46.09375 13.28125 39.84375 7.03125 \n",
       "Q 33.59375 0.78125 25 0.78125 \n",
       "Q 16.40625 0.78125 10.15625 7.03125 \n",
       "Q 3.90625 13.28125 3.90625 23.4375 \n",
       "Q 3.90625 33.59375 10.15625 39.84375 \n",
       "Q 16.40625 46.09375 25 46.09375 \n",
       "Q 33.59375 46.09375 39.84375 39.84375 \n",
       "Q 46.09375 33.59375 46.09375 23.4375 \n",
       "z\n",
       "M 37.5 23.4375 \n",
       "Q 37.5 31.25 33.59375 35.15625 \n",
       "Q 29.6875 39.0625 25 39.0625 \n",
       "Q 20.3125 39.0625 16.40625 35.15625 \n",
       "Q 12.5 31.25 12.5 23.4375 \n",
       "Q 12.5 15.625 16.40625 11.71875 \n",
       "Q 20.3125 7.8125 25 7.8125 \n",
       "Q 29.6875 7.8125 33.59375 11.71875 \n",
       "Q 37.5 15.625 37.5 23.4375 \n",
       "z\n",
       "\" id=\"SimHei-111\"/>\n",
       "       <path d=\"M 44.140625 1.5625 \n",
       "L 36.328125 1.5625 \n",
       "L 36.328125 29.6875 \n",
       "Q 36.328125 34.375 33.984375 37.109375 \n",
       "Q 31.640625 39.84375 27.734375 39.84375 \n",
       "Q 22.65625 39.84375 18.15625 34.5625 \n",
       "Q 13.671875 29.296875 13.671875 21.484375 \n",
       "L 13.671875 1.5625 \n",
       "L 5.859375 1.5625 \n",
       "L 5.859375 45.3125 \n",
       "L 13.671875 45.3125 \n",
       "L 13.671875 37.109375 \n",
       "Q 16.796875 41.40625 20.5 43.75 \n",
       "Q 24.21875 46.09375 30.078125 46.09375 \n",
       "Q 37.109375 46.09375 40.625 42.1875 \n",
       "Q 44.140625 38.28125 44.140625 32.421875 \n",
       "z\n",
       "\" id=\"SimHei-110\"/>\n",
       "       <path id=\"SimHei-32\"/>\n",
       "       <path d=\"M 44.140625 1.5625 \n",
       "L 36.328125 1.5625 \n",
       "L 36.328125 9.765625 \n",
       "Q 33.203125 5.46875 29.484375 3.125 \n",
       "Q 25.78125 0.78125 19.921875 0.78125 \n",
       "Q 12.890625 0.78125 9.375 4.6875 \n",
       "Q 5.859375 8.59375 5.859375 14.453125 \n",
       "L 5.859375 45.3125 \n",
       "L 13.671875 45.3125 \n",
       "L 13.671875 17.1875 \n",
       "Q 13.671875 12.5 16.015625 9.765625 \n",
       "Q 18.359375 7.03125 22.265625 7.03125 \n",
       "Q 27.34375 7.03125 31.828125 12.296875 \n",
       "Q 36.328125 17.578125 36.328125 25.390625 \n",
       "L 36.328125 45.3125 \n",
       "L 44.140625 45.3125 \n",
       "z\n",
       "\" id=\"SimHei-117\"/>\n",
       "       <path d=\"M 48.046875 1.5625 \n",
       "L 40.234375 1.5625 \n",
       "L 40.234375 33.203125 \n",
       "Q 40.234375 35.546875 39.453125 37.109375 \n",
       "Q 38.671875 38.671875 36.328125 38.671875 \n",
       "Q 33.59375 38.671875 31.25 35.734375 \n",
       "Q 28.90625 32.8125 28.90625 28.125 \n",
       "L 28.90625 1.5625 \n",
       "L 21.09375 1.5625 \n",
       "L 21.09375 33.203125 \n",
       "Q 21.09375 35.546875 20.3125 37.109375 \n",
       "Q 19.53125 38.671875 17.1875 38.671875 \n",
       "Q 14.453125 38.671875 12.109375 35.734375 \n",
       "Q 9.765625 32.8125 9.765625 28.125 \n",
       "L 9.765625 1.5625 \n",
       "L 1.953125 1.5625 \n",
       "L 1.953125 45.3125 \n",
       "L 9.765625 45.3125 \n",
       "L 9.765625 39.453125 \n",
       "Q 11.71875 42.578125 14.453125 44.328125 \n",
       "Q 17.1875 46.09375 20.3125 46.09375 \n",
       "Q 23.4375 46.09375 25.578125 44.328125 \n",
       "Q 27.734375 42.578125 28.515625 39.453125 \n",
       "Q 30.46875 42.578125 33 44.328125 \n",
       "Q 35.546875 46.09375 38.671875 46.09375 \n",
       "Q 43.359375 46.09375 45.703125 43.546875 \n",
       "Q 48.046875 41.015625 48.046875 36.328125 \n",
       "z\n",
       "\" id=\"SimHei-109\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-105\"/>\n",
       "      <use x=\"50\" xlink:href=\"#SimHei-116\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-101\"/>\n",
       "      <use x=\"150\" xlink:href=\"#SimHei-114\"/>\n",
       "      <use x=\"200\" xlink:href=\"#SimHei-97\"/>\n",
       "      <use x=\"250\" xlink:href=\"#SimHei-116\"/>\n",
       "      <use x=\"300\" xlink:href=\"#SimHei-105\"/>\n",
       "      <use x=\"350\" xlink:href=\"#SimHei-111\"/>\n",
       "      <use x=\"400\" xlink:href=\"#SimHei-110\"/>\n",
       "      <use x=\"450\" xlink:href=\"#SimHei-32\"/>\n",
       "      <use x=\"500\" xlink:href=\"#SimHei-110\"/>\n",
       "      <use x=\"550\" xlink:href=\"#SimHei-117\"/>\n",
       "      <use x=\"600\" xlink:href=\"#SimHei-109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m872ac53bab\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#m872ac53bab\" y=\"255.951915\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 300 -->\n",
       "      <g transform=\"translate(20.95 260.053478)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 44.140625 20.3125 \n",
       "Q 44.140625 11.328125 38.46875 6.046875 \n",
       "Q 32.8125 0.78125 24.21875 0.78125 \n",
       "Q 15.625 0.78125 9.953125 6.046875 \n",
       "Q 4.296875 11.328125 4.296875 22.265625 \n",
       "L 13.28125 22.265625 \n",
       "Q 13.28125 14.84375 16.203125 11.515625 \n",
       "Q 19.140625 8.203125 24.21875 8.203125 \n",
       "Q 29.296875 8.203125 32.03125 11.328125 \n",
       "Q 34.765625 14.453125 34.765625 21.09375 \n",
       "Q 34.765625 26.5625 31.828125 29.6875 \n",
       "Q 28.90625 32.8125 21.484375 32.8125 \n",
       "L 21.484375 39.453125 \n",
       "Q 27.734375 39.453125 30.65625 42.578125 \n",
       "Q 33.59375 45.703125 33.59375 51.953125 \n",
       "Q 33.59375 56.640625 31.4375 59.375 \n",
       "Q 29.296875 62.109375 24.609375 62.109375 \n",
       "Q 19.921875 62.109375 17.375 58.78125 \n",
       "Q 14.84375 55.46875 14.453125 49.21875 \n",
       "L 5.859375 49.21875 \n",
       "Q 6.640625 58.203125 11.515625 63.671875 \n",
       "Q 16.40625 69.140625 24.609375 69.140625 \n",
       "Q 33.203125 69.140625 37.890625 64.25 \n",
       "Q 42.578125 59.375 42.578125 52.34375 \n",
       "Q 42.578125 45.703125 40.234375 41.984375 \n",
       "Q 37.890625 38.28125 32.421875 36.328125 \n",
       "Q 37.890625 35.15625 41.015625 30.859375 \n",
       "Q 44.140625 26.5625 44.140625 20.3125 \n",
       "z\n",
       "\" id=\"SimHei-51\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-51\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#m872ac53bab\" y=\"216.933952\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(20.95 221.035515)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-52\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#m872ac53bab\" y=\"177.915989\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 500 -->\n",
       "      <g transform=\"translate(20.95 182.017551)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 44.140625 25.78125 \n",
       "Q 44.140625 14.0625 38.46875 7.421875 \n",
       "Q 32.8125 0.78125 23.4375 0.78125 \n",
       "Q 15.234375 0.78125 9.953125 6.25 \n",
       "Q 4.6875 11.71875 4.296875 21.09375 \n",
       "L 13.28125 21.09375 \n",
       "Q 13.28125 15.234375 16.015625 11.71875 \n",
       "Q 18.75 8.203125 23.828125 8.203125 \n",
       "Q 28.90625 8.203125 31.828125 12.5 \n",
       "Q 34.765625 16.796875 34.765625 25.78125 \n",
       "Q 34.765625 33.59375 32.21875 37.296875 \n",
       "Q 29.6875 41.015625 25.390625 41.015625 \n",
       "Q 21.875 41.015625 19.328125 39.453125 \n",
       "Q 16.796875 37.890625 14.453125 33.984375 \n",
       "L 6.640625 33.984375 \n",
       "L 8.984375 68.359375 \n",
       "L 42.578125 68.359375 \n",
       "L 42.578125 60.9375 \n",
       "L 16.40625 60.9375 \n",
       "L 14.84375 42.96875 \n",
       "Q 17.1875 45.3125 19.921875 46.484375 \n",
       "Q 22.65625 47.65625 27.34375 47.65625 \n",
       "Q 34.765625 47.65625 39.453125 41.984375 \n",
       "Q 44.140625 36.328125 44.140625 25.78125 \n",
       "z\n",
       "\" id=\"SimHei-53\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-53\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#m872ac53bab\" y=\"138.898026\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 600 -->\n",
       "      <g transform=\"translate(20.95 142.999588)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-54\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#m872ac53bab\" y=\"99.880062\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 700 -->\n",
       "      <g transform=\"translate(20.95 103.981625)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 43.359375 60.15625 \n",
       "L 25 1.5625 \n",
       "L 16.015625 1.5625 \n",
       "L 34.765625 60.9375 \n",
       "L 6.25 60.9375 \n",
       "L 6.25 68.359375 \n",
       "L 43.359375 68.359375 \n",
       "z\n",
       "\" id=\"SimHei-55\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-55\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#m872ac53bab\" y=\"60.862099\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 800 -->\n",
       "      <g transform=\"translate(20.95 64.963662)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-56\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#m872ac53bab\" y=\"21.844136\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 900 -->\n",
       "      <g transform=\"translate(20.95 25.945698)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 44.140625 35.9375 \n",
       "Q 44.140625 19.921875 38.46875 10.34375 \n",
       "Q 32.8125 0.78125 22.265625 0.78125 \n",
       "Q 14.84375 0.78125 10.34375 6.25 \n",
       "Q 5.859375 11.71875 5.859375 18.359375 \n",
       "L 14.84375 18.359375 \n",
       "Q 14.84375 14.453125 16.984375 11.328125 \n",
       "Q 19.140625 8.203125 22.65625 8.203125 \n",
       "Q 28.515625 8.203125 31.4375 14.84375 \n",
       "Q 34.375 21.484375 35.15625 34.375 \n",
       "Q 33.203125 30.078125 29.6875 27.734375 \n",
       "Q 26.171875 25.390625 21.875 25.390625 \n",
       "Q 14.453125 25.390625 9.765625 30.859375 \n",
       "Q 5.078125 36.328125 5.078125 46.484375 \n",
       "Q 5.078125 56.640625 9.765625 62.890625 \n",
       "Q 14.453125 69.140625 23.828125 69.140625 \n",
       "Q 33.203125 69.140625 38.671875 61.328125 \n",
       "Q 44.140625 53.515625 44.140625 35.9375 \n",
       "z\n",
       "M 34.375 44.921875 \n",
       "Q 34.375 53.515625 31.4375 57.8125 \n",
       "Q 28.515625 62.109375 23.4375 62.109375 \n",
       "Q 19.921875 62.109375 17.1875 58.78125 \n",
       "Q 14.453125 55.46875 14.453125 46.484375 \n",
       "Q 14.453125 39.84375 16.59375 36.125 \n",
       "Q 18.75 32.421875 23.4375 32.421875 \n",
       "Q 28.515625 32.421875 31.4375 35.9375 \n",
       "Q 34.375 39.453125 34.375 44.921875 \n",
       "z\n",
       "\" id=\"SimHei-57\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-57\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- loss -->\n",
       "     <g transform=\"translate(15.403125 155.1)rotate(-90)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 28.90625 1.5625 \n",
       "L 21.09375 1.5625 \n",
       "L 21.09375 68.359375 \n",
       "L 28.90625 68.359375 \n",
       "z\n",
       "\" id=\"SimHei-108\"/>\n",
       "       <path d=\"M 43.359375 13.671875 \n",
       "Q 43.359375 7.421875 38.46875 4.09375 \n",
       "Q 33.59375 0.78125 26.171875 0.78125 \n",
       "Q 16.796875 0.78125 11.71875 4.484375 \n",
       "Q 6.640625 8.203125 6.640625 15.234375 \n",
       "L 14.453125 15.234375 \n",
       "Q 14.453125 10.546875 17.765625 8.984375 \n",
       "Q 21.09375 7.421875 25.78125 7.421875 \n",
       "Q 30.46875 7.421875 32.8125 9.171875 \n",
       "Q 35.15625 10.9375 35.15625 13.671875 \n",
       "Q 35.15625 15.625 33.203125 17.578125 \n",
       "Q 31.25 19.53125 23.4375 20.703125 \n",
       "Q 14.453125 21.875 11.125 25.1875 \n",
       "Q 7.8125 28.515625 7.8125 33.984375 \n",
       "Q 7.8125 38.671875 12.296875 42.375 \n",
       "Q 16.796875 46.09375 25.390625 46.09375 \n",
       "Q 33.203125 46.09375 37.6875 42.578125 \n",
       "Q 42.1875 39.0625 42.1875 33.203125 \n",
       "L 34.375 33.203125 \n",
       "Q 34.375 36.71875 31.828125 38.078125 \n",
       "Q 29.296875 39.453125 25.390625 39.453125 \n",
       "Q 20.3125 39.453125 18.15625 37.6875 \n",
       "Q 16.015625 35.9375 16.015625 33.59375 \n",
       "Q 16.015625 30.859375 17.96875 29.296875 \n",
       "Q 19.921875 27.734375 26.171875 26.953125 \n",
       "Q 36.328125 25.390625 39.84375 22.0625 \n",
       "Q 43.359375 18.75 43.359375 13.671875 \n",
       "z\n",
       "\" id=\"SimHei-115\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-108\"/>\n",
       "      <use x=\"50\" xlink:href=\"#SimHei-111\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-115\"/>\n",
       "      <use x=\"150\" xlink:href=\"#SimHei-115\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path clip-path=\"url(#pe131d754a4)\" d=\"M 71.313636 19.554545 \n",
       "L 72.836978 48.842499 \n",
       "L 74.360319 74.141257 \n",
       "L 75.883661 95.994913 \n",
       "L 77.407002 114.87321 \n",
       "L 78.930344 131.181761 \n",
       "L 80.453686 145.271023 \n",
       "L 81.977027 157.44337 \n",
       "L 83.500369 167.959954 \n",
       "L 85.02371 177.04636 \n",
       "L 86.547052 184.897463 \n",
       "L 88.070393 191.681371 \n",
       "L 89.593735 197.543472 \n",
       "L 91.117076 202.609187 \n",
       "L 92.640418 206.986943 \n",
       "L 94.163759 210.770298 \n",
       "L 95.687101 214.040088 \n",
       "L 97.210442 216.866187 \n",
       "L 98.733784 219.308954 \n",
       "L 100.257125 221.420411 \n",
       "L 102.288247 223.797365 \n",
       "L 104.319369 225.754801 \n",
       "L 106.350491 227.366994 \n",
       "L 108.381613 228.69496 \n",
       "L 110.412735 229.788852 \n",
       "L 112.951638 230.889447 \n",
       "L 115.490541 231.753396 \n",
       "L 118.537224 232.548818 \n",
       "L 122.091687 233.227536 \n",
       "L 126.153931 233.768379 \n",
       "L 131.231736 234.207962 \n",
       "L 137.832883 234.538736 \n",
       "L 146.972932 234.759629 \n",
       "L 162.714128 234.884787 \n",
       "L 206.383251 234.921557 \n",
       "L 578.586364 234.92226 \n",
       "L 578.586364 234.92226 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path clip-path=\"url(#pe131d754a4)\" d=\"M 71.313636 113.609603 \n",
       "L 72.836978 135.647894 \n",
       "L 74.360319 154.601184 \n",
       "L 75.883661 170.895066 \n",
       "L 77.407002 184.896749 \n",
       "L 78.930344 196.923243 \n",
       "L 80.453686 207.247833 \n",
       "L 81.977027 216.106547 \n",
       "L 83.500369 223.702702 \n",
       "L 85.02371 230.211919 \n",
       "L 86.547052 235.78553 \n",
       "L 88.070393 240.554097 \n",
       "L 89.593735 244.630157 \n",
       "L 91.117076 248.110719 \n",
       "L 92.640418 251.079504 \n",
       "L 94.163759 253.608551 \n",
       "L 95.687101 255.760005 \n",
       "L 97.210442 257.587364 \n",
       "L 98.733784 259.136759 \n",
       "L 100.764906 260.837996 \n",
       "L 102.796028 262.194158 \n",
       "L 104.82715 263.270082 \n",
       "L 106.858272 264.118753 \n",
       "L 109.397174 264.925261 \n",
       "L 111.936077 265.511471 \n",
       "L 114.98276 265.99704 \n",
       "L 118.537224 266.347676 \n",
       "L 123.107248 266.572772 \n",
       "L 129.708395 266.643978 \n",
       "L 140.879566 266.496446 \n",
       "L 171.854177 266.036537 \n",
       "L 201.813227 265.876598 \n",
       "L 264.77801 265.816918 \n",
       "L 578.586364 265.812429 \n",
       "L 578.586364 265.812429 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 45.95 279 \n",
       "L 45.95 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 603.95 279 \n",
       "L 603.95 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 45.95 279 \n",
       "L 603.95 279 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 45.95 7.2 \n",
       "L 603.95 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"legend_1\">\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 366.03425 57.006 \n",
       "L 576.03425 57.006 \n",
       "Q 578.43425 57.006 578.43425 54.606 \n",
       "L 578.43425 39.765375 \n",
       "Q 578.43425 37.365375 576.03425 37.365375 \n",
       "L 366.03425 37.365375 \n",
       "Q 363.63425 37.365375 363.63425 39.765375 \n",
       "L 363.63425 54.606 \n",
       "Q 363.63425 57.006 366.03425 57.006 \n",
       "z\n",
       "\" style=\"fill:#f5f5f5;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 368.43425 46.365375 \n",
       "L 392.43425 46.365375 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_17\"/>\n",
       "   <g id=\"text_16\">\n",
       "    <!-- train_loss -->\n",
       "    <g transform=\"translate(402.03425 50.565375)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path d=\"M 49.609375 -13.671875 \n",
       "L 0 -13.671875 \n",
       "L 0 -8.984375 \n",
       "L 49.609375 -8.984375 \n",
       "z\n",
       "\" id=\"SimHei-95\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#SimHei-116\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-114\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-97\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-105\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-110\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-95\"/>\n",
       "     <use x=\"300\" xlink:href=\"#SimHei-108\"/>\n",
       "     <use x=\"350\" xlink:href=\"#SimHei-111\"/>\n",
       "     <use x=\"400\" xlink:href=\"#SimHei-115\"/>\n",
       "     <use x=\"450\" xlink:href=\"#SimHei-115\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_18\">\n",
       "    <path d=\"M 486.03425 46.365375 \n",
       "L 510.03425 46.365375 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_19\"/>\n",
       "   <g id=\"text_17\">\n",
       "    <!-- test_loss -->\n",
       "    <g transform=\"translate(519.63425 50.565375)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#SimHei-116\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-101\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-115\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-116\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-95\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-108\"/>\n",
       "     <use x=\"300\" xlink:href=\"#SimHei-111\"/>\n",
       "     <use x=\"350\" xlink:href=\"#SimHei-115\"/>\n",
       "     <use x=\"400\" xlink:href=\"#SimHei-115\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pe131d754a4\">\n",
       "   <rect height=\"271.8\" width=\"558\" x=\"45.95\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute time is 4.351 seconds\n"
     ]
    }
   ],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(1, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "# define model and loss\n",
    "model = LinearModel()\n",
    "init.normal_(model.layer[0].weight, 0, 0.01)\n",
    "init.constant_(model.layer[0].bias, 0)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# deal with data\n",
    "train_dataset = Data.TensorDataset(linear_feature[:100], y[:100])\n",
    "test_dataset = Data.TensorDataset(linear_feature[100:], y[100:])\n",
    "test_iter = Data.DataLoader(test_dataset, batch_size=len(y[:100]), shuffle=True)\n",
    "\n",
    "params = {\n",
    "    \"model\": model,\n",
    "    \"loss\": loss,\n",
    "    \"epoch_num\": 1000,\n",
    "    \"batch_size\": 100,\n",
    "    \"lr\": 0.01,\n",
    "    \"data_num\": 100,\n",
    "    \"test_iter\":test_iter,\n",
    "    \"draw\": True,\n",
    "}\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=params[\"lr\"])\n",
    "train_iter = Data.DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "params[\"optimizer\"] = optimizer\n",
    "params[\"train_iter\"] = train_iter\n",
    "\n",
    "# training\n",
    "set_fig_display()\n",
    "train_experiment(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用单个特征的线性模型来拟合，迭代多轮后，误差仍然非常大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "即使用数据生成模型同阶的三阶多项式函数模型，如果训练样本不足，该模型依然容易过拟合\n",
    "- 只使用两个样本来训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T13:22:09.978277Z",
     "start_time": "2020-10-08T13:22:09.726503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0227,  0.0167, -0.0017]], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "2/2 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 113.1013, train_score: -, test_loss: 614.8608, test_score: -\n",
      "\n",
      "Epoch [2/10]\n",
      "2/2 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 66.0653, train_score: -, test_loss: 498.7602, test_score: -\n",
      "\n",
      "Epoch [3/10]\n",
      "2/2 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 39.5900, train_score: -, test_loss: 393.1441, test_score: -\n",
      "\n",
      "Epoch [4/10]\n",
      "2/2 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 24.5065, train_score: -, test_loss: 373.2470, test_score: -\n",
      "\n",
      "Epoch [5/10]\n",
      "2/2 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 16.0839, train_score: -, test_loss: 340.1553, test_score: -\n",
      "\n",
      "Epoch [6/10]\n",
      "2/2 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 11.2736, train_score: -, test_loss: 317.7139, test_score: -\n",
      "\n",
      "Epoch [7/10]\n",
      "2/2 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 8.4919, train_score: -, test_loss: 295.5863, test_score: -\n",
      "\n",
      "Epoch [8/10]\n",
      "2/2 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 6.8201, train_score: -, test_loss: 286.7379, test_score: -\n",
      "\n",
      "Epoch [9/10]\n",
      "2/2 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 5.8182, train_score: -, test_loss: 280.7623, test_score: -\n",
      "\n",
      "Epoch [10/10]\n",
      "2/2 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 5.1948, train_score: -, test_loss: 279.1401, test_score: -\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"316.7pt\" version=\"1.1\" viewBox=\"0 0 611.15 316.7\" width=\"611.15pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2020-10-08T21:22:09.917219</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 316.7 \n",
       "L 611.15 316.7 \n",
       "L 611.15 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 45.95 279 \n",
       "L 603.95 279 \n",
       "L 603.95 7.2 \n",
       "L 45.95 7.2 \n",
       "z\n",
       "\" style=\"fill:#f5f5f5;\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m63619f3b0f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"71.313636\" xlink:href=\"#m63619f3b0f\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(62.313636 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 46.484375 35.15625 \n",
       "Q 46.484375 21.09375 41.40625 10.9375 \n",
       "Q 36.328125 0.78125 25 0.78125 \n",
       "Q 13.671875 0.78125 8.390625 10.9375 \n",
       "Q 3.125 21.09375 3.125 35.15625 \n",
       "Q 3.125 49.21875 8.390625 59.171875 \n",
       "Q 13.671875 69.140625 25 69.140625 \n",
       "Q 36.328125 69.140625 41.40625 59.171875 \n",
       "Q 46.484375 49.21875 46.484375 35.15625 \n",
       "z\n",
       "M 37.109375 35.15625 \n",
       "Q 37.109375 47.65625 34.171875 54.6875 \n",
       "Q 31.25 61.71875 25 61.71875 \n",
       "Q 18.75 61.71875 15.625 54.6875 \n",
       "Q 12.5 47.65625 12.5 35.15625 \n",
       "Q 12.5 22.65625 15.625 15.421875 \n",
       "Q 18.75 8.203125 25 8.203125 \n",
       "Q 31.25 8.203125 34.171875 15.421875 \n",
       "Q 37.109375 22.65625 37.109375 35.15625 \n",
       "z\n",
       "\" id=\"SimHei-48\"/>\n",
       "        <path d=\"M 17.1875 1.5625 \n",
       "L 8.203125 1.5625 \n",
       "L 8.203125 10.15625 \n",
       "L 17.1875 10.15625 \n",
       "z\n",
       "\" id=\"SimHei-46\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-46\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"138.060048\" xlink:href=\"#m63619f3b0f\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 2.5 -->\n",
       "      <g transform=\"translate(129.060048 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 44.53125 1.5625 \n",
       "L 4.6875 1.5625 \n",
       "L 4.6875 7.8125 \n",
       "Q 7.03125 14.0625 11.125 19.328125 \n",
       "Q 15.234375 24.609375 23.046875 31.25 \n",
       "Q 28.90625 36.328125 31.4375 40.625 \n",
       "Q 33.984375 44.921875 33.984375 50 \n",
       "Q 33.984375 55.078125 31.828125 58.390625 \n",
       "Q 29.6875 61.71875 25 61.71875 \n",
       "Q 21.09375 61.71875 18.15625 58.203125 \n",
       "Q 15.234375 54.6875 15.234375 45.703125 \n",
       "L 6.25 45.703125 \n",
       "Q 6.640625 57.03125 11.515625 63.078125 \n",
       "Q 16.40625 69.140625 25.390625 69.140625 \n",
       "Q 33.984375 69.140625 38.671875 63.859375 \n",
       "Q 43.359375 58.59375 43.359375 49.609375 \n",
       "Q 43.359375 42.1875 39.0625 36.71875 \n",
       "Q 34.765625 31.25 28.515625 25.78125 \n",
       "Q 21.484375 19.53125 18.75 16.40625 \n",
       "Q 16.015625 13.28125 13.671875 8.984375 \n",
       "L 44.53125 8.984375 \n",
       "z\n",
       "\" id=\"SimHei-50\"/>\n",
       "        <path d=\"M 44.140625 25.78125 \n",
       "Q 44.140625 14.0625 38.46875 7.421875 \n",
       "Q 32.8125 0.78125 23.4375 0.78125 \n",
       "Q 15.234375 0.78125 9.953125 6.25 \n",
       "Q 4.6875 11.71875 4.296875 21.09375 \n",
       "L 13.28125 21.09375 \n",
       "Q 13.28125 15.234375 16.015625 11.71875 \n",
       "Q 18.75 8.203125 23.828125 8.203125 \n",
       "Q 28.90625 8.203125 31.828125 12.5 \n",
       "Q 34.765625 16.796875 34.765625 25.78125 \n",
       "Q 34.765625 33.59375 32.21875 37.296875 \n",
       "Q 29.6875 41.015625 25.390625 41.015625 \n",
       "Q 21.875 41.015625 19.328125 39.453125 \n",
       "Q 16.796875 37.890625 14.453125 33.984375 \n",
       "L 6.640625 33.984375 \n",
       "L 8.984375 68.359375 \n",
       "L 42.578125 68.359375 \n",
       "L 42.578125 60.9375 \n",
       "L 16.40625 60.9375 \n",
       "L 14.84375 42.96875 \n",
       "Q 17.1875 45.3125 19.921875 46.484375 \n",
       "Q 22.65625 47.65625 27.34375 47.65625 \n",
       "Q 34.765625 47.65625 39.453125 41.984375 \n",
       "Q 44.140625 36.328125 44.140625 25.78125 \n",
       "z\n",
       "\" id=\"SimHei-53\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-46\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"204.806459\" xlink:href=\"#m63619f3b0f\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 5.0 -->\n",
       "      <g transform=\"translate(195.806459 294.203125)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-53\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-46\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"271.552871\" xlink:href=\"#m63619f3b0f\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 7.5 -->\n",
       "      <g transform=\"translate(262.552871 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 43.359375 60.15625 \n",
       "L 25 1.5625 \n",
       "L 16.015625 1.5625 \n",
       "L 34.765625 60.9375 \n",
       "L 6.25 60.9375 \n",
       "L 6.25 68.359375 \n",
       "L 43.359375 68.359375 \n",
       "z\n",
       "\" id=\"SimHei-55\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-55\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-46\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"338.299282\" xlink:href=\"#m63619f3b0f\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 10.0 -->\n",
       "      <g transform=\"translate(326.299282 294.203125)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 30.46875 1.5625 \n",
       "L 21.484375 1.5625 \n",
       "L 21.484375 53.515625 \n",
       "L 9.765625 53.515625 \n",
       "L 9.765625 58.203125 \n",
       "Q 16.796875 58.203125 20.703125 60.9375 \n",
       "Q 24.609375 63.671875 25.78125 69.140625 \n",
       "L 30.46875 69.140625 \n",
       "z\n",
       "\" id=\"SimHei-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-46\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"405.045694\" xlink:href=\"#m63619f3b0f\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 12.5 -->\n",
       "      <g transform=\"translate(393.045694 294.203125)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-46\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"471.792105\" xlink:href=\"#m63619f3b0f\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 15.0 -->\n",
       "      <g transform=\"translate(459.792105 294.203125)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-53\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-46\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"538.538517\" xlink:href=\"#m63619f3b0f\" y=\"279\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 17.5 -->\n",
       "      <g transform=\"translate(526.538517 294.203125)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-55\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-46\"/>\n",
       "       <use x=\"150\" xlink:href=\"#SimHei-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_9\">\n",
       "     <!-- iteration num -->\n",
       "     <g transform=\"translate(285.95 307.953125)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 28.515625 57.8125 \n",
       "L 20.703125 57.8125 \n",
       "L 20.703125 67.96875 \n",
       "L 28.515625 67.96875 \n",
       "z\n",
       "M 28.515625 1.5625 \n",
       "L 20.703125 1.5625 \n",
       "L 20.703125 45.3125 \n",
       "L 28.515625 45.3125 \n",
       "z\n",
       "\" id=\"SimHei-105\"/>\n",
       "       <path d=\"M 43.359375 2.734375 \n",
       "Q 41.40625 1.953125 38.859375 1.359375 \n",
       "Q 36.328125 0.78125 32.03125 0.78125 \n",
       "Q 25 0.78125 20.703125 4.6875 \n",
       "Q 16.40625 8.59375 16.40625 15.625 \n",
       "L 16.40625 39.0625 \n",
       "L 3.125 39.0625 \n",
       "L 3.125 45.3125 \n",
       "L 16.40625 45.3125 \n",
       "L 16.40625 60.546875 \n",
       "L 24.21875 60.546875 \n",
       "L 24.21875 45.3125 \n",
       "L 40.234375 45.3125 \n",
       "L 40.234375 39.0625 \n",
       "L 24.21875 39.0625 \n",
       "L 24.21875 15.234375 \n",
       "Q 24.21875 12.109375 25.78125 9.953125 \n",
       "Q 27.34375 7.8125 31.640625 7.8125 \n",
       "Q 35.9375 7.8125 38.671875 8.59375 \n",
       "Q 41.40625 9.375 43.359375 10.546875 \n",
       "z\n",
       "\" id=\"SimHei-116\"/>\n",
       "       <path d=\"M 44.921875 16.40625 \n",
       "Q 44.140625 9.375 38.671875 5.078125 \n",
       "Q 33.203125 0.78125 25.78125 0.78125 \n",
       "Q 16.40625 0.78125 10.34375 6.828125 \n",
       "Q 4.296875 12.890625 4.296875 23.4375 \n",
       "Q 4.296875 33.984375 10.34375 40.03125 \n",
       "Q 16.40625 46.09375 25.78125 46.09375 \n",
       "Q 33.984375 46.09375 39.25 40.8125 \n",
       "Q 44.53125 35.546875 44.53125 23.4375 \n",
       "L 12.890625 23.4375 \n",
       "Q 12.890625 14.84375 16.59375 11.328125 \n",
       "Q 20.3125 7.8125 25.78125 7.8125 \n",
       "Q 30.078125 7.8125 32.8125 9.953125 \n",
       "Q 35.546875 12.109375 36.328125 16.40625 \n",
       "z\n",
       "M 35.546875 29.6875 \n",
       "Q 34.765625 35.15625 32.03125 37.296875 \n",
       "Q 29.296875 39.453125 25 39.453125 \n",
       "Q 21.09375 39.453125 17.96875 37.296875 \n",
       "Q 14.84375 35.15625 13.28125 29.6875 \n",
       "z\n",
       "\" id=\"SimHei-101\"/>\n",
       "       <path d=\"M 39.453125 37.5 \n",
       "Q 32.03125 38.671875 26.953125 35.34375 \n",
       "Q 21.875 32.03125 18.359375 23.828125 \n",
       "L 18.359375 1.5625 \n",
       "L 10.546875 1.5625 \n",
       "L 10.546875 45.3125 \n",
       "L 18.359375 45.3125 \n",
       "L 18.359375 33.984375 \n",
       "Q 21.875 40.234375 27.140625 43.15625 \n",
       "Q 32.421875 46.09375 39.453125 46.09375 \n",
       "z\n",
       "\" id=\"SimHei-114\"/>\n",
       "       <path d=\"M 45.3125 1.5625 \n",
       "L 35.9375 1.5625 \n",
       "Q 35.15625 2.34375 34.765625 3.703125 \n",
       "Q 34.375 5.078125 34.375 7.03125 \n",
       "Q 31.640625 3.90625 27.734375 2.34375 \n",
       "Q 23.828125 0.78125 19.53125 0.78125 \n",
       "Q 13.28125 0.78125 8.984375 3.90625 \n",
       "Q 4.6875 7.03125 4.6875 12.890625 \n",
       "Q 4.6875 18.75 8.59375 22.265625 \n",
       "Q 12.5 25.78125 20.703125 26.953125 \n",
       "Q 26.171875 27.734375 30.265625 28.90625 \n",
       "Q 34.375 30.078125 34.375 32.03125 \n",
       "Q 34.375 34.375 32.609375 36.71875 \n",
       "Q 30.859375 39.0625 25 39.0625 \n",
       "Q 20.3125 39.0625 18.15625 37.296875 \n",
       "Q 16.015625 35.546875 15.234375 32.421875 \n",
       "L 6.640625 32.421875 \n",
       "Q 7.421875 38.671875 12.296875 42.375 \n",
       "Q 17.1875 46.09375 25 46.09375 \n",
       "Q 33.59375 46.09375 37.890625 42.1875 \n",
       "Q 42.1875 38.28125 42.1875 31.25 \n",
       "L 42.1875 9.765625 \n",
       "Q 42.1875 7.421875 42.96875 5.46875 \n",
       "Q 43.75 3.515625 45.3125 1.5625 \n",
       "z\n",
       "M 34.375 16.015625 \n",
       "L 34.375 23.828125 \n",
       "Q 32.03125 23.046875 29.875 22.453125 \n",
       "Q 27.734375 21.875 22.65625 21.09375 \n",
       "Q 16.796875 20.3125 15.03125 18.359375 \n",
       "Q 13.28125 16.40625 13.28125 13.671875 \n",
       "Q 13.28125 11.328125 15.03125 9.5625 \n",
       "Q 16.796875 7.8125 20.3125 7.8125 \n",
       "Q 23.828125 7.8125 27.921875 9.765625 \n",
       "Q 32.03125 11.71875 34.375 16.015625 \n",
       "z\n",
       "\" id=\"SimHei-97\"/>\n",
       "       <path d=\"M 46.09375 23.4375 \n",
       "Q 46.09375 13.28125 39.84375 7.03125 \n",
       "Q 33.59375 0.78125 25 0.78125 \n",
       "Q 16.40625 0.78125 10.15625 7.03125 \n",
       "Q 3.90625 13.28125 3.90625 23.4375 \n",
       "Q 3.90625 33.59375 10.15625 39.84375 \n",
       "Q 16.40625 46.09375 25 46.09375 \n",
       "Q 33.59375 46.09375 39.84375 39.84375 \n",
       "Q 46.09375 33.59375 46.09375 23.4375 \n",
       "z\n",
       "M 37.5 23.4375 \n",
       "Q 37.5 31.25 33.59375 35.15625 \n",
       "Q 29.6875 39.0625 25 39.0625 \n",
       "Q 20.3125 39.0625 16.40625 35.15625 \n",
       "Q 12.5 31.25 12.5 23.4375 \n",
       "Q 12.5 15.625 16.40625 11.71875 \n",
       "Q 20.3125 7.8125 25 7.8125 \n",
       "Q 29.6875 7.8125 33.59375 11.71875 \n",
       "Q 37.5 15.625 37.5 23.4375 \n",
       "z\n",
       "\" id=\"SimHei-111\"/>\n",
       "       <path d=\"M 44.140625 1.5625 \n",
       "L 36.328125 1.5625 \n",
       "L 36.328125 29.6875 \n",
       "Q 36.328125 34.375 33.984375 37.109375 \n",
       "Q 31.640625 39.84375 27.734375 39.84375 \n",
       "Q 22.65625 39.84375 18.15625 34.5625 \n",
       "Q 13.671875 29.296875 13.671875 21.484375 \n",
       "L 13.671875 1.5625 \n",
       "L 5.859375 1.5625 \n",
       "L 5.859375 45.3125 \n",
       "L 13.671875 45.3125 \n",
       "L 13.671875 37.109375 \n",
       "Q 16.796875 41.40625 20.5 43.75 \n",
       "Q 24.21875 46.09375 30.078125 46.09375 \n",
       "Q 37.109375 46.09375 40.625 42.1875 \n",
       "Q 44.140625 38.28125 44.140625 32.421875 \n",
       "z\n",
       "\" id=\"SimHei-110\"/>\n",
       "       <path id=\"SimHei-32\"/>\n",
       "       <path d=\"M 44.140625 1.5625 \n",
       "L 36.328125 1.5625 \n",
       "L 36.328125 9.765625 \n",
       "Q 33.203125 5.46875 29.484375 3.125 \n",
       "Q 25.78125 0.78125 19.921875 0.78125 \n",
       "Q 12.890625 0.78125 9.375 4.6875 \n",
       "Q 5.859375 8.59375 5.859375 14.453125 \n",
       "L 5.859375 45.3125 \n",
       "L 13.671875 45.3125 \n",
       "L 13.671875 17.1875 \n",
       "Q 13.671875 12.5 16.015625 9.765625 \n",
       "Q 18.359375 7.03125 22.265625 7.03125 \n",
       "Q 27.34375 7.03125 31.828125 12.296875 \n",
       "Q 36.328125 17.578125 36.328125 25.390625 \n",
       "L 36.328125 45.3125 \n",
       "L 44.140625 45.3125 \n",
       "z\n",
       "\" id=\"SimHei-117\"/>\n",
       "       <path d=\"M 48.046875 1.5625 \n",
       "L 40.234375 1.5625 \n",
       "L 40.234375 33.203125 \n",
       "Q 40.234375 35.546875 39.453125 37.109375 \n",
       "Q 38.671875 38.671875 36.328125 38.671875 \n",
       "Q 33.59375 38.671875 31.25 35.734375 \n",
       "Q 28.90625 32.8125 28.90625 28.125 \n",
       "L 28.90625 1.5625 \n",
       "L 21.09375 1.5625 \n",
       "L 21.09375 33.203125 \n",
       "Q 21.09375 35.546875 20.3125 37.109375 \n",
       "Q 19.53125 38.671875 17.1875 38.671875 \n",
       "Q 14.453125 38.671875 12.109375 35.734375 \n",
       "Q 9.765625 32.8125 9.765625 28.125 \n",
       "L 9.765625 1.5625 \n",
       "L 1.953125 1.5625 \n",
       "L 1.953125 45.3125 \n",
       "L 9.765625 45.3125 \n",
       "L 9.765625 39.453125 \n",
       "Q 11.71875 42.578125 14.453125 44.328125 \n",
       "Q 17.1875 46.09375 20.3125 46.09375 \n",
       "Q 23.4375 46.09375 25.578125 44.328125 \n",
       "Q 27.734375 42.578125 28.515625 39.453125 \n",
       "Q 30.46875 42.578125 33 44.328125 \n",
       "Q 35.546875 46.09375 38.671875 46.09375 \n",
       "Q 43.359375 46.09375 45.703125 43.546875 \n",
       "Q 48.046875 41.015625 48.046875 36.328125 \n",
       "z\n",
       "\" id=\"SimHei-109\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-105\"/>\n",
       "      <use x=\"50\" xlink:href=\"#SimHei-116\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-101\"/>\n",
       "      <use x=\"150\" xlink:href=\"#SimHei-114\"/>\n",
       "      <use x=\"200\" xlink:href=\"#SimHei-97\"/>\n",
       "      <use x=\"250\" xlink:href=\"#SimHei-116\"/>\n",
       "      <use x=\"300\" xlink:href=\"#SimHei-105\"/>\n",
       "      <use x=\"350\" xlink:href=\"#SimHei-111\"/>\n",
       "      <use x=\"400\" xlink:href=\"#SimHei-110\"/>\n",
       "      <use x=\"450\" xlink:href=\"#SimHei-32\"/>\n",
       "      <use x=\"500\" xlink:href=\"#SimHei-110\"/>\n",
       "      <use x=\"550\" xlink:href=\"#SimHei-117\"/>\n",
       "      <use x=\"600\" xlink:href=\"#SimHei-109\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"mcae1ec1c0d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#mcae1ec1c0d\" y=\"266.832286\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(32.95 270.933848)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#mcae1ec1c0d\" y=\"230.745503\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 100 -->\n",
       "      <g transform=\"translate(20.95 234.847066)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-49\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#mcae1ec1c0d\" y=\"194.65872\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(20.95 198.760283)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-50\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#mcae1ec1c0d\" y=\"158.571938\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 300 -->\n",
       "      <g transform=\"translate(20.95 162.6735)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 44.140625 20.3125 \n",
       "Q 44.140625 11.328125 38.46875 6.046875 \n",
       "Q 32.8125 0.78125 24.21875 0.78125 \n",
       "Q 15.625 0.78125 9.953125 6.046875 \n",
       "Q 4.296875 11.328125 4.296875 22.265625 \n",
       "L 13.28125 22.265625 \n",
       "Q 13.28125 14.84375 16.203125 11.515625 \n",
       "Q 19.140625 8.203125 24.21875 8.203125 \n",
       "Q 29.296875 8.203125 32.03125 11.328125 \n",
       "Q 34.765625 14.453125 34.765625 21.09375 \n",
       "Q 34.765625 26.5625 31.828125 29.6875 \n",
       "Q 28.90625 32.8125 21.484375 32.8125 \n",
       "L 21.484375 39.453125 \n",
       "Q 27.734375 39.453125 30.65625 42.578125 \n",
       "Q 33.59375 45.703125 33.59375 51.953125 \n",
       "Q 33.59375 56.640625 31.4375 59.375 \n",
       "Q 29.296875 62.109375 24.609375 62.109375 \n",
       "Q 19.921875 62.109375 17.375 58.78125 \n",
       "Q 14.84375 55.46875 14.453125 49.21875 \n",
       "L 5.859375 49.21875 \n",
       "Q 6.640625 58.203125 11.515625 63.671875 \n",
       "Q 16.40625 69.140625 24.609375 69.140625 \n",
       "Q 33.203125 69.140625 37.890625 64.25 \n",
       "Q 42.578125 59.375 42.578125 52.34375 \n",
       "Q 42.578125 45.703125 40.234375 41.984375 \n",
       "Q 37.890625 38.28125 32.421875 36.328125 \n",
       "Q 37.890625 35.15625 41.015625 30.859375 \n",
       "Q 44.140625 26.5625 44.140625 20.3125 \n",
       "z\n",
       "\" id=\"SimHei-51\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-51\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#mcae1ec1c0d\" y=\"122.485155\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(20.95 126.586718)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 46.484375 18.75 \n",
       "L 38.28125 18.75 \n",
       "L 38.28125 1.5625 \n",
       "L 29.296875 1.5625 \n",
       "L 29.296875 18.75 \n",
       "L 3.125 18.75 \n",
       "L 3.125 26.171875 \n",
       "L 29.296875 69.140625 \n",
       "L 38.28125 69.140625 \n",
       "L 38.28125 26.171875 \n",
       "L 46.484375 26.171875 \n",
       "z\n",
       "M 29.296875 26.171875 \n",
       "L 29.296875 55.078125 \n",
       "L 11.71875 26.171875 \n",
       "z\n",
       "\" id=\"SimHei-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-52\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#mcae1ec1c0d\" y=\"86.398372\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 500 -->\n",
       "      <g transform=\"translate(20.95 90.499935)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-53\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#mcae1ec1c0d\" y=\"50.31159\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 600 -->\n",
       "      <g transform=\"translate(20.95 54.413152)scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path d=\"M 44.53125 24.21875 \n",
       "Q 44.53125 13.28125 39.84375 7.03125 \n",
       "Q 35.15625 0.78125 25.78125 0.78125 \n",
       "Q 16.40625 0.78125 10.9375 8.59375 \n",
       "Q 5.46875 16.40625 5.46875 33.984375 \n",
       "Q 5.46875 50 11.125 59.5625 \n",
       "Q 16.796875 69.140625 27.34375 69.140625 \n",
       "Q 34.765625 69.140625 39.25 63.671875 \n",
       "Q 43.75 58.203125 43.75 51.5625 \n",
       "L 34.765625 51.5625 \n",
       "Q 34.765625 55.46875 32.609375 58.59375 \n",
       "Q 30.46875 61.71875 26.953125 61.71875 \n",
       "Q 21.09375 61.71875 17.96875 55.65625 \n",
       "Q 14.84375 49.609375 14.453125 37.109375 \n",
       "Q 17.1875 42.1875 20.3125 44.140625 \n",
       "Q 23.4375 46.09375 27.734375 46.09375 \n",
       "Q 35.15625 46.09375 39.84375 40.234375 \n",
       "Q 44.53125 34.375 44.53125 24.21875 \n",
       "z\n",
       "M 35.15625 24.21875 \n",
       "Q 35.15625 31.25 32.8125 35.15625 \n",
       "Q 30.46875 39.0625 26.171875 39.0625 \n",
       "Q 21.09375 39.0625 18.15625 35.15625 \n",
       "Q 15.234375 31.25 15.234375 25.78125 \n",
       "Q 15.234375 17.1875 18.15625 12.5 \n",
       "Q 21.09375 7.8125 26.171875 7.8125 \n",
       "Q 29.6875 7.8125 32.421875 11.328125 \n",
       "Q 35.15625 14.84375 35.15625 24.21875 \n",
       "z\n",
       "\" id=\"SimHei-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#SimHei-54\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.95\" xlink:href=\"#mcae1ec1c0d\" y=\"14.224807\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_17\">\n",
       "      <!-- 700 -->\n",
       "      <g transform=\"translate(20.95 18.326369)scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#SimHei-55\"/>\n",
       "       <use x=\"50\" xlink:href=\"#SimHei-48\"/>\n",
       "       <use x=\"100\" xlink:href=\"#SimHei-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- loss -->\n",
       "     <g transform=\"translate(15.403125 155.1)rotate(-90)scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path d=\"M 28.90625 1.5625 \n",
       "L 21.09375 1.5625 \n",
       "L 21.09375 68.359375 \n",
       "L 28.90625 68.359375 \n",
       "z\n",
       "\" id=\"SimHei-108\"/>\n",
       "       <path d=\"M 43.359375 13.671875 \n",
       "Q 43.359375 7.421875 38.46875 4.09375 \n",
       "Q 33.59375 0.78125 26.171875 0.78125 \n",
       "Q 16.796875 0.78125 11.71875 4.484375 \n",
       "Q 6.640625 8.203125 6.640625 15.234375 \n",
       "L 14.453125 15.234375 \n",
       "Q 14.453125 10.546875 17.765625 8.984375 \n",
       "Q 21.09375 7.421875 25.78125 7.421875 \n",
       "Q 30.46875 7.421875 32.8125 9.171875 \n",
       "Q 35.15625 10.9375 35.15625 13.671875 \n",
       "Q 35.15625 15.625 33.203125 17.578125 \n",
       "Q 31.25 19.53125 23.4375 20.703125 \n",
       "Q 14.453125 21.875 11.125 25.1875 \n",
       "Q 7.8125 28.515625 7.8125 33.984375 \n",
       "Q 7.8125 38.671875 12.296875 42.375 \n",
       "Q 16.796875 46.09375 25.390625 46.09375 \n",
       "Q 33.203125 46.09375 37.6875 42.578125 \n",
       "Q 42.1875 39.0625 42.1875 33.203125 \n",
       "L 34.375 33.203125 \n",
       "Q 34.375 36.71875 31.828125 38.078125 \n",
       "Q 29.296875 39.453125 25.390625 39.453125 \n",
       "Q 20.3125 39.453125 18.15625 37.6875 \n",
       "Q 16.015625 35.9375 16.015625 33.59375 \n",
       "Q 16.015625 30.859375 17.96875 29.296875 \n",
       "Q 19.921875 27.734375 26.171875 26.953125 \n",
       "Q 36.328125 25.390625 39.84375 22.0625 \n",
       "Q 43.359375 18.75 43.359375 13.671875 \n",
       "z\n",
       "\" id=\"SimHei-115\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#SimHei-108\"/>\n",
       "      <use x=\"50\" xlink:href=\"#SimHei-111\"/>\n",
       "      <use x=\"100\" xlink:href=\"#SimHei-115\"/>\n",
       "      <use x=\"150\" xlink:href=\"#SimHei-115\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_17\">\n",
       "    <path clip-path=\"url(#p9115dc4737)\" d=\"M 71.313636 257.515847 \n",
       "L 98.012201 194.519458 \n",
       "L 124.710766 259.076046 \n",
       "L 151.40933 226.906864 \n",
       "L 178.107895 244.317141 \n",
       "L 204.806459 260.773949 \n",
       "L 231.505024 261.017743 \n",
       "L 258.203589 254.959596 \n",
       "L 284.902153 261.63772 \n",
       "L 311.600718 260.41856 \n",
       "L 338.299282 262.115972 \n",
       "L 364.997847 263.41201 \n",
       "L 391.696411 264.903488 \n",
       "L 418.394976 262.632211 \n",
       "L 445.093541 265.845305 \n",
       "L 471.792105 262.896933 \n",
       "L 498.49067 266.344845 \n",
       "L 525.189234 263.120507 \n",
       "L 551.887799 263.269872 \n",
       "L 578.586364 266.645455 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_18\">\n",
       "    <path clip-path=\"url(#p9115dc4737)\" d=\"M 71.313636 19.554545 \n",
       "L 98.012201 70.34308 \n",
       "L 124.710766 70.502413 \n",
       "L 151.40933 103.189144 \n",
       "L 178.107895 124.935825 \n",
       "L 204.806459 124.982596 \n",
       "L 231.505024 125.023377 \n",
       "L 258.203589 139.255553 \n",
       "L 284.902153 139.264 \n",
       "L 311.600718 148.898361 \n",
       "L 338.299282 148.884374 \n",
       "L 364.997847 155.47475 \n",
       "L 391.696411 160.183927 \n",
       "L 418.394976 160.145481 \n",
       "L 445.093541 163.381332 \n",
       "L 471.792105 163.334274 \n",
       "L 498.49067 165.540834 \n",
       "L 525.189234 165.487554 \n",
       "L 551.887799 165.432281 \n",
       "L 578.586364 166.766946 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 45.95 279 \n",
       "L 45.95 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 603.95 279 \n",
       "L 603.95 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 45.95 279 \n",
       "L 603.95 279 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 45.95 7.2 \n",
       "L 603.95 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"legend_1\">\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 366.03425 57.006 \n",
       "L 576.03425 57.006 \n",
       "Q 578.43425 57.006 578.43425 54.606 \n",
       "L 578.43425 39.765375 \n",
       "Q 578.43425 37.365375 576.03425 37.365375 \n",
       "L 366.03425 37.365375 \n",
       "Q 363.63425 37.365375 363.63425 39.765375 \n",
       "L 363.63425 54.606 \n",
       "Q 363.63425 57.006 366.03425 57.006 \n",
       "z\n",
       "\" style=\"fill:#f5f5f5;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_19\">\n",
       "    <path d=\"M 368.43425 46.365375 \n",
       "L 392.43425 46.365375 \n",
       "\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_20\"/>\n",
       "   <g id=\"text_19\">\n",
       "    <!-- train_loss -->\n",
       "    <g transform=\"translate(402.03425 50.565375)scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path d=\"M 49.609375 -13.671875 \n",
       "L 0 -13.671875 \n",
       "L 0 -8.984375 \n",
       "L 49.609375 -8.984375 \n",
       "z\n",
       "\" id=\"SimHei-95\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#SimHei-116\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-114\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-97\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-105\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-110\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-95\"/>\n",
       "     <use x=\"300\" xlink:href=\"#SimHei-108\"/>\n",
       "     <use x=\"350\" xlink:href=\"#SimHei-111\"/>\n",
       "     <use x=\"400\" xlink:href=\"#SimHei-115\"/>\n",
       "     <use x=\"450\" xlink:href=\"#SimHei-115\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path d=\"M 486.03425 46.365375 \n",
       "L 510.03425 46.365375 \n",
       "\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_22\"/>\n",
       "   <g id=\"text_20\">\n",
       "    <!-- test_loss -->\n",
       "    <g transform=\"translate(519.63425 50.565375)scale(0.12 -0.12)\">\n",
       "     <use xlink:href=\"#SimHei-116\"/>\n",
       "     <use x=\"50\" xlink:href=\"#SimHei-101\"/>\n",
       "     <use x=\"100\" xlink:href=\"#SimHei-115\"/>\n",
       "     <use x=\"150\" xlink:href=\"#SimHei-116\"/>\n",
       "     <use x=\"200\" xlink:href=\"#SimHei-95\"/>\n",
       "     <use x=\"250\" xlink:href=\"#SimHei-108\"/>\n",
       "     <use x=\"300\" xlink:href=\"#SimHei-111\"/>\n",
       "     <use x=\"350\" xlink:href=\"#SimHei-115\"/>\n",
       "     <use x=\"400\" xlink:href=\"#SimHei-115\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p9115dc4737\">\n",
       "   <rect height=\"271.8\" width=\"558\" x=\"45.95\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute time is 0.222 seconds\n"
     ]
    }
   ],
   "source": [
    "# define model and loss\n",
    "model = PolyModel(poly_feature.shape[1])\n",
    "init.normal_(model.layer[0].weight, 0, 0.01)\n",
    "init.constant_(model.layer[0].bias, 0)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "# deal with data\n",
    "train_dataset = Data.TensorDataset(poly_feature[:2], y[:2])\n",
    "test_dataset = Data.TensorDataset(poly_feature[100:], y[100:])\n",
    "test_iter = Data.DataLoader(test_dataset, batch_size=len(y[:100]), shuffle=True)\n",
    "\n",
    "params = {\n",
    "    \"model\": model,\n",
    "    \"loss\": loss,\n",
    "    \"epoch_num\": 10,\n",
    "    \"batch_size\": 1,\n",
    "    \"lr\": 0.01,\n",
    "    \"data_num\": 2,\n",
    "    \"test_iter\":test_iter,\n",
    "    \"draw\": True,\n",
    "}\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=params[\"lr\"])\n",
    "train_iter = Data.DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "params[\"optimizer\"] = optimizer\n",
    "params[\"train_iter\"] = train_iter\n",
    "\n",
    "# training\n",
    "set_fig_display()\n",
    "train_experiment(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看见，虽然训练样本的误差很低，但是测试误差却是很高，这是典型的过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此，降低训练误差不一定意味着泛化误差一定会降低，机器学习模型应该关注降低泛化误差\n",
    "- 可以使用验证集来进行模型的选择\n",
    "- 欠拟合指的是无法得到较低的训练误差\n",
    "- 过拟合是模型的训练误差远小于测试集上的误差\n",
    "- 偏差-方差的trade-off"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
