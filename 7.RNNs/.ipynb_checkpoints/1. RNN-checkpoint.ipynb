{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T15:08:53.559845Z",
     "start_time": "2020-10-31T15:08:53.529334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity = \"all\"\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T15:08:54.507462Z",
     "start_time": "2020-10-31T15:08:53.678487Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import zipfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相对于多层感知机和能够有效处理空间信息的CNN，RNN主要用于处理时序数据，它引入状态变量来存储过去的信息，并用其于当前的输入共同决定当前的输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-24T06:50:34.594726Z",
     "start_time": "2020-10-24T06:50:34.591690Z"
    }
   },
   "source": [
    "$$h_{t} = f(W_{hx}x_t + W_{hh}h_{t-1} + b_h)$$\n",
    "$$y_t = g(W_{yh}h_t + b_y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实对于$W_{hx}, x_t, W_{hh}, h_{t-1}$，它们是可以不需要分开处理，只需将$x_t$和$h_{t-1}$按列合并，将$W_{xh}$和$W_{hh}$按行合并，并进行矩阵相乘，能获得一样的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T15:08:54.724875Z",
     "start_time": "2020-10-31T15:08:54.709456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36117668,  0.84170464,  0.51634436,  1.0192241 ],\n",
       "       [ 1.98568241,  1.65775323, -0.14316661,  0.47196442],\n",
       "       [-0.75610492, -0.22715356, -0.76128796, -0.84124357]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 假设xt-->(3, 1), W_hx--->(4, 3)，W_hh--->(4, 4), h_(t-1) ---> (3, 4)\n",
    "xt = np.random.rand(3, 1)\n",
    "w_hx = np.random.rand(1, 4)\n",
    "w_hh = np.random.rand(4, 4)\n",
    "h_t_1 = np.random.randn(3, 4)\n",
    "\n",
    "h_t = xt@w_hx + h_t_1@w_hh\n",
    "h_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T15:08:54.888000Z",
     "start_time": "2020-10-31T15:08:54.883676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36117668,  0.84170464,  0.51634436,  1.0192241 ],\n",
       "       [ 1.98568241,  1.65775323, -0.14316661,  0.47196442],\n",
       "       [-0.75610492, -0.22715356, -0.76128796, -0.84124357]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_t = np.hstack((xt, h_t_1)) @ np.vstack((w_hx, w_hh))\n",
    "h_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建token映射"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-24T07:07:44.983347Z",
     "start_time": "2020-10-24T07:07:44.973007Z"
    }
   },
   "source": [
    "使用周杰伦歌词来建模，并对周杰伦歌词进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T15:08:55.775122Z",
     "start_time": "2020-10-31T15:08:55.745635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'想要有直升机\\n想要和你飞到宇宙去\\n想要和你融化在一起\\n融化在宇宙里\\n我每天每天每天在想想想想著你\\n这样的甜蜜\\n让我开始乡相信命运\\n感谢地心引力\\n让我碰到你\\n漂亮的让我面红的可爱女人\\n温柔的让我心疼的可'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "63282"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f.read是读取整个文件数据字符串，f.readline是读取一行数据，f.readlines是读取一个数据列表\n",
    "with zipfile.ZipFile(\"../data/jaychou_lyrics.txt.zip\") as zfile:\n",
    "    with zfile.open(\"jaychou_lyrics.txt\", \"r\") as f:\n",
    "        corpus_chars = f.read().decode(\"utf-8\")\n",
    "        \n",
    "# 看一下数据长什么样\n",
    "corpus_chars[:100]\n",
    "len(corpus_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整个数据集中有63282条数据，为了打印方便，将换行符来替换空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T15:08:56.292730Z",
     "start_time": "2020-10-31T15:08:56.278975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5819"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_chars.count(\"\\n\")\n",
    "corpus_chars.count(\"\\r\")\n",
    "corpus_chars = corpus_chars.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T15:08:58.085250Z",
     "start_time": "2020-10-31T15:08:58.081311Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data_jay_song(corpus_chars):\n",
    "    \"\"\"\n",
    "    function: load the data of jay song\n",
    "    params corpus_chars: the chars in corpus\n",
    "    \"\"\"\n",
    "    # id --> chars, the index is id: list\n",
    "    vocab_set = list(set(corpus_chars))\n",
    "    # corpus char --> id: dict\n",
    "    chars_to_idx = {chars: idx for idx, chars in enumerate(vocab_set)}\n",
    "    # the length of vocab_list\n",
    "    vocab_size = len(vocab_set)\n",
    "    # the index of data\n",
    "    corpus_index = [chars_to_idx[chars] for chars in corpus_chars]\n",
    "    \n",
    "    return corpus_index, chars_to_idx, vocab_set, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T15:08:58.267504Z",
     "start_time": "2020-10-31T15:08:58.246935Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_index, chars_to_idx, vocab_set, vocab_size = load_data_jay_song(corpus_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 时序数据采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练中我们每次需要随机读取小批量样本和标签，时序数据的一个样本通常包含连续字符\n",
    "- 如果time-step=5的时候，就是输入的样本序列为5个字符（你-今-天-吃-了），标签中的每一个字符就是对应训练集中的下一个字符（今-天-吃-了-吗）\n",
    "- 对时序数据的采样方式有两种，一个是随机采样，另外一种就是相邻采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在随机采样中，每个样本是原始序列中任意截取的一段序列，相邻的两个随机小批量在原始序列中的位置不一定相毗邻\n",
    "- 因此，我们不能用前一个小批量最后time_step的隐藏状态来初始化下一个小批量的隐藏状态\n",
    "- 在训练模型的时候，如果使用随机采样，那么在每次随机采样之前都要重新初始化隐藏状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T16:03:56.532197Z",
     "start_time": "2020-10-31T16:03:56.509980Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_iter_random(corpus_index, batch_size, num_steps):\n",
    "    \"\"\"\n",
    "    function: realize random sample\n",
    "    params corpus_index: the idx with corpus --> list\n",
    "    params batch_size: the size of each batch\n",
    "    params num_steps: the number of time steps in a network\n",
    "    \"\"\"\n",
    "    # because the index of y is equal to the index of x + 1, so when we calucate the number of example,\n",
    "    # we should use len(corpus_index) - 1, \"example_num\" stand fot the number of example with the num_steps.\n",
    "    example_num = (len(corpus_index) - 1) // num_steps\n",
    "    sample_start = (len(corpus_index) - 1) % num_steps\n",
    "    # the example is the combination of several char, so it must with num_steps. when the example is not the\n",
    "    # factor of batch_size, we only retain the complete example\n",
    "    if sample_start != 0:\n",
    "        example_index = np.arange(np.random.randint(sample_start), \n",
    "                                  len(corpus_index), num_steps)[:example_num]\n",
    "    else:\n",
    "        example_index = np.arange(0, len(corpus_index), num_steps)[:example_num]\n",
    "    np.random.shuffle(example_index)\n",
    "\n",
    "    # extract batch example\n",
    "    for idx in np.arange(0, len(example_index), batch_size):\n",
    "        batch_example = example_index[idx:(idx+batch_size)]\n",
    "        # extract example in each batch\n",
    "        x = [corpus_index[pos:(pos+num_steps)] for pos in batch_example]\n",
    "        y = [corpus_index[(pos+1):(pos+1+num_steps)] for pos in batch_example]\n",
    "        yield torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T16:04:28.379107Z",
     "start_time": "2020-10-31T16:04:28.355726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[21., 22., 23., 24., 25., 26.],\n",
      "        [15., 16., 17., 18., 19., 20.]])\n",
      "y: tensor([[22., 23., 24., 25., 26., 27.],\n",
      "        [16., 17., 18., 19., 20., 21.]])\n",
      "\n",
      "\n",
      "x: tensor([[ 9., 10., 11., 12., 13., 14.],\n",
      "        [ 3.,  4.,  5.,  6.,  7.,  8.]])\n",
      "y: tensor([[10., 11., 12., 13., 14., 15.],\n",
      "        [ 4.,  5.,  6.,  7.,  8.,  9.]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_index = list(range(30))\n",
    "for x, y in data_iter_random(corpus_index, 2, 6):\n",
    "    print(f\"x: {x}\")\n",
    "    print(f\"y: {y}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相邻采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们还可以让相邻的两个随机小批量在原始序列上的位置相邻，这时我们就可以用一个小批量最终时间步的隐藏层来初始化下一个小批量的隐藏状态，那么下一个下批量的输出也取决于当前小批量的输入\n",
    "- 这样做，在训练模型的时候，我们只需要一个迭代周期开始的时候初始化隐藏状态\n",
    "- 当多个相邻小批量通过传递隐藏状态串联起来的时候，模型参数的梯度计算将依赖所有串联起来的小批量序列。随着迭代次数的增加，梯度计算开销回越来越大（此时可以在每次小批量前将隐藏状态从计算图中分离出来，让模型参数的梯度计算只依赖一次迭代读取的小批量序列）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T16:10:09.065678Z",
     "start_time": "2020-10-31T16:10:09.057006Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_iter_consecutive(corpus_index, batch_size, num_step):\n",
    "    \"\"\"realize consecutive sample, the params is same as random sample\"\"\"\n",
    "    example_num = (len(corpus_index) - 1) // num_step\n",
    "    # avoid the situation of (len(corpus_index) - 1) % num_step == 0\n",
    "    try:\n",
    "        sample_start = np.random.randint((len(corpus_index) - 1) % num_step)\n",
    "    except:\n",
    "        sample_start = 0\n",
    "    # extract consecutive index which will sample, change shape with batch_size\n",
    "    corpus_index = torch.tensor(corpus_index[sample_start:sample_start+example_num*num_step], \n",
    "                                dtype=torch.float32).view(batch_size, -1)\n",
    "    \n",
    "    batch_num = corpus_index.shape[1] // num_step\n",
    "    # the reason same as sample_start\n",
    "    try:\n",
    "        batch_start = np.random.randint(corpus_index.shape[1] % num_step)\n",
    "    except:\n",
    "        batch_start = 0\n",
    "    # yield consecutive sample with num_step\n",
    "    for i in range(batch_start, batch_start+batch_num*num_step, num_step):\n",
    "        x = corpus_index[:, i:i+num_step]\n",
    "        y = x + 1\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-31T16:11:10.865579Z",
     "start_time": "2020-10-31T16:11:10.857009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
      "        [12., 13., 14., 15., 16., 17.]])\n",
      "y: tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],\n",
      "        [13., 14., 15., 16., 17., 18.]])\n",
      "\n",
      "\n",
      "x: tensor([[ 6.,  7.,  8.,  9., 10., 11.],\n",
      "        [18., 19., 20., 21., 22., 23.]])\n",
      "y: tensor([[ 7.,  8.,  9., 10., 11., 12.],\n",
      "        [19., 20., 21., 22., 23., 24.]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_index = list(range(30))\n",
    "for x, y in data_iter_consecutive(corpus_index, 2, 6):\n",
    "    print(f\"x: {x}\")\n",
    "    print(f\"y: {y}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
