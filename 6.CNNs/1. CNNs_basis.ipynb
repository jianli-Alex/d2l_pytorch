{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T12:50:05.949451Z",
     "start_time": "2020-10-09T12:50:05.915891Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%config ZMQInteractiveShell.ast_node_interactivity = \"all\"\n",
    "%pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二维卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积神经网络是含有卷积层的神经网络\n",
    "- 我们用得最多就是二维的卷积层(有高宽两个维度)\n",
    "- 多输入通道数和多输出通道数的卷积层都是在这上面进行扩展"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积和互相关运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常来说,我们在卷积神经网络上使用的卷积运算并不是真正的卷积运算,其通常是使用互相关运算\n",
    "- 卷积运算是先将卷积核上下左右翻转后,再对输入数据进行互相关运算\n",
    "- 但由于深度学习中,卷积核的参数都是学习出来的,无论使用互相关运算或者是真正的卷积运算都不影响模型预测时的输出\n",
    "- 卷积核其实就是一个特征提取器,运算后的输出可以看成是输入在空间维度(高和宽)上某一级的表征\n",
    "- 考虑单通道输入和输出,将输入的高宽分别记为$I_h$和$I_w$,卷积核的高宽分别记为$K_h$和$K_w$,输出的的高宽分别记为$O_h$和$O_w$,对高宽进行的padding分别记为$p_h$和$p_w$,对高宽进行的stride分别记为$s_h$和$s_w$,那么对于以下几种情况的卷积输出分别为:\n",
    "    - 无padding和stride: $O_h = I_h - k_h + 1$, $O_w = I_w - k_w + 1$\n",
    "    - 有padding和无stride: $O_h = I_h - k_h + p_h + 1$, $O_h = I_w- k_w + p_w + 1$\n",
    "    - 无padding和有stride: $(O_h = I_h - k_h)/s_h + 1$, $(O_w = I_w - k_w)/s_w + 1$\n",
    "    - 有padding和有stride: $(O_h = I_h - k_h + p_h)/s_h + 1$, $(O_w = I_w - k_w + p_w)/s_w + 1$\n",
    "        - 其实第四条就能包括前三条,这里只是列得仔细点,另外p指的是两边一共padding的数量,有的书是用2p(这实际上是指单边的padding数量)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过我们会将padding设为$k-1$,这样就能获得和输入同shape的tensor(这也叫等宽卷积)\n",
    "- 卷积核通常也是奇数,这样两端的padding一样,否则为偶数时,一边的padding需要向上取整,另一边padding要向下取整\n",
    "- 目前多用小的卷积核(像1x1, 3x3等)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T13:14:55.160755Z",
     "start_time": "2020-10-09T13:14:55.136989Z"
    }
   },
   "source": [
    "我们可以通过更深的网络结构来让感受野变得更加广阔,从而捕捉输入上更大尺寸特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积个人实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在二维互相关运算中(如无特殊说明,深度学习中的卷积就是指互相关运算)\n",
    "- 就是卷积窗口从输入数组的最上方开始,从左到右,从上到下的顺序,依次做滑窗运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T11:15:21.429429Z",
     "start_time": "2020-10-09T11:15:21.426450Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T11:56:54.480144Z",
     "start_time": "2020-10-09T11:56:54.475620Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv2d(x, k):\n",
    "    \"\"\"\n",
    "    功能: 实现卷积操作(无padding/无stride)\n",
    "    参数 x: 输入数据\n",
    "    参数 k; 传入一个卷积核\n",
    "    \"\"\"\n",
    "    # 获取卷积核的大小\n",
    "    h, w = k.shape\n",
    "    # 定义输出的shpe\n",
    "    y = torch.rand((x.shape[0] - h + 1, x.shape[1] - w + 1))\n",
    "    # 卷积运算\n",
    "    for i in range(y.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            y[i, j] = (x[i:i+h, j:j+w] * k).sum()\n",
    "            \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T10:32:40.439622Z",
     "start_time": "2020-10-09T10:32:40.432133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(9).view(3, 3)\n",
    "k = torch.arange(4).view(2, 2)\n",
    "\n",
    "# 卷积运算\n",
    "conv2d(x, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T11:07:09.893140Z",
     "start_time": "2020-10-09T11:07:09.881886Z"
    }
   },
   "source": [
    "### 自定义卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T11:42:35.347329Z",
     "start_time": "2020-10-09T11:42:35.344821Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T12:02:08.947029Z",
     "start_time": "2020-10-09T12:02:08.934630Z"
    }
   },
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    \"\"\"自定义实现卷积层\"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(Conv2D, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return conv2d(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积窗口形状为pxq的卷积层称为pxq卷积层\n",
    "- 说明卷积核的高和宽分别为p和q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像的物体边缘检测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用卷积层来检测图像中的物体边缘(找到像素变化的位置)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T11:48:33.206683Z",
     "start_time": "2020-10-09T11:48:33.190680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建一个6*8的图像,中间4列为黑,其余为白\n",
    "x = torch.ones(6, 8)\n",
    "x[:, 2:6] = 0\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为实际上是测相邻的元素是否有变化,因此可以定义一个1*2的卷积核[[-1, 1]],只要相邻两行出现变化,卷积计算出来的就不为0,如果没有变化就为0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义卷积核的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T12:50:11.811816Z",
     "start_time": "2020-10-09T12:50:11.790373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0., -1.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0., -1.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0., -1.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0., -1.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0., -1.,  0.,  0.,  0.,  1.,  0.],\n",
       "        [ 0., -1.,  0.,  0.,  0.,  1.,  0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = torch.tensor([[-1, 1]])\n",
    "y = conv2d(x, k)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积层可以通过重复使用卷积核有效地表征局部空间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 网络训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T12:43:23.222708Z",
     "start_time": "2020-10-09T12:43:23.215211Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../d2l_func/\")\n",
    "from optim import sgd\n",
    "from sqdm import sqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T12:35:57.441699Z",
     "start_time": "2020-10-09T12:35:57.434031Z"
    }
   },
   "outputs": [],
   "source": [
    "def squared_loss(y_pred, y):\n",
    "    return ((y_pred - y)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T13:11:26.704663Z",
     "start_time": "2020-10-09T13:11:26.381473Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 23.8259, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [2/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 9.5828, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [3/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 6.6669, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [4/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 4.9749, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [5/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 3.7512, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [6/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.8428, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [7/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 2.1634, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [8/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.6526, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [9/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 1.2667, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [10/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.9739, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [11/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.7510, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [12/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.5807, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [13/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.4502, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [14/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.3500, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [15/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2727, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [16/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.2130, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [17/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1669, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [18/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1311, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [19/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.1033, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [20/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0816, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [21/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0647, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [22/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0515, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [23/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0411, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [24/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0330, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [25/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0266, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [26/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0216, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [27/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0176, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [28/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0144, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [29/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0118, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [30/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0098, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [31/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0082, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [32/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0069, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [33/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0059, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [34/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0050, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [35/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0043, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [36/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0037, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [37/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0033, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [38/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0029, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [39/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0026, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [40/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0023, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [41/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0021, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [42/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0019, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [43/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0017, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [44/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0016, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [45/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0015, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [46/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0014, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [47/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0013, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [48/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0013, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [49/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0012, train_score: -, test_loss: -, test_score: -\n",
      "\n",
      "Epoch [50/50]\n",
      "1/1 [>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] - train_loss: 0.0012, train_score: -, test_loss: -, test_score: -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model  = Conv2D(kernel_size=(1, 2))\n",
    "loss = squared_loss\n",
    "\n",
    "process_bar = sqdm()\n",
    "for epoch in range(50):\n",
    "    print(f\"Epoch [{epoch+1}/{50}]\")\n",
    "    y_pred = model(x)\n",
    "    l = loss(y_pred, y)\n",
    "    l.backward()\n",
    "    \n",
    "    sgd([model.weight, model.bias], lr=0.01, weight_decay=0.1)\n",
    "#     _ = model.weight.grad.data.zero_()\n",
    "#     _ = model.bias.grad.data.zero_()\n",
    "    _ = model.weight.grad.fill_(0)\n",
    "    _ = model.bias.grad.fill_(0)\n",
    "    \n",
    "    process_bar.show_process(data_num=1, batch_size=1, train_loss=l.item())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T13:11:31.910851Z",
     "start_time": "2020-10-09T13:11:31.893378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.9904,  0.9904]], requires_grad=True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-5.5702e-06], requires_grad=True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result\n",
    "model.weight\n",
    "model.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果和自定义的[[-1, 1]]差不多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 带padding卷积的个人实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T13:26:34.743036Z",
     "start_time": "2020-10-09T13:26:34.736637Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T13:26:51.555055Z",
     "start_time": "2020-10-09T13:26:51.548729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11, 12, 13, 14, 15]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(16).reshape(2, 8)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T13:27:48.666643Z",
     "start_time": "2020-10-09T13:27:48.662276Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  2,  3,  4,  5,  6,  7,  0,  0],\n",
       "       [ 0,  0,  8,  9, 10, 11, 12, 13, 14, 15,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(a, ((1, 1), (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T13:35:28.362105Z",
     "start_time": "2020-10-09T13:35:28.356334Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv2d_padding(x, k, padding):\n",
    "    \"\"\"\n",
    "    function: 实现带padding的卷积\n",
    "    params x: 输入张量\n",
    "    params k: 巻积核\n",
    "    params padding: 传入padding的元组(h, w),高padding多少,宽padding多少,如果为整数就高宽一样\n",
    "    \"\"\"\n",
    "    assert padding > 0\n",
    "    if padding == 0:\n",
    "        return conv2d(x, k)\n",
    "    else:\n",
    "        if isinstance(padding, int):\n",
    "            h = w = padding\n",
    "        else:\n",
    "            h, w = padding\n",
    "        x = x.numpy()\n",
    "        x = torch.from_numpy(np.pad(x, ((w, w), (h, h))))\n",
    "        return conv2d(x, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T13:35:35.640464Z",
     "start_time": "2020-10-09T13:35:35.621607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 等宽巻积\n",
    "x = torch.rand(8, 8)\n",
    "k = torch.rand(3, 3)\n",
    "\n",
    "conv2d_padding(x, k, padding=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 带stride的巻积个人实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T14:19:12.474013Z",
     "start_time": "2020-10-09T14:19:12.459141Z"
    }
   },
   "outputs": [],
   "source": [
    "def conv2d_padding_stride(x, k, padding, stride=1):\n",
    "    \"\"\"\n",
    "    function: 实现带padding和stride的巻积\n",
    "    params x: 输入张量\n",
    "    params k: 巻积核\n",
    "    params padding: 传入padding的元组(h, w),高padding多少,宽padding多少,如果为整数就高宽一样\n",
    "    params stride: 默认为1, 传入(h, w)或者整数\n",
    "    \"\"\"\n",
    "    if stride == 1:\n",
    "        return conv2d_padding(x, k, padding)\n",
    "    else:\n",
    "        kh, kw = k.shape\n",
    "        if isinstance(padding, int):\n",
    "            ph = pw = padding\n",
    "        else:\n",
    "            ph, pw = padding\n",
    "            \n",
    "        if isinstance(stride, int):\n",
    "            sh = sw = stride\n",
    "        else:\n",
    "            sh, sw = stride\n",
    "        \n",
    "        y = np.zeros(np.round((x.shape[0] - kh + ph + sh)/sh), \n",
    "                        np.round((x.shape[1] - kw + pw + sw)/sw))\n",
    "        y = torch.from_numpy(y)\n",
    "        \n",
    "        # 对x加padding\n",
    "        x = x.numpy()\n",
    "        x = torch.from_numpy(np.pad(x, ((pw, pw), (ph, ph))))\n",
    "        \n",
    "        for i in range(0, y.shape[0], sh):\n",
    "            for j in range(0, y.shape[1], sw):\n",
    "                y[i, j] = (x[i:(i+h), j:(j+w)] * k).sum()\n",
    "            \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T14:14:59.659399Z",
     "start_time": "2020-10-09T14:14:59.654849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.floor(2.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-09T14:19:13.544354Z",
     "start_time": "2020-10-09T14:19:13.512971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-7381d0039e3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconv2d_padding_stride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-131-803b025b25e1>\u001b[0m in \u001b[0;36mconv2d_padding_stride\u001b[0;34m(x, k, padding, stride)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         y = np.zeros(np.round((x.shape[0] - kh + ph + sh)/sh), \n\u001b[0m\u001b[1;32m     24\u001b[0m                         np.round((x.shape[1] - kw + pw + sw)/sw))\n\u001b[1;32m     25\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "x.shape\n",
    "k = torch.rand(3, 5)\n",
    "conv2d_padding_stride(x, k, (0, 1), (3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
